{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the home of solid-state physics \u00b6 This site exists to enhance the distribution of course information and content for the solid-state physics component of KYA322: Statistical and solid-state physics . All official communication will be though MyLO 1 . A Crocoite sample found near Dundas in western Tasmania. As part of this course, we will investigate the what happens when atoms are no longer considered in isolation, and see that systems of interacting particles can have some pretty incredible outcomes Course expectations: my expectations of you Solid-state physics is where the rubber meets the road: abstract concepts will be applied in an effort to model realistic and complex systems. There are delights are to be had, but like most truly rewarding endeavours, said delights do not come for free. In undertaking this course, it is expected that: You will view the content download sessions outside of scheduled lecture times Prescribed problems and reading will be undertaken before any content extraction sessions If you are experiencing difficulties, that you will get in contact as soon as is reasonably possible Course objectives The purpose of this course is to provide an introduction to the world of solid-state physics. At the conclusion of your journey, you should: Be familiar with the main models of solid-state physics, and their application to real-world systems Have proficiency parsing and extracting information from applied solid-state systems, with an eye to identification the relevant theoretical framework(s) and the concise formulation of physics to be investigated Have experience identifying and applying appropriate approximations and physical insight to make difficult problems more tractable Be familiar with experimental and analytical apparatus relevant to probing solid-state systems, in addition to some of the main systems and devices one might encounter in the wild Have had some fun! Course expectations: my promises to you Rightly, you should have expectations of me. It is my intention that: I will work to communicate my understanding and insight in the course material I will actively seek input to steer and shape the content discussed, and develop relevant resources I will be widely available for consultation and discussion I will do my best to cultivate a safe and open forum for discussion If you think that I am not fulfilling my commitments, or if you have other comments, I would hope that you are comfortable conveying your concerns and/or comments to me, either directly or anonymously. It is my genuine desire to help you navigate learning new concepts and ideas, and I want to do this to the best of my ability, and feedback is the best way to ensure this endeavour proceeds as smoothly as possible. For the curious traveller, MyLO is The University of Tasmania's learning management system, based on Brightspace as developed D2L. \u21a9","title":"Home"},{"location":"#welcome-to-the-home-of-solid-state-physics","text":"This site exists to enhance the distribution of course information and content for the solid-state physics component of KYA322: Statistical and solid-state physics . All official communication will be though MyLO 1 . A Crocoite sample found near Dundas in western Tasmania. As part of this course, we will investigate the what happens when atoms are no longer considered in isolation, and see that systems of interacting particles can have some pretty incredible outcomes Course expectations: my expectations of you Solid-state physics is where the rubber meets the road: abstract concepts will be applied in an effort to model realistic and complex systems. There are delights are to be had, but like most truly rewarding endeavours, said delights do not come for free. In undertaking this course, it is expected that: You will view the content download sessions outside of scheduled lecture times Prescribed problems and reading will be undertaken before any content extraction sessions If you are experiencing difficulties, that you will get in contact as soon as is reasonably possible Course objectives The purpose of this course is to provide an introduction to the world of solid-state physics. At the conclusion of your journey, you should: Be familiar with the main models of solid-state physics, and their application to real-world systems Have proficiency parsing and extracting information from applied solid-state systems, with an eye to identification the relevant theoretical framework(s) and the concise formulation of physics to be investigated Have experience identifying and applying appropriate approximations and physical insight to make difficult problems more tractable Be familiar with experimental and analytical apparatus relevant to probing solid-state systems, in addition to some of the main systems and devices one might encounter in the wild Have had some fun! Course expectations: my promises to you Rightly, you should have expectations of me. It is my intention that: I will work to communicate my understanding and insight in the course material I will actively seek input to steer and shape the content discussed, and develop relevant resources I will be widely available for consultation and discussion I will do my best to cultivate a safe and open forum for discussion If you think that I am not fulfilling my commitments, or if you have other comments, I would hope that you are comfortable conveying your concerns and/or comments to me, either directly or anonymously. It is my genuine desire to help you navigate learning new concepts and ideas, and I want to do this to the best of my ability, and feedback is the best way to ensure this endeavour proceeds as smoothly as possible. For the curious traveller, MyLO is The University of Tasmania's learning management system, based on Brightspace as developed D2L. \u21a9","title":"Welcome to the home of solid-state physics"},{"location":"01specificheatI/","text":"The specific heat of solids I \u00b6 Introduction \u00b6 We embark on our journey by starting at the nexus of the known and unknown, namely around the turn of the nineteenth and twentieth centuries, where the development of \"modern\" physics was being applied to systems which had hitherto be poorly understood. Now this is not to say that nothing was known about the systems, on the contrary: empirical laws had been used to great effect to describe the observable world, but with the increasing sophistication of experimental technique and apparatus, the cracks in certain rules started to appear. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Thermal physics: heat capacity Quantum mechanics: energy spectrum of the harmonic oscillator Statistical physics: the partition function, equipartition theorem Text reference The material covered here is discussed in section(s) \\S 2.1 of The Oxford Solid State Basics The Dulong\u2013Petit law \u00b6 Consider the heat capacity of a solid. 1.1 Explain the concept of heat capacity in a manner understandable to someone without a science background. The heat capacity is the a measure of how much heat, or how much energy transfer, is required to change the temperature of a material. By measuring the heat capacity per weight, that is the mass-specific heat capacity , of a range of different elements, the two chemists Pierre Dulong and Alexis Petit observed the value was approximately constant when multiplied by the atomic weight of the element, stating that: c \\times M = constant where c is the specific heat capacity and M is the molar mass of the material. More commonly, one will see the law expressed in terms of the heat capacity C and number of moles n : C/n=\\frac{\\partial Q}{\\partial T} = 3R where R \\approx 8.314~\\mathrm{J K^{-1} mol^{-1}} is the ideal gas constant 1 . In the physics context, it is much more common do talk about the number of atoms N , which transforms the above equation into the Dulong-Peteit Law : C/N= 3 k_\\mathrm{B} But is this an accurate description? Let's have a look. Shown below is a plot of the heat capacity C 2 (in units of R ) as a function of atomic number: Heat capacity of the elements at room temperature as sourced from the CRC handbook of chemistry of physics which is pretty incredible. But a natural question arises: why is this the case? The Boltzmann model of a solid \u00b6 It was exactly the question of \"why does the Dulong-Petit law seem to work?\" that motivated Ludwig Boltzmann to use his novel - and at the time completely unaccepted - ideas, notably the existence of atoms and molecules and the mechanics that arises from statistically significant numbers of these atoms and molecules, to model unexplained systems. The insight of Boltzmann was to consider a solid as a collection of constituent particles, but unlike gasses, these particles would be strongly interacting. Explicitly, the idea of atoms interacting with their nearest neighbours through an elastic spring-like potential - an harmonic potential - would allow the system to be modelled with statistical mechanics. Like the case of a gas, energy can be stored in the system in the form of atomic motion, but unlike a gas, the motion of the atoms is constrained. A schematic of the atomic-scale model constructed by Boltzmann in an attempt to explain the Dulong-Petit law Whilst this may seem like a major leap forward, it is worth considering what the explaination for this behaviour had been prior to this proposal: nothing . Then, using the recently minted ideas such as the equipartition theorem , it was clear why the C/N= 3 k_\\mathrm{B} . To see this, recall that for a gas in thermal equilibrium, we have C_V/N = f/2 k_\\mathrm{B} where f is the number of thermodynamic degrees of freedom, or stated another way: each degree of freedom contributes k_\\mathrm{B}/2 to the heat capacity. Immediately, we can see that the Dulong\u2013Petit law is of this form, but suggests that the number of DoF is six, i.e. twice that of an ideal monatomic gas. 1.2 What is the difference between the heat capacities C_V and C_P ? What is the relationship between the two quantities, and what is the implication for the heat capacity of solids? As the heat capacity of an object is defined through \\frac{\\partial Q}{\\partial T} , one must consider the different thermodynamic processes (e.g. isochoric versus isobraic) as the heat supplied to the system will be different (e.g. dQ = dU versus dQ = dU + PdV ). It then follows that we define the heat capacity at constant volume C_V and the heat capacity at constant pressure C_P . Linking the two quantities is Mayer's relation, which states that for an ideal gas: C_P - C_V = nR and more generally C_P - C_V = \\frac{VT\\alpha^2}{\\beta} where \\alpha is the thermal expansion coefficient and \\beta is the isothermal compressibility. This should immediately point to the implication for solids: solids tend to be rather incompressible, which manifests in small values of \\alpha and \\beta , and especially small values of \\alpha^2 , and a negligible difference between C_P and C_V . Hence the usage of C ! The thermal expansion coefficients of various elements, noting that \\beta is of order 10^{-6} \\mathrm{m}^2 \\mathrm{N}^{-1} for squishy things (e.g. soft clay) down to 10^{-10} \\mathrm{m}^2 \\mathrm{N}^{-1} for things that a not squishy (e.g. rocks) Hopefully it not a mystery why there are additional degrees of freedom in a solid as compared to a monatomic gas: remember that Boltzmann's model of a solid is effectively a collection of harmonic oscillators, so not only could energy be stored in the motion of the motion of the constituent atoms, but also their position, storing energy in the \"bonds\" between atoms. Monatomic gas The degrees of freedom for a monatomic gas are listed below: Property Degrees of freedom Momentum p_x , p_y , and p_z The 4 degrees of freedom each contribute k_\\mathrm{B}/2 to the specific heat such that C=3k_\\mathrm{B}/2 . Diatomic gas The degrees of freedom for a diatomic gas (at room temperature) are listed below: Property Degrees of freedom Momentum p_x , p_y , and p_z Rotation Axial and end-over-end The 5 degrees of freedom each contribute k_\\mathrm{B}/2 to the specific heat such that C=5k_\\mathrm{B}/2 . Solid The degrees of freedom for a solid are listed below: Property Degrees of freedom Momentum p_x , p_y , and p_z Position x , y , and z The 6 degrees of freedom each contribute k_\\mathrm{B}/2 to the specific heat such that C=3k_\\mathrm{B} . This result stood as one of the great achievements of statistical mechanics at the time, as up to (and indeed past this point) it was still considered a fringe theory. So, what happened? Diamond is the worst \u00b6 but also, diamond is remarkable Whilst most people will be familiar with the cool properties of diamond, some things are best seen. For example, diamond is often quoted as having the greatest thermal conductivity of any material, but what does that actually look like? Well, take a look : If one inspects the plot of heat capacities for the different elements, one can see that there are a few outliers, but it should be made clear that these measurements were taken at room temperature. Above room temperature, there is widespread agreement - even better than room temperature - but if one makes the same measurements at low temperatures, the Dulong-Petit law completely falls apart, with C \\rightarrow 0 as T \\rightarrow 0 . And even at room temperature, some materials do not behave as expected, and in particular: diamond. At room temperature, diamond has a value of C/R \\approx 0.74 , which is much less than 3! The remarkable properties of diamond had long been known, and consequently any theory its salt had to explain why diamond was special. Shown below is a plot of the heat capacity of diamond versus temperature: The heat capacity of diamond as a function of temperature. Data has been sourced from Einstein's original paper of $T>230~\\mathrm{K}$ and from J. E. Desnoyehs & J. A. Morrison for $T < 230~\\mathrm{K}$. Immediately one can notice: C is not a constant Things are good at high temperature Things are bad at low temperature and Boltzmann's theory does not do anything to explain any of this. The Einstein model of a solid \u00b6 It is perhaps unsurprising that a both difficult and well-known problem became the focus of attention for Einstein, someone who even at the very beginning of his career showed remarkable insight into physical systems, often reasoning from observations what must be going on, and constructing a theory to make it all work. Following his work on the photoelectric effect and Brownian motion, he was well placed to tackle the problem of the unexpected behaviour of heat capacity at low-temperatures. The model \u00b6 Like Boltzmann's model, Einstein's model was based around atoms in an harmonic potential, but they key - and highly consequential - difference being that each atom is an identical potential, and that oscillation in said potential occurs at a frequency \\omega , later dubbed the Einstein frequency . Basically, he took Boltzmann's model, injected quantum mechanics and asked: what will be the result. It is worth pausing to point out that this was done prior to quantum mechanics having been developed: Einstein's explanation of the photoelectric effect is widely heralded as the starting point of quantum, but it was not until roughly 20 years later that the Schr\u00f6dinger equation was published! So this was a pretty wild assertion. To see the implications, we can make use of our knowledge of statistical physics and the quantum harmonic oscillator: using the energy eigenstates of the system E_n , we can calculate the partition function Z , then the expectation value for the energy \\langle E \\rangle , and ultimately the heat cavity C . 1.3 Beginning with the energy eigenstates of a single one-dimensional harmonic oscillator, show that the heat capacity for a single oscillator is C = k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} In one dimension, the energy eigenstates E_n of a single harmonic oscillator are given by: E_n = \\hbar\\omega(n+1/2) where \\omega is the frequency of the harmonic oscillator. The partition function is then given by: \\begin{aligned} Z = & \\sum_{n\\ge0} \\exp\\left[-\\beta\\hbar\\omega(n+1/2)\\right] \\\\ = & \\frac{\\exp(-\\beta\\hbar\\omega/2)}{1-\\exp(-\\beta\\hbar\\omega)} = \\frac{1}{2\\sinh(\\beta\\hbar\\omega/2)} \\end{aligned} We can then compute the expectation value of the energy \\langle E \\rangle via \\begin{aligned} \\langle E \\rangle = -\\frac{1}{Z}\\frac{\\partial Z}{\\partial \\beta} & = \\frac{\\hbar \\omega}{2}\\coth\\left(\\beta\\hbar\\omega/2\\right) \\\\ & = \\hbar \\omega \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + 1/2\\right) \\end{aligned} where n_\\mathrm{B} is the Bose occupation factor, defined as n_\\mathrm{B}(x) = \\frac{1}{\\exp(x)-1} It then straightforward to extract the heat capacity for a single oscillator through C = \\frac{\\partial \\langle E \\rangle}{\\partial T} = k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} The above result is stated for a one-dimensional harmonic oscillator, but to expend the system three dimensions we need to multiply this result by three 3 which gives the final result C = 3k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} 1.4 Produce a plot the specific heat C versus temperature for realistic values of \\omega , providing your code. Code the produce the plot as requested in shown below, along with the output of said code. Note that # Import all the goodies required for running code in this unit from ssp import * # Define a function to calculate the heat capacity def c_einstein ( T , w ): \"\"\" Calculate the specific heat capacity according to the Einstein model of a solid Input: --- T: Temperature [K] w: Einstein frequency \\omega [rad.s^-1] Returns: --- The heat capacity in units of k_B \"\"\" x = ( hbar * w ) / ( T * kb ) # scale the variable return 3 * x ** 2 * np . exp ( x ) / ( np . exp ( x ) - 1 ) ** 2 # compute the heat capacity # The range of temperatures over which the heat capity will be calculated # Note: overflow errors will occur is the x_min value is too small temp = np . linspace ( 10 , 1000 , 200 ) # The range of Einstein freqeuncies to be computed. For reference, diamond has \\omega \\approx 170 w = np . linspace ( 20 , 200 , 5 ) # Create the plot instance fig , ax = plt . subplots () # Plot and label each frequency for f in w : ax . plot ( temp , c_einstein ( temp , f * 1e12 ), label = f '$\\omega= { f : .0f } $ THz' ) # Make the plot readable ax . set_xlabel ( '$T [K]$' ) ax . set_ylabel ( r '$C/k_B$' ); ax . set_title ( r 'The Einstein model of heat capacity' ) ax . legend () # Save the figure plt . savefig ( '01_Einstein_c.svg' , facecolor = 'white' , transparent = False ) plt . show () # Show the plot A plot of the specific heat as computed from the Einstein model. Note that diamond has a an Einstein frequency of approximately \\omega = 170~\\mathrm{Hz} Looking at the from of C , it is clear: In the high-temperature limit ( k_{\\mathrm{B}} T/\\hbar\\omega \\gg 1 ) we recover the Dulong-Petit law In the low-temperature limit, the heat capacity is exponentially small But what is the physical interpretation of this behaviour? For higher temperatures ( k_{\\mathrm{B}} T/\\hbar\\omega \\gg 1 ), the ability to store energy in harmonic motion is unencumbered, with a decrease in temperature, this ceases to be the case of these degrees of freedom are \"frozen out\". Once the temperature is sufficiently low ( k_{\\mathrm{B}} T/\\hbar\\omega < 1 ), atoms are necessarily in the ground states of the harmonic oscillator; only with sufficient energy ( E = \\hbar\\omega ) can an atom be excited, and with a temperature much less than the energy level spacing, atoms are stuck and thus cannot absorb any energy. It is incredible that Einstein reasoned that this process must be occurring, which prompted him to describe the theory, essentially leading to him inventing the quantisation of energy levels. Coming up diamonds \u00b6 Attempting to explain the heat capacity of diamond had proven the death knell of all theories up to this point, and so it is unsurprising that in Einstein's original paper on the topic cantered around measurements of the heat capacity of diamond, which is shown below: Plot A plot of the molar heat capacity of diamond as a function of temperature. The plot is somewhat diabolical in its omission of labels and units, which should read k_\\mathrm{B}T/\\hbar\\omega and C~[\\mathrm{cal}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}] for the x and y axes respectively Data The raw data used to produce the figure of the heat capacity of diamond There are obviously a few discrepancies, but on the whole it looks much better than the Boltzmann model and rightly was seen as a major triumph. But again, the question is why does this happen physically? What is it about diamond that makes is act so strangely? An energy-level diagram for the quantum harmonic oscillator, showing the wavefunctions for the three lowest-energy eigenstates Well if we consider the energy spacing of the harmonic oscillator, \\hbar\\omega , it is related to both the mass ( m ) and the spring constant ( \\kappa ) of the oscillator. For most materials, the Einstein frequency is such that C/N \\approx 3 k_\\mathrm{B} , but diamond has an especially low value of \\omega = \\sqrt{\\kappa/m} , which perhaps is unsurprising given that carbon is light (low m ) and diamond is incredibly hard (large \\kappa ). Conclusions \u00b6 The law of Dulong\u2013Petit is an observation that all materials have C \\approx 3k_B per atom. The Einstein model describes each atom in a solid as an independent quantum harmonic oscillator with the same eigenfrequency \\omega_0 . At sufficiently low T , the thermal excitations freeze out, resulting in \\langle E \\rangle = \\hbar \\omega_0/2 . The Einstein model correctly predicts that the heat capacity drops to 0 as T\\rightarrow 0 . Exercises \u00b6 Preliminary provocations \u00b6 What is the high-temperature heat capacity of an atom in a solid with two momentum and two spatial coordinate degrees of freedom? Sketch the Bose Einstein distribution as a function of \\omega for two different values of T Exercise 1: Total heat capacity of a diatomic material \u00b6 One of the assumptions of the Einstein model states that every atom in a solid oscillates with the same frequency \\omega_0 . However, if the solid contains different types of atoms, it is unreasonable to assume that the atoms oscillate with the same frequency. One example of such a solid is a lithium crystal, which consists of the two stable isotopes ^6 Li (7.5%) and ^7 Li (92.5%) in their natural abundance. Let us extend the Einstein model to take into account the different masses of these different isotopes. Assume that the solid is 1D (1D quantum harmonic oscillator). Assume that the strength of the returning force k experienced by each atom is the same. What is the difference in the oscillation frequencies of the two different isotopes in the lithium crystal? Write down the total energy stored in the vibrations of each atom of the lithium crystal, assuming that all ^6 Li atoms are in n=2 vibrational mode and all ^7 Li atoms are in n=4 vibrational mode. In the case where the oscilators can occupy any vibrational mode, write down the total energy stored in the vibrations of each atom in the lithium crystal at a temperature T by modifying the Einstein model. Compute the heat capacity of the lithium crystal as a function of T . The exact value can be found on the NIST database \u21a9 Data is collated in the Heat Capacity of the Elements at 25 ^{\\circ} C as published in the CRC handbook of chemistry of physics , but was sourced from wikipedia \u21a9 Verify this explicitly if it is not obvious: noting the result Z_{3D} = Z_{1D}^3 is a key observation \u21a9","title":"The specific heat of solids I"},{"location":"01specificheatI/#the-specific-heat-of-solids-i","text":"","title":"The specific heat of solids I"},{"location":"01specificheatI/#introduction","text":"We embark on our journey by starting at the nexus of the known and unknown, namely around the turn of the nineteenth and twentieth centuries, where the development of \"modern\" physics was being applied to systems which had hitherto be poorly understood. Now this is not to say that nothing was known about the systems, on the contrary: empirical laws had been used to great effect to describe the observable world, but with the increasing sophistication of experimental technique and apparatus, the cracks in certain rules started to appear. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Thermal physics: heat capacity Quantum mechanics: energy spectrum of the harmonic oscillator Statistical physics: the partition function, equipartition theorem Text reference The material covered here is discussed in section(s) \\S 2.1 of The Oxford Solid State Basics","title":"Introduction"},{"location":"01specificheatI/#the-dulongpetit-law","text":"Consider the heat capacity of a solid. 1.1 Explain the concept of heat capacity in a manner understandable to someone without a science background. The heat capacity is the a measure of how much heat, or how much energy transfer, is required to change the temperature of a material. By measuring the heat capacity per weight, that is the mass-specific heat capacity , of a range of different elements, the two chemists Pierre Dulong and Alexis Petit observed the value was approximately constant when multiplied by the atomic weight of the element, stating that: c \\times M = constant where c is the specific heat capacity and M is the molar mass of the material. More commonly, one will see the law expressed in terms of the heat capacity C and number of moles n : C/n=\\frac{\\partial Q}{\\partial T} = 3R where R \\approx 8.314~\\mathrm{J K^{-1} mol^{-1}} is the ideal gas constant 1 . In the physics context, it is much more common do talk about the number of atoms N , which transforms the above equation into the Dulong-Peteit Law : C/N= 3 k_\\mathrm{B} But is this an accurate description? Let's have a look. Shown below is a plot of the heat capacity C 2 (in units of R ) as a function of atomic number: Heat capacity of the elements at room temperature as sourced from the CRC handbook of chemistry of physics which is pretty incredible. But a natural question arises: why is this the case?","title":"The Dulong\u2013Petit law"},{"location":"01specificheatI/#the-boltzmann-model-of-a-solid","text":"It was exactly the question of \"why does the Dulong-Petit law seem to work?\" that motivated Ludwig Boltzmann to use his novel - and at the time completely unaccepted - ideas, notably the existence of atoms and molecules and the mechanics that arises from statistically significant numbers of these atoms and molecules, to model unexplained systems. The insight of Boltzmann was to consider a solid as a collection of constituent particles, but unlike gasses, these particles would be strongly interacting. Explicitly, the idea of atoms interacting with their nearest neighbours through an elastic spring-like potential - an harmonic potential - would allow the system to be modelled with statistical mechanics. Like the case of a gas, energy can be stored in the system in the form of atomic motion, but unlike a gas, the motion of the atoms is constrained. A schematic of the atomic-scale model constructed by Boltzmann in an attempt to explain the Dulong-Petit law Whilst this may seem like a major leap forward, it is worth considering what the explaination for this behaviour had been prior to this proposal: nothing . Then, using the recently minted ideas such as the equipartition theorem , it was clear why the C/N= 3 k_\\mathrm{B} . To see this, recall that for a gas in thermal equilibrium, we have C_V/N = f/2 k_\\mathrm{B} where f is the number of thermodynamic degrees of freedom, or stated another way: each degree of freedom contributes k_\\mathrm{B}/2 to the heat capacity. Immediately, we can see that the Dulong\u2013Petit law is of this form, but suggests that the number of DoF is six, i.e. twice that of an ideal monatomic gas. 1.2 What is the difference between the heat capacities C_V and C_P ? What is the relationship between the two quantities, and what is the implication for the heat capacity of solids? As the heat capacity of an object is defined through \\frac{\\partial Q}{\\partial T} , one must consider the different thermodynamic processes (e.g. isochoric versus isobraic) as the heat supplied to the system will be different (e.g. dQ = dU versus dQ = dU + PdV ). It then follows that we define the heat capacity at constant volume C_V and the heat capacity at constant pressure C_P . Linking the two quantities is Mayer's relation, which states that for an ideal gas: C_P - C_V = nR and more generally C_P - C_V = \\frac{VT\\alpha^2}{\\beta} where \\alpha is the thermal expansion coefficient and \\beta is the isothermal compressibility. This should immediately point to the implication for solids: solids tend to be rather incompressible, which manifests in small values of \\alpha and \\beta , and especially small values of \\alpha^2 , and a negligible difference between C_P and C_V . Hence the usage of C ! The thermal expansion coefficients of various elements, noting that \\beta is of order 10^{-6} \\mathrm{m}^2 \\mathrm{N}^{-1} for squishy things (e.g. soft clay) down to 10^{-10} \\mathrm{m}^2 \\mathrm{N}^{-1} for things that a not squishy (e.g. rocks) Hopefully it not a mystery why there are additional degrees of freedom in a solid as compared to a monatomic gas: remember that Boltzmann's model of a solid is effectively a collection of harmonic oscillators, so not only could energy be stored in the motion of the motion of the constituent atoms, but also their position, storing energy in the \"bonds\" between atoms. Monatomic gas The degrees of freedom for a monatomic gas are listed below: Property Degrees of freedom Momentum p_x , p_y , and p_z The 4 degrees of freedom each contribute k_\\mathrm{B}/2 to the specific heat such that C=3k_\\mathrm{B}/2 . Diatomic gas The degrees of freedom for a diatomic gas (at room temperature) are listed below: Property Degrees of freedom Momentum p_x , p_y , and p_z Rotation Axial and end-over-end The 5 degrees of freedom each contribute k_\\mathrm{B}/2 to the specific heat such that C=5k_\\mathrm{B}/2 . Solid The degrees of freedom for a solid are listed below: Property Degrees of freedom Momentum p_x , p_y , and p_z Position x , y , and z The 6 degrees of freedom each contribute k_\\mathrm{B}/2 to the specific heat such that C=3k_\\mathrm{B} . This result stood as one of the great achievements of statistical mechanics at the time, as up to (and indeed past this point) it was still considered a fringe theory. So, what happened?","title":"The Boltzmann model of a solid"},{"location":"01specificheatI/#diamond-is-the-worst","text":"but also, diamond is remarkable Whilst most people will be familiar with the cool properties of diamond, some things are best seen. For example, diamond is often quoted as having the greatest thermal conductivity of any material, but what does that actually look like? Well, take a look : If one inspects the plot of heat capacities for the different elements, one can see that there are a few outliers, but it should be made clear that these measurements were taken at room temperature. Above room temperature, there is widespread agreement - even better than room temperature - but if one makes the same measurements at low temperatures, the Dulong-Petit law completely falls apart, with C \\rightarrow 0 as T \\rightarrow 0 . And even at room temperature, some materials do not behave as expected, and in particular: diamond. At room temperature, diamond has a value of C/R \\approx 0.74 , which is much less than 3! The remarkable properties of diamond had long been known, and consequently any theory its salt had to explain why diamond was special. Shown below is a plot of the heat capacity of diamond versus temperature: The heat capacity of diamond as a function of temperature. Data has been sourced from Einstein's original paper of $T>230~\\mathrm{K}$ and from J. E. Desnoyehs & J. A. Morrison for $T < 230~\\mathrm{K}$. Immediately one can notice: C is not a constant Things are good at high temperature Things are bad at low temperature and Boltzmann's theory does not do anything to explain any of this.","title":"Diamond is the worst"},{"location":"01specificheatI/#the-einstein-model-of-a-solid","text":"It is perhaps unsurprising that a both difficult and well-known problem became the focus of attention for Einstein, someone who even at the very beginning of his career showed remarkable insight into physical systems, often reasoning from observations what must be going on, and constructing a theory to make it all work. Following his work on the photoelectric effect and Brownian motion, he was well placed to tackle the problem of the unexpected behaviour of heat capacity at low-temperatures.","title":"The Einstein model of a solid"},{"location":"01specificheatI/#the-model","text":"Like Boltzmann's model, Einstein's model was based around atoms in an harmonic potential, but they key - and highly consequential - difference being that each atom is an identical potential, and that oscillation in said potential occurs at a frequency \\omega , later dubbed the Einstein frequency . Basically, he took Boltzmann's model, injected quantum mechanics and asked: what will be the result. It is worth pausing to point out that this was done prior to quantum mechanics having been developed: Einstein's explanation of the photoelectric effect is widely heralded as the starting point of quantum, but it was not until roughly 20 years later that the Schr\u00f6dinger equation was published! So this was a pretty wild assertion. To see the implications, we can make use of our knowledge of statistical physics and the quantum harmonic oscillator: using the energy eigenstates of the system E_n , we can calculate the partition function Z , then the expectation value for the energy \\langle E \\rangle , and ultimately the heat cavity C . 1.3 Beginning with the energy eigenstates of a single one-dimensional harmonic oscillator, show that the heat capacity for a single oscillator is C = k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} In one dimension, the energy eigenstates E_n of a single harmonic oscillator are given by: E_n = \\hbar\\omega(n+1/2) where \\omega is the frequency of the harmonic oscillator. The partition function is then given by: \\begin{aligned} Z = & \\sum_{n\\ge0} \\exp\\left[-\\beta\\hbar\\omega(n+1/2)\\right] \\\\ = & \\frac{\\exp(-\\beta\\hbar\\omega/2)}{1-\\exp(-\\beta\\hbar\\omega)} = \\frac{1}{2\\sinh(\\beta\\hbar\\omega/2)} \\end{aligned} We can then compute the expectation value of the energy \\langle E \\rangle via \\begin{aligned} \\langle E \\rangle = -\\frac{1}{Z}\\frac{\\partial Z}{\\partial \\beta} & = \\frac{\\hbar \\omega}{2}\\coth\\left(\\beta\\hbar\\omega/2\\right) \\\\ & = \\hbar \\omega \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + 1/2\\right) \\end{aligned} where n_\\mathrm{B} is the Bose occupation factor, defined as n_\\mathrm{B}(x) = \\frac{1}{\\exp(x)-1} It then straightforward to extract the heat capacity for a single oscillator through C = \\frac{\\partial \\langle E \\rangle}{\\partial T} = k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} The above result is stated for a one-dimensional harmonic oscillator, but to expend the system three dimensions we need to multiply this result by three 3 which gives the final result C = 3k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} 1.4 Produce a plot the specific heat C versus temperature for realistic values of \\omega , providing your code. Code the produce the plot as requested in shown below, along with the output of said code. Note that # Import all the goodies required for running code in this unit from ssp import * # Define a function to calculate the heat capacity def c_einstein ( T , w ): \"\"\" Calculate the specific heat capacity according to the Einstein model of a solid Input: --- T: Temperature [K] w: Einstein frequency \\omega [rad.s^-1] Returns: --- The heat capacity in units of k_B \"\"\" x = ( hbar * w ) / ( T * kb ) # scale the variable return 3 * x ** 2 * np . exp ( x ) / ( np . exp ( x ) - 1 ) ** 2 # compute the heat capacity # The range of temperatures over which the heat capity will be calculated # Note: overflow errors will occur is the x_min value is too small temp = np . linspace ( 10 , 1000 , 200 ) # The range of Einstein freqeuncies to be computed. For reference, diamond has \\omega \\approx 170 w = np . linspace ( 20 , 200 , 5 ) # Create the plot instance fig , ax = plt . subplots () # Plot and label each frequency for f in w : ax . plot ( temp , c_einstein ( temp , f * 1e12 ), label = f '$\\omega= { f : .0f } $ THz' ) # Make the plot readable ax . set_xlabel ( '$T [K]$' ) ax . set_ylabel ( r '$C/k_B$' ); ax . set_title ( r 'The Einstein model of heat capacity' ) ax . legend () # Save the figure plt . savefig ( '01_Einstein_c.svg' , facecolor = 'white' , transparent = False ) plt . show () # Show the plot A plot of the specific heat as computed from the Einstein model. Note that diamond has a an Einstein frequency of approximately \\omega = 170~\\mathrm{Hz} Looking at the from of C , it is clear: In the high-temperature limit ( k_{\\mathrm{B}} T/\\hbar\\omega \\gg 1 ) we recover the Dulong-Petit law In the low-temperature limit, the heat capacity is exponentially small But what is the physical interpretation of this behaviour? For higher temperatures ( k_{\\mathrm{B}} T/\\hbar\\omega \\gg 1 ), the ability to store energy in harmonic motion is unencumbered, with a decrease in temperature, this ceases to be the case of these degrees of freedom are \"frozen out\". Once the temperature is sufficiently low ( k_{\\mathrm{B}} T/\\hbar\\omega < 1 ), atoms are necessarily in the ground states of the harmonic oscillator; only with sufficient energy ( E = \\hbar\\omega ) can an atom be excited, and with a temperature much less than the energy level spacing, atoms are stuck and thus cannot absorb any energy. It is incredible that Einstein reasoned that this process must be occurring, which prompted him to describe the theory, essentially leading to him inventing the quantisation of energy levels.","title":"The model"},{"location":"01specificheatI/#coming-up-diamonds","text":"Attempting to explain the heat capacity of diamond had proven the death knell of all theories up to this point, and so it is unsurprising that in Einstein's original paper on the topic cantered around measurements of the heat capacity of diamond, which is shown below: Plot A plot of the molar heat capacity of diamond as a function of temperature. The plot is somewhat diabolical in its omission of labels and units, which should read k_\\mathrm{B}T/\\hbar\\omega and C~[\\mathrm{cal}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}] for the x and y axes respectively Data The raw data used to produce the figure of the heat capacity of diamond There are obviously a few discrepancies, but on the whole it looks much better than the Boltzmann model and rightly was seen as a major triumph. But again, the question is why does this happen physically? What is it about diamond that makes is act so strangely? An energy-level diagram for the quantum harmonic oscillator, showing the wavefunctions for the three lowest-energy eigenstates Well if we consider the energy spacing of the harmonic oscillator, \\hbar\\omega , it is related to both the mass ( m ) and the spring constant ( \\kappa ) of the oscillator. For most materials, the Einstein frequency is such that C/N \\approx 3 k_\\mathrm{B} , but diamond has an especially low value of \\omega = \\sqrt{\\kappa/m} , which perhaps is unsurprising given that carbon is light (low m ) and diamond is incredibly hard (large \\kappa ).","title":"Coming up diamonds"},{"location":"01specificheatI/#conclusions","text":"The law of Dulong\u2013Petit is an observation that all materials have C \\approx 3k_B per atom. The Einstein model describes each atom in a solid as an independent quantum harmonic oscillator with the same eigenfrequency \\omega_0 . At sufficiently low T , the thermal excitations freeze out, resulting in \\langle E \\rangle = \\hbar \\omega_0/2 . The Einstein model correctly predicts that the heat capacity drops to 0 as T\\rightarrow 0 .","title":"Conclusions"},{"location":"01specificheatI/#exercises","text":"","title":"Exercises"},{"location":"01specificheatI/#preliminary-provocations","text":"What is the high-temperature heat capacity of an atom in a solid with two momentum and two spatial coordinate degrees of freedom? Sketch the Bose Einstein distribution as a function of \\omega for two different values of T","title":"Preliminary provocations"},{"location":"01specificheatI/#exercise-1-total-heat-capacity-of-a-diatomic-material","text":"One of the assumptions of the Einstein model states that every atom in a solid oscillates with the same frequency \\omega_0 . However, if the solid contains different types of atoms, it is unreasonable to assume that the atoms oscillate with the same frequency. One example of such a solid is a lithium crystal, which consists of the two stable isotopes ^6 Li (7.5%) and ^7 Li (92.5%) in their natural abundance. Let us extend the Einstein model to take into account the different masses of these different isotopes. Assume that the solid is 1D (1D quantum harmonic oscillator). Assume that the strength of the returning force k experienced by each atom is the same. What is the difference in the oscillation frequencies of the two different isotopes in the lithium crystal? Write down the total energy stored in the vibrations of each atom of the lithium crystal, assuming that all ^6 Li atoms are in n=2 vibrational mode and all ^7 Li atoms are in n=4 vibrational mode. In the case where the oscilators can occupy any vibrational mode, write down the total energy stored in the vibrations of each atom in the lithium crystal at a temperature T by modifying the Einstein model. Compute the heat capacity of the lithium crystal as a function of T . The exact value can be found on the NIST database \u21a9 Data is collated in the Heat Capacity of the Elements at 25 ^{\\circ} C as published in the CRC handbook of chemistry of physics , but was sourced from wikipedia \u21a9 Verify this explicitly if it is not obvious: noting the result Z_{3D} = Z_{1D}^3 is a key observation \u21a9","title":"Exercise 1: Total heat capacity of a diatomic material"},{"location":"02specificheatII/","text":"The specific heat of solids II \u00b6 Introduction \u00b6 Previously, we saw how an empirical observation describing the behaviour of the specific heat of solids motivated the development of atomic-scale models of solids in order to understand and predict their behaviour. This marked the beginning of using theories which involved the quantisation of certain observables to accurately predict previously unexplained behaviour, but as we shall see, one must continue down the rabbit hole of quantisation in order to better model physical systems. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Wave mechanics: acoustic waves in solids (sound) Mathematics: periodic boundary conditions, spherical coordinates Text reference The material covered here is discussed in section(s) \\S 2.2 of The Oxford Solid State Basics Shortcomings of the Einstein model \u00b6 The Einstein model did much better than the Boltzmann model at explaining the behaviour of solids outside the regime of k_{\\mathrm{B}} T/\\hbar\\omega \\gg 1 ; however, it would turn out that the model routinely underpredicts the heat capacity as T \\rightarrow 0 . This can be seen in Einstein's plot of diamond , but also in other, better behaved materials. For example shown below is a plot of the heat capacity of silver (and diamond), along with a fit of the data using the Einstein model: The heat capacity of silver and diamond as a function of temperature, with the data fitted to the Einstein model with fitting parameter $\\omega$. Indeed, it was known that at low temperatures, the heat capacity displayed cubic behaviour, that is C \\propto T^3 . Using the provided data ! Link the data ! for the heat capacity of silver, verify the cubic behaviour of the heat capacity at low temperatures. Ensure to include you code. # Import the data from the supplied .csv file data = pd . read_csv ( 'Heat_capacity_Ag.csv' ) data = data [ data [ 'T' ] < 25 ] # take only the low-termperature data # Define the function to fit (a cubic) def cubic ( x , a ): return a * x ** 3 # The range of temperatures over which the fit capity will be calculated temp = np . linspace ( 0 , 25 , 100 ) fit = curve_fit ( cubic , data [ 'T' ], data [ 'C' ]) # perform the fit a_ag = fit [ 0 ][ 0 ] # extract the fit parameter # Make the plot fig , ax = plt . subplots () ax . scatter ( data [ 'T' ], data [ 'C' ], label = 'Silver' , color = 'C1' ) ax . plot ( temp , cubic ( temp , a_ag ), label = f 'Cubic fit' , color = 'C1' ) ax . set_xlabel ( '$T$ [K]' ) ax . set_ylabel ( '$C/k_\\mathrm {B} $' ) ax . set_ylim (( 0 , . 3 )) ax . set_xlim (( 0 , 25 )) ax . set_title ( 'Heat capacity of silver at low temperature' ); ax . legend () plt . savefig ( '02_heat_capacity_cubic.svg' , facecolor = 'white' , transparent = False ) plt . show () The heat capacity of silver at low temperature, T<25~\\mathrm{K} , follows well a cubic relationship in temperature. How does C predicted by the Einstein model behave at low T ? From the Einstein model, we have C = 3k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} which means that as T \\rightarrow 0 , \\beta \\rightarrow \\infty and thus C \\propto \\beta^2/\\exp(\\beta\\hbar\\omega) , which is exponentially small - and definitely not cubic! The Debye model \u00b6 In the years following the development of Einstein's model, with more people delving into the world of quantised oscillators, people were grappling with the links to other areas of physics. A key insight of Peter Debye was that oscillators in a crystal cannot be thought of as isolated identical systems, but rather as a coupled network of oscillators: recognising that oscillations in solids gives rise to sound waves, these waves should be quantised in the same way that Max Plank had done previously for light. Sound wave refresher A sound wave is a collective motion of atoms through a solid. The displacement \\mathbf{\\delta r} of an atom at position \\mathbf{r} and time t is described by \\mathbf{\\delta r} = \\mathbf{\\delta r}_0 e^{i(\\mathbf{k} \\cdot \\mathbf{r}-\\omega t)}, where \\mathbf{\\delta r}_0 is the amplitude of the wave and \\mathbf{k} = (k_x, k_y, k_z) the wave vector . The wavelength \\lambda is related to the wavevector \\mathbf{k} though \\lambda = 2\\pi/|\\mathbf{k}| . The wave depends on time only through the factor e^{-i\\omega t} . Therefore these waves are normal modes : oscillations of a system in which all parts of the system oscillate with the same frequency and fixed phase relation. In addition to direction of the wave k , each sound wave has another degree of freedom: the direction in which the atoms themselves move or the wave polarization . Per wavevector \\mathbf{k} there are three modes in a 3D solid: two transverse (perpendicular to \\mathbf{k} ) and one longitudinal mode (parallel to \\mathbf{k} ). The space containing all possible values of \\mathbf{k} is called the k -space (also named the reciprocal space ). Debye modelled the oscillation modes of a solid as waves with frequency \\omega , which through the dispersion relation is related to the wavevector k , explicitly \\omega(\\mathbf{k}) = v|\\mathbf{k}| where v is the speed of sound in the material. If we then construct a partition function and from this, compute the expectation value of the energy, we arrive at \\langle E \\rangle = 3 \\sum_\\mathbf{k} \\hbar\\omega(\\mathbf{k}) \\left( n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k}))+\\frac{1}{2} \\right) which is very similar to the equivalent expression from Einstein's treatment, other than the sum over wavevectors. It is also interesting to note that the oscillation modes also obey Bose statistics - we shall discuss this more later. From Where does the factor of 3 in the above expression originate? The factor 3 comes from the three possible normal modes of polarization for each wavevector \\mathbf{k} . To reiterate where we are and where we are going: instead of having 3N oscillators with the same frequency \\omega_0 , we now have 3N possible vibrational modes with frequencies depending on \\textbf{k} through the dispersion relation \\omega(\\mathbf{k}) = v_s|\\mathbf{k}| . But the question is now, how do we evaluate the above expression? And there are a few natural questions that arise from what we have done thus far: Don't normal modes depend on the material's shape. What impact does this have on the heat capacity? Which values of \\mathbf{k} are possible? and if all \\mathbf{k} are possible, won't E be infinite? Detour: periodic boundary conditions \u00b6 It is expected that you will have seen periodic boundary conditions in various contexts, mostly likely in studies of differential equations of electromagnetism, but during this course we shall use them regularly. Importantly, we must first establish why we would impose periodic boundary conditions on a system which is not periodic: solids have boundaries! An intuition can be cultivated by considering that C is a macroscopic property : it should not depend on the material's shape and should only be proportional to its volume. Therefore, we can consider making measurements of quantities of interest far from any boundary, and with this, we are free to choose the geometry of material and of course, we pick things that make our life easier! Consider a box of dimension L \\times L \\times L , which then has volume V = L^3 with periodic boundary conditions. These conditions enforce that the atomic displacement \\mathbf{\\delta r} is periodic inside the material. If we consider a translation by L in the x -direction \\mathbf{\\delta r}(\\mathbf{r} + L\\mathbf{\\hat{x}}) = \\mathbf{\\delta r}(\\mathbf{r}) and a wave in this sample \\delta \\mathbf{r_0} e^{i(\\mathbf{k}\\cdot\\mathbf{r}-\\omega t)} must satisfy the above equation, implying \\delta\\mathbf{r_0} e^{i(\\mathbf{k} \\cdot \\mathbf{r}+k_xL-\\omega t)} = \\mathbf{\\delta r}_0 e^{i(\\mathbf{k} \\cdot \\mathbf{r}-\\omega t)} and ultimately e^{i k_x L} = e^{i 0} = 1. This then restricts the possible values of k_x = n_x \\frac{2 \\pi}{L} , for n_x \\in \\mathbb{Z} . Given the same condition holds for the y - and z -direction, the allowed values for \\mathbf{k} are given by \\mathbf{k} = \\frac{2\\pi}{L}(n_x, n_y, n_z), \\quad \\{n_x, n_y, n_z\\} \\in \\mathbb{Z}. A key observation here is that the imposition of periodic boundary conditions results in a discretisation of k -space, where the allowed values of \\mathbf{k} form a regular grid in k -space, and moreover, per volume \\left(\\frac{2\\pi}{L}\\right)^3 in k -space there is exactly one allowed \\mathbf{k} . In the standard way, if we are required to sum over all possible values of \\mathbf{k} and the volume of L is sufficiently large - that is, the volume per allowed mode becomes smaller - we can replace the sum over \\mathbf{k} with an integral \\sum_\\mathbf{k} \\approx \\frac{L^3}{(2\\pi)^3}\\int \\textrm{d} \\textbf{k} Integral over k -space We shall use this result very regularly. The conversion from a sum over the discrete grid of k -space states to a volume integral provides an effective way to count all the possible waves. The density of states \u00b6 Armed with a shiny new tool (wrapping our sample into a hypertorus to make the maths nicer), we can return to evaluating the expectation value \\langle E \\rangle : \\begin{aligned} \\langle E \\rangle & = 3 \\sum_\\mathbf{k} \\hbar\\omega(\\mathbf{k}) \\left( n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k}))+\\frac{1}{2} \\right) \\\\ & = 3 \\frac{L^3}{(2\\pi)^3}\\int \\mathrm{d} \\mathbf{k} \\hbar\\omega(\\mathbf{k}) \\left( n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k}))+\\frac{1}{2} \\right) \\end{aligned} Note that in the above expression, the integrand depends only on \\omega(\\mathbf{k}) \\propto |\\mathbf{k}| , and it is therefore natural to move to spherical coordinates, where the 3-dimensional integral can be collapsed to one dimension since: \\int \\mathrm{d} \\mathbf{k} \\rightarrow 4\\pi\\int_0^\\infty k^2 \\mathrm{d} \\mathbf{k} Spherical coordinate transformation As a refresher, using the coordinate system defined by x = r \\sin(\\theta)\\cos(\\varphi) , y = r \\sin(\\theta)\\sin(\\varphi) , and z = r\\cos(\\theta) , the transformation of the integral can be performed via \\int f(\\mathbf{r}) \\textrm{d} \\textbf{r} \\to \\int\\limits_0^{2\\pi}\\int\\limits_0^{\\pi} \\int\\limits_0^\\infty f(r, \\theta, \\varphi) ~ r^2 \\sin(\\theta) \\textrm{d}r \\textrm{d}\\theta \\textrm{d}\\varphi Performing the change of variables, we obtain the expression for the total energy in spherical coordinates: \\langle E \\rangle = \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ g(\\omega) (\\hbar\\omega) \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + \\frac{1}{2} \\right) where we have introduced g(\\omega) , the density of states g(\\omega) = L^3\\left[\\frac{12\\pi\\omega^2}{(2\\pi)^3 v_s^3} \\right] = n\\left[\\frac{12\\pi\\omega^2}{(2\\pi)^3 n v_s^3} \\right] = N \\frac{9\\omega^2}{\\omega_d^3} and \\omega_d^3 is the Debye frequency \\omega_d^3 = 6\\pi^2 n v_s^3 The (\\hbar\\omega) \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + \\frac{1}{2} \\right) term describes the average energy of an oscillation with frequency \\omega , and g(\\omega) describes the number of modes at the frequency \\omega The density of states Technically, the density of states total is related to number of oscillation modes between frequencies \\omega and \\omega + \\mathrm{d} \\omega via g(\\omega)\\mathrm{d} \\omega It can be convenient to express the density of states in the form g(\\omega) = 3 \\left(\\frac{L}{2\\pi}\\right)^3 \\frac{4\\pi \\omega^2}{v_s^3} which allows for us to see g(\\omega) in terms of its constituent components: 3 comes from the number of possible polarizations in 3D (two transversal, one longitudinal). (\\frac{L}{2\\pi})^3 is the density of \\textbf{k} points in k -space. 4\\pi is the area of a unit sphere. \\omega^2 is due to the area of a sphere in k -space being proportional to its squared radius k^2 and by having a linear dispersion relation \\omega = v_sk . v_s^{-3} is from the linear dispersion relation \\omega = v_sk . So in our case, due to the spherical symmetry, g(\\omega)\\textrm{d} \\omega can be obtained by calculating the density of states of a volume element dV = 4\\pi k^2 dk in k -space and substituting the dispersion relation \\omega(k) . In terms of the calculation of \\langle E \\rangle , we multiply the number of modes g(\\omega) by the average energy of a single mode at a given frequency \\omega and integrate over all frequencies. Low-temperature behaviour \u00b6 In order to calculate a value of C , we must compute C = \\partial \\langle E \\rangle/\\partial T , which means actually computing \\langle E \\rangle . From above we have \\langle E \\rangle = \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ g(\\omega) (\\hbar\\omega) \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + \\frac{1}{2} \\right) which we are going to separate into two components: \\begin{aligned} \\langle E \\rangle & = \\frac{9N\\hbar}{\\omega_d^3} \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ \\frac{\\omega^3}{\\exp(\\beta\\hbar\\omega)-1} + \\frac{9N\\hbar}{\\omega_d^3} \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ \\frac{\\omega^3}{2} \\\\ & = \\frac{9N\\hbar}{\\omega_d^3} \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ \\frac{\\omega^3}{\\exp(\\beta\\hbar\\omega)-1} + \\textrm{ something independent of } T \\end{aligned} The independent component is the zero-point energy E_{ZP} of the vibrational modes, which despite diverging towards infinity, does not contribute to C . One can then make the substitution x =\\beta\\hbar\\omega to transform the above equation into something a little more palatable: \\langle E \\rangle = \\frac{9N\\hbar}{\\omega_d^3 (\\beta\\hbar)^4} \\int\\limits_0^{\\infty}\\mathrm{d} x ~ \\frac{x^3}{\\exp(x)-1} + E_{ZP} which evaluates to \\langle E \\rangle = 9N\\frac{\\left(k_\\mathrm{B} T\\right)^4}{(\\hbar \\omega_d)^3}\\frac{\\pi^4}{15} + E_{ZP} It should not be conspicuous that this result looks similar to Plank's result that E \\propto T^4 for photons. The above result also yields the result that C = \\frac{\\partial \\langle E\\rangle}{\\partial T} = N k_\\mathrm{B} \\frac{(k_\\mathrm{B} T)}{(\\hbar\\omega_d)^3}\\frac{12\\pi^4}{5} \\propto T^3 which produces the desired T^3 dependence, but critically, and unlike the result of Einstein, does not have any free parameters rather only requiring knowledge material density and the sound velocity. What is the physical reason for the difference in the low-temperature behaviour of C for the Einstein and Debye models? In the Einstein model, once the temperature was below the energy associated with the oscillator, there was no capacity for the heat to absorb heat. In contrast, in the Debye model, there exist vibrational modes of the solid do have the capacity to absorb heat. Debye's interpolation (the duct-tape solution) \u00b6 Debye successfully constructed a model which quantised the vibrational modes of solids to accurately predict the low-temperature behaviour of the heat capacity. Unfortunately, the model produces a T^3 dependence for all T , not just low temperature and thus does not recover the Dulong-Petit law at high temperature. Debye understood the problem arose from allowing an infinite number of modes, with an implication that there are more modes of oscillation than atoms in the system. The \"quick fix\" for this - which will be revisited with rigour later in the course - to ensure that there are only as many oscillation modes as there are degrees of freedom is to introduce a cutoff frequency \\omega_{\\textrm{cutoff}} such that the total number of oscillation modes equates to the 3N , the number of normal modes in an 3-dimension material. This manifests in the following way: 3N = \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega) which leads to an altered expression for \\langle E \\rangle : \\langle E \\rangle = \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega)~\\hbar\\omega ~ n_{\\textrm{B}}(\\beta\\hbar\\omega) + E_{ZP} Verify that the expected high-temperature behaviour for C is recovered when using Debye's interpolation For high temperature: n_{\\textrm{B}}(\\beta\\hbar\\omega) = \\frac{1}{\\exp(\\beta\\hbar\\omega)-1} \\to \\frac{k_{\\textrm{B}}T}{\\hbar\\omega} which when put into the expression above (ignoring the zero-point energy) \\langle E \\rangle = k_{\\textrm{B}}T \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega) which by design returns 3 k_{\\textrm{B}} T N , which is exactly the Dulong-Petit law. Explicitly evaluate the cutoff frequency, and express the solution in terms of the Debye frequency An educated guess would probably land you in the correct spot: given the arbitrary definition of the Debye frequency, it is likely that \\omega_{\\textrm{cutoff}} = \\omega_d . Let's have a look: 3N = \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega) = 9N \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ \\frac{\\omega^2}{\\omega_d^3} = 3N \\frac{\\omega_{\\textrm{cutoff}}^3}{\\omega_d^3} That is, \\omega_{\\textrm{cutoff}} = \\omega_d . The question that one must ask: was it worth it? Well, let's look at the Debye model applied to the silver data as shown at the beginning of this section: The heat capacity of silver with fits to both the Einstein and Debye models of solids. Conclusions \u00b6 The Debye model assumes that atoms in materials move in a collective fashion, described by quantized normal modes with a dispersion relation \\omega = v_s|\\mathbf{k}| . The phonon modes have a constant density of (L/2\\pi)^3 in the reciprocal / k -space. The total energy and heat capacity are obtained by integrating the contribution of the individual modes over k -space. The density of states g(\\omega) is the number of states per frequency. With a dispersion relation \u03c9 = v_s|\\mathbf{k}| , g(\\omega) is proportional to \\omega^2 for a 3D bosonic system. At low temperatures the phonon heat capacity is proportional to T^3 . Phonon modes only exist up until the Debye frequency \\omega_D , after which there are no modes in the system. Exercises \u00b6 Preliminary provocations \u00b6 Why are there only 3 polarizations when there are 6 degrees of freedom in three-dimensions for an oscillator? Express the two-dimensional integral \\int\\mathrm{d}k_x\\mathrm{d}k_y in terms of polar coordinates. You can assume rotational symmetry. The Einstein model has a material-dependent frequency \\omega_0 = k_\\mathrm{B} T_E/\\hbar of the quantum harmonic oscillators as a free fitting parameter. What is the material-dependent parameter that plays a similar role in the Debye model? Derive an expression for the shortest possible wavelength in the Debye model it in terms of the interatomic distance a . Hint: assume that the number of atoms is given by N=V/a^3 . Discuss if the answer is reasonable. Exercise 1: Debye model: concepts \u00b6 Consider the probability to find an atom of a 1D solid that originally had a position x at a displacement \\delta x shown below: Describe which k -states are occupied. Explain your answer. Hint There are two k -states which contain a phonon. Describe the concept of k -space. What momenta are allowed in a 2D system with dimensions L\\times L ? Explain the concept of density of states. Calculate the phonon density of states g(\\omega) of a 3D, 2D and 1D solid with linear dispersion \\omega=v_s|\\mathbf{k}| . Exercise 2: Debye model in 2D \u00b6 State the assumptions of the Debye model. Determine the energy of a two-dimensional solid as a function of T using the Debye approximation. You do not have to solve the integral. Calculate the heat capacity in the high T limit. At low T , show that C_V=KT^{n} . Find n . Express K as an indefinite integral (similarly to what done during the lecture)[^3]. Exercise 3: Different phonon modes \u00b6 (adapted from ex 2.6a of \"The Oxford Solid State Basics\" by S.Simon) During the lecture we derived the low-temperature heat capacity assuming that all the phonons have the same sound velocity v . In reality the longitudinal and transverse modes have different sound velocities (see Wikipedia for an illustration of different sound wave types). Assume that there are two types of excitations: One longitudinal mode with \\omega = v_\\parallel |k| Two transverse modes with \\omega = v_\\bot |k| Write down the total energy of phonons in this material (hint: use the same reasoning as in the Lithium exercise ) . Verify that at high T you reproduce the Dulong-Petit law. Compute the behavior of heat capacity at low T . Exercise 4: Anisotropic sound velocities \u00b6 (adapted from ex 2.6b of \"The Oxford Solid State Basics\" by S.Simon) Suppose now that the velocity is anisotropic ( v_x \\neq v_y \\neq v_z ) and \\omega = \\sqrt{v_x^2 k_x^2 + v_y^2 k_y^2 + v_z^2 k_z^2} . How does this change the Debye result for the heat capacity? Hint Write down the total energy as an integral over k , then change the integration variables so that the spherical symmetry of the integrand is restored.","title":"The specific heat of solids II"},{"location":"02specificheatII/#the-specific-heat-of-solids-ii","text":"","title":"The specific heat of solids II"},{"location":"02specificheatII/#introduction","text":"Previously, we saw how an empirical observation describing the behaviour of the specific heat of solids motivated the development of atomic-scale models of solids in order to understand and predict their behaviour. This marked the beginning of using theories which involved the quantisation of certain observables to accurately predict previously unexplained behaviour, but as we shall see, one must continue down the rabbit hole of quantisation in order to better model physical systems. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Wave mechanics: acoustic waves in solids (sound) Mathematics: periodic boundary conditions, spherical coordinates Text reference The material covered here is discussed in section(s) \\S 2.2 of The Oxford Solid State Basics","title":"Introduction"},{"location":"02specificheatII/#shortcomings-of-the-einstein-model","text":"The Einstein model did much better than the Boltzmann model at explaining the behaviour of solids outside the regime of k_{\\mathrm{B}} T/\\hbar\\omega \\gg 1 ; however, it would turn out that the model routinely underpredicts the heat capacity as T \\rightarrow 0 . This can be seen in Einstein's plot of diamond , but also in other, better behaved materials. For example shown below is a plot of the heat capacity of silver (and diamond), along with a fit of the data using the Einstein model: The heat capacity of silver and diamond as a function of temperature, with the data fitted to the Einstein model with fitting parameter $\\omega$. Indeed, it was known that at low temperatures, the heat capacity displayed cubic behaviour, that is C \\propto T^3 . Using the provided data ! Link the data ! for the heat capacity of silver, verify the cubic behaviour of the heat capacity at low temperatures. Ensure to include you code. # Import the data from the supplied .csv file data = pd . read_csv ( 'Heat_capacity_Ag.csv' ) data = data [ data [ 'T' ] < 25 ] # take only the low-termperature data # Define the function to fit (a cubic) def cubic ( x , a ): return a * x ** 3 # The range of temperatures over which the fit capity will be calculated temp = np . linspace ( 0 , 25 , 100 ) fit = curve_fit ( cubic , data [ 'T' ], data [ 'C' ]) # perform the fit a_ag = fit [ 0 ][ 0 ] # extract the fit parameter # Make the plot fig , ax = plt . subplots () ax . scatter ( data [ 'T' ], data [ 'C' ], label = 'Silver' , color = 'C1' ) ax . plot ( temp , cubic ( temp , a_ag ), label = f 'Cubic fit' , color = 'C1' ) ax . set_xlabel ( '$T$ [K]' ) ax . set_ylabel ( '$C/k_\\mathrm {B} $' ) ax . set_ylim (( 0 , . 3 )) ax . set_xlim (( 0 , 25 )) ax . set_title ( 'Heat capacity of silver at low temperature' ); ax . legend () plt . savefig ( '02_heat_capacity_cubic.svg' , facecolor = 'white' , transparent = False ) plt . show () The heat capacity of silver at low temperature, T<25~\\mathrm{K} , follows well a cubic relationship in temperature. How does C predicted by the Einstein model behave at low T ? From the Einstein model, we have C = 3k_{\\mathrm{B}}(\\beta\\hbar\\omega)^2\\frac{\\exp(\\beta\\hbar\\omega)}{(\\exp(\\beta\\hbar\\omega)-1)^2} which means that as T \\rightarrow 0 , \\beta \\rightarrow \\infty and thus C \\propto \\beta^2/\\exp(\\beta\\hbar\\omega) , which is exponentially small - and definitely not cubic!","title":"Shortcomings of the Einstein model"},{"location":"02specificheatII/#the-debye-model","text":"In the years following the development of Einstein's model, with more people delving into the world of quantised oscillators, people were grappling with the links to other areas of physics. A key insight of Peter Debye was that oscillators in a crystal cannot be thought of as isolated identical systems, but rather as a coupled network of oscillators: recognising that oscillations in solids gives rise to sound waves, these waves should be quantised in the same way that Max Plank had done previously for light. Sound wave refresher A sound wave is a collective motion of atoms through a solid. The displacement \\mathbf{\\delta r} of an atom at position \\mathbf{r} and time t is described by \\mathbf{\\delta r} = \\mathbf{\\delta r}_0 e^{i(\\mathbf{k} \\cdot \\mathbf{r}-\\omega t)}, where \\mathbf{\\delta r}_0 is the amplitude of the wave and \\mathbf{k} = (k_x, k_y, k_z) the wave vector . The wavelength \\lambda is related to the wavevector \\mathbf{k} though \\lambda = 2\\pi/|\\mathbf{k}| . The wave depends on time only through the factor e^{-i\\omega t} . Therefore these waves are normal modes : oscillations of a system in which all parts of the system oscillate with the same frequency and fixed phase relation. In addition to direction of the wave k , each sound wave has another degree of freedom: the direction in which the atoms themselves move or the wave polarization . Per wavevector \\mathbf{k} there are three modes in a 3D solid: two transverse (perpendicular to \\mathbf{k} ) and one longitudinal mode (parallel to \\mathbf{k} ). The space containing all possible values of \\mathbf{k} is called the k -space (also named the reciprocal space ). Debye modelled the oscillation modes of a solid as waves with frequency \\omega , which through the dispersion relation is related to the wavevector k , explicitly \\omega(\\mathbf{k}) = v|\\mathbf{k}| where v is the speed of sound in the material. If we then construct a partition function and from this, compute the expectation value of the energy, we arrive at \\langle E \\rangle = 3 \\sum_\\mathbf{k} \\hbar\\omega(\\mathbf{k}) \\left( n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k}))+\\frac{1}{2} \\right) which is very similar to the equivalent expression from Einstein's treatment, other than the sum over wavevectors. It is also interesting to note that the oscillation modes also obey Bose statistics - we shall discuss this more later. From Where does the factor of 3 in the above expression originate? The factor 3 comes from the three possible normal modes of polarization for each wavevector \\mathbf{k} . To reiterate where we are and where we are going: instead of having 3N oscillators with the same frequency \\omega_0 , we now have 3N possible vibrational modes with frequencies depending on \\textbf{k} through the dispersion relation \\omega(\\mathbf{k}) = v_s|\\mathbf{k}| . But the question is now, how do we evaluate the above expression? And there are a few natural questions that arise from what we have done thus far: Don't normal modes depend on the material's shape. What impact does this have on the heat capacity? Which values of \\mathbf{k} are possible? and if all \\mathbf{k} are possible, won't E be infinite?","title":"The Debye model"},{"location":"02specificheatII/#detour-periodic-boundary-conditions","text":"It is expected that you will have seen periodic boundary conditions in various contexts, mostly likely in studies of differential equations of electromagnetism, but during this course we shall use them regularly. Importantly, we must first establish why we would impose periodic boundary conditions on a system which is not periodic: solids have boundaries! An intuition can be cultivated by considering that C is a macroscopic property : it should not depend on the material's shape and should only be proportional to its volume. Therefore, we can consider making measurements of quantities of interest far from any boundary, and with this, we are free to choose the geometry of material and of course, we pick things that make our life easier! Consider a box of dimension L \\times L \\times L , which then has volume V = L^3 with periodic boundary conditions. These conditions enforce that the atomic displacement \\mathbf{\\delta r} is periodic inside the material. If we consider a translation by L in the x -direction \\mathbf{\\delta r}(\\mathbf{r} + L\\mathbf{\\hat{x}}) = \\mathbf{\\delta r}(\\mathbf{r}) and a wave in this sample \\delta \\mathbf{r_0} e^{i(\\mathbf{k}\\cdot\\mathbf{r}-\\omega t)} must satisfy the above equation, implying \\delta\\mathbf{r_0} e^{i(\\mathbf{k} \\cdot \\mathbf{r}+k_xL-\\omega t)} = \\mathbf{\\delta r}_0 e^{i(\\mathbf{k} \\cdot \\mathbf{r}-\\omega t)} and ultimately e^{i k_x L} = e^{i 0} = 1. This then restricts the possible values of k_x = n_x \\frac{2 \\pi}{L} , for n_x \\in \\mathbb{Z} . Given the same condition holds for the y - and z -direction, the allowed values for \\mathbf{k} are given by \\mathbf{k} = \\frac{2\\pi}{L}(n_x, n_y, n_z), \\quad \\{n_x, n_y, n_z\\} \\in \\mathbb{Z}. A key observation here is that the imposition of periodic boundary conditions results in a discretisation of k -space, where the allowed values of \\mathbf{k} form a regular grid in k -space, and moreover, per volume \\left(\\frac{2\\pi}{L}\\right)^3 in k -space there is exactly one allowed \\mathbf{k} . In the standard way, if we are required to sum over all possible values of \\mathbf{k} and the volume of L is sufficiently large - that is, the volume per allowed mode becomes smaller - we can replace the sum over \\mathbf{k} with an integral \\sum_\\mathbf{k} \\approx \\frac{L^3}{(2\\pi)^3}\\int \\textrm{d} \\textbf{k} Integral over k -space We shall use this result very regularly. The conversion from a sum over the discrete grid of k -space states to a volume integral provides an effective way to count all the possible waves.","title":"Detour: periodic boundary conditions"},{"location":"02specificheatII/#the-density-of-states","text":"Armed with a shiny new tool (wrapping our sample into a hypertorus to make the maths nicer), we can return to evaluating the expectation value \\langle E \\rangle : \\begin{aligned} \\langle E \\rangle & = 3 \\sum_\\mathbf{k} \\hbar\\omega(\\mathbf{k}) \\left( n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k}))+\\frac{1}{2} \\right) \\\\ & = 3 \\frac{L^3}{(2\\pi)^3}\\int \\mathrm{d} \\mathbf{k} \\hbar\\omega(\\mathbf{k}) \\left( n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k}))+\\frac{1}{2} \\right) \\end{aligned} Note that in the above expression, the integrand depends only on \\omega(\\mathbf{k}) \\propto |\\mathbf{k}| , and it is therefore natural to move to spherical coordinates, where the 3-dimensional integral can be collapsed to one dimension since: \\int \\mathrm{d} \\mathbf{k} \\rightarrow 4\\pi\\int_0^\\infty k^2 \\mathrm{d} \\mathbf{k} Spherical coordinate transformation As a refresher, using the coordinate system defined by x = r \\sin(\\theta)\\cos(\\varphi) , y = r \\sin(\\theta)\\sin(\\varphi) , and z = r\\cos(\\theta) , the transformation of the integral can be performed via \\int f(\\mathbf{r}) \\textrm{d} \\textbf{r} \\to \\int\\limits_0^{2\\pi}\\int\\limits_0^{\\pi} \\int\\limits_0^\\infty f(r, \\theta, \\varphi) ~ r^2 \\sin(\\theta) \\textrm{d}r \\textrm{d}\\theta \\textrm{d}\\varphi Performing the change of variables, we obtain the expression for the total energy in spherical coordinates: \\langle E \\rangle = \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ g(\\omega) (\\hbar\\omega) \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + \\frac{1}{2} \\right) where we have introduced g(\\omega) , the density of states g(\\omega) = L^3\\left[\\frac{12\\pi\\omega^2}{(2\\pi)^3 v_s^3} \\right] = n\\left[\\frac{12\\pi\\omega^2}{(2\\pi)^3 n v_s^3} \\right] = N \\frac{9\\omega^2}{\\omega_d^3} and \\omega_d^3 is the Debye frequency \\omega_d^3 = 6\\pi^2 n v_s^3 The (\\hbar\\omega) \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + \\frac{1}{2} \\right) term describes the average energy of an oscillation with frequency \\omega , and g(\\omega) describes the number of modes at the frequency \\omega The density of states Technically, the density of states total is related to number of oscillation modes between frequencies \\omega and \\omega + \\mathrm{d} \\omega via g(\\omega)\\mathrm{d} \\omega It can be convenient to express the density of states in the form g(\\omega) = 3 \\left(\\frac{L}{2\\pi}\\right)^3 \\frac{4\\pi \\omega^2}{v_s^3} which allows for us to see g(\\omega) in terms of its constituent components: 3 comes from the number of possible polarizations in 3D (two transversal, one longitudinal). (\\frac{L}{2\\pi})^3 is the density of \\textbf{k} points in k -space. 4\\pi is the area of a unit sphere. \\omega^2 is due to the area of a sphere in k -space being proportional to its squared radius k^2 and by having a linear dispersion relation \\omega = v_sk . v_s^{-3} is from the linear dispersion relation \\omega = v_sk . So in our case, due to the spherical symmetry, g(\\omega)\\textrm{d} \\omega can be obtained by calculating the density of states of a volume element dV = 4\\pi k^2 dk in k -space and substituting the dispersion relation \\omega(k) . In terms of the calculation of \\langle E \\rangle , we multiply the number of modes g(\\omega) by the average energy of a single mode at a given frequency \\omega and integrate over all frequencies.","title":"The density of states"},{"location":"02specificheatII/#low-temperature-behaviour","text":"In order to calculate a value of C , we must compute C = \\partial \\langle E \\rangle/\\partial T , which means actually computing \\langle E \\rangle . From above we have \\langle E \\rangle = \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ g(\\omega) (\\hbar\\omega) \\left(n_\\mathrm{B}(\\beta\\hbar\\omega) + \\frac{1}{2} \\right) which we are going to separate into two components: \\begin{aligned} \\langle E \\rangle & = \\frac{9N\\hbar}{\\omega_d^3} \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ \\frac{\\omega^3}{\\exp(\\beta\\hbar\\omega)-1} + \\frac{9N\\hbar}{\\omega_d^3} \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ \\frac{\\omega^3}{2} \\\\ & = \\frac{9N\\hbar}{\\omega_d^3} \\int\\limits_0^{\\infty}\\textrm{d} \\omega ~ \\frac{\\omega^3}{\\exp(\\beta\\hbar\\omega)-1} + \\textrm{ something independent of } T \\end{aligned} The independent component is the zero-point energy E_{ZP} of the vibrational modes, which despite diverging towards infinity, does not contribute to C . One can then make the substitution x =\\beta\\hbar\\omega to transform the above equation into something a little more palatable: \\langle E \\rangle = \\frac{9N\\hbar}{\\omega_d^3 (\\beta\\hbar)^4} \\int\\limits_0^{\\infty}\\mathrm{d} x ~ \\frac{x^3}{\\exp(x)-1} + E_{ZP} which evaluates to \\langle E \\rangle = 9N\\frac{\\left(k_\\mathrm{B} T\\right)^4}{(\\hbar \\omega_d)^3}\\frac{\\pi^4}{15} + E_{ZP} It should not be conspicuous that this result looks similar to Plank's result that E \\propto T^4 for photons. The above result also yields the result that C = \\frac{\\partial \\langle E\\rangle}{\\partial T} = N k_\\mathrm{B} \\frac{(k_\\mathrm{B} T)}{(\\hbar\\omega_d)^3}\\frac{12\\pi^4}{5} \\propto T^3 which produces the desired T^3 dependence, but critically, and unlike the result of Einstein, does not have any free parameters rather only requiring knowledge material density and the sound velocity. What is the physical reason for the difference in the low-temperature behaviour of C for the Einstein and Debye models? In the Einstein model, once the temperature was below the energy associated with the oscillator, there was no capacity for the heat to absorb heat. In contrast, in the Debye model, there exist vibrational modes of the solid do have the capacity to absorb heat.","title":"Low-temperature behaviour"},{"location":"02specificheatII/#debyes-interpolation-the-duct-tape-solution","text":"Debye successfully constructed a model which quantised the vibrational modes of solids to accurately predict the low-temperature behaviour of the heat capacity. Unfortunately, the model produces a T^3 dependence for all T , not just low temperature and thus does not recover the Dulong-Petit law at high temperature. Debye understood the problem arose from allowing an infinite number of modes, with an implication that there are more modes of oscillation than atoms in the system. The \"quick fix\" for this - which will be revisited with rigour later in the course - to ensure that there are only as many oscillation modes as there are degrees of freedom is to introduce a cutoff frequency \\omega_{\\textrm{cutoff}} such that the total number of oscillation modes equates to the 3N , the number of normal modes in an 3-dimension material. This manifests in the following way: 3N = \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega) which leads to an altered expression for \\langle E \\rangle : \\langle E \\rangle = \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega)~\\hbar\\omega ~ n_{\\textrm{B}}(\\beta\\hbar\\omega) + E_{ZP} Verify that the expected high-temperature behaviour for C is recovered when using Debye's interpolation For high temperature: n_{\\textrm{B}}(\\beta\\hbar\\omega) = \\frac{1}{\\exp(\\beta\\hbar\\omega)-1} \\to \\frac{k_{\\textrm{B}}T}{\\hbar\\omega} which when put into the expression above (ignoring the zero-point energy) \\langle E \\rangle = k_{\\textrm{B}}T \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega) which by design returns 3 k_{\\textrm{B}} T N , which is exactly the Dulong-Petit law. Explicitly evaluate the cutoff frequency, and express the solution in terms of the Debye frequency An educated guess would probably land you in the correct spot: given the arbitrary definition of the Debye frequency, it is likely that \\omega_{\\textrm{cutoff}} = \\omega_d . Let's have a look: 3N = \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ g(\\omega) = 9N \\int_0^{\\omega_{\\textrm{cutoff}}} \\textrm{d} \\omega ~ \\frac{\\omega^2}{\\omega_d^3} = 3N \\frac{\\omega_{\\textrm{cutoff}}^3}{\\omega_d^3} That is, \\omega_{\\textrm{cutoff}} = \\omega_d . The question that one must ask: was it worth it? Well, let's look at the Debye model applied to the silver data as shown at the beginning of this section: The heat capacity of silver with fits to both the Einstein and Debye models of solids.","title":"Debye's interpolation (the duct-tape solution)"},{"location":"02specificheatII/#conclusions","text":"The Debye model assumes that atoms in materials move in a collective fashion, described by quantized normal modes with a dispersion relation \\omega = v_s|\\mathbf{k}| . The phonon modes have a constant density of (L/2\\pi)^3 in the reciprocal / k -space. The total energy and heat capacity are obtained by integrating the contribution of the individual modes over k -space. The density of states g(\\omega) is the number of states per frequency. With a dispersion relation \u03c9 = v_s|\\mathbf{k}| , g(\\omega) is proportional to \\omega^2 for a 3D bosonic system. At low temperatures the phonon heat capacity is proportional to T^3 . Phonon modes only exist up until the Debye frequency \\omega_D , after which there are no modes in the system.","title":"Conclusions"},{"location":"02specificheatII/#exercises","text":"","title":"Exercises"},{"location":"02specificheatII/#preliminary-provocations","text":"Why are there only 3 polarizations when there are 6 degrees of freedom in three-dimensions for an oscillator? Express the two-dimensional integral \\int\\mathrm{d}k_x\\mathrm{d}k_y in terms of polar coordinates. You can assume rotational symmetry. The Einstein model has a material-dependent frequency \\omega_0 = k_\\mathrm{B} T_E/\\hbar of the quantum harmonic oscillators as a free fitting parameter. What is the material-dependent parameter that plays a similar role in the Debye model? Derive an expression for the shortest possible wavelength in the Debye model it in terms of the interatomic distance a . Hint: assume that the number of atoms is given by N=V/a^3 . Discuss if the answer is reasonable.","title":"Preliminary provocations"},{"location":"02specificheatII/#exercise-1-debye-model-concepts","text":"Consider the probability to find an atom of a 1D solid that originally had a position x at a displacement \\delta x shown below: Describe which k -states are occupied. Explain your answer. Hint There are two k -states which contain a phonon. Describe the concept of k -space. What momenta are allowed in a 2D system with dimensions L\\times L ? Explain the concept of density of states. Calculate the phonon density of states g(\\omega) of a 3D, 2D and 1D solid with linear dispersion \\omega=v_s|\\mathbf{k}| .","title":"Exercise 1: Debye model: concepts"},{"location":"02specificheatII/#exercise-2-debye-model-in-2d","text":"State the assumptions of the Debye model. Determine the energy of a two-dimensional solid as a function of T using the Debye approximation. You do not have to solve the integral. Calculate the heat capacity in the high T limit. At low T , show that C_V=KT^{n} . Find n . Express K as an indefinite integral (similarly to what done during the lecture)[^3].","title":"Exercise 2: Debye model in 2D"},{"location":"02specificheatII/#exercise-3-different-phonon-modes","text":"(adapted from ex 2.6a of \"The Oxford Solid State Basics\" by S.Simon) During the lecture we derived the low-temperature heat capacity assuming that all the phonons have the same sound velocity v . In reality the longitudinal and transverse modes have different sound velocities (see Wikipedia for an illustration of different sound wave types). Assume that there are two types of excitations: One longitudinal mode with \\omega = v_\\parallel |k| Two transverse modes with \\omega = v_\\bot |k| Write down the total energy of phonons in this material (hint: use the same reasoning as in the Lithium exercise ) . Verify that at high T you reproduce the Dulong-Petit law. Compute the behavior of heat capacity at low T .","title":"Exercise 3: Different phonon modes"},{"location":"02specificheatII/#exercise-4-anisotropic-sound-velocities","text":"(adapted from ex 2.6b of \"The Oxford Solid State Basics\" by S.Simon) Suppose now that the velocity is anisotropic ( v_x \\neq v_y \\neq v_z ) and \\omega = \\sqrt{v_x^2 k_x^2 + v_y^2 k_y^2 + v_z^2 k_z^2} . How does this change the Debye result for the heat capacity? Hint Write down the total energy as an integral over k , then change the integration variables so that the spherical symmetry of the integrand is restored.","title":"Exercise 4: Anisotropic sound velocities"},{"location":"03emetalsI/","text":"Electrons in metals I \u00b6 Introduction \u00b6 Metals are awesome, and this has long been known. People have been drawn to their shininess since the first chunks of the stuff were found, and it mustn't have been long before it was realised that they were different to other materials. To nail down exactly what is the difference would take some time (of order 10,000 years!) but it boils down to metals being conductive, and this comes from the ability of electrons in the material to move more freely. It turns out that one can apply a somewhat crude kinetic theory to understand the transport of electrons in metals, in the same way kinetic theory can be used to understand the transport of gasses. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Electromagnetism: The influence of fields of charged particles Mechanics: Construct and solve equations of motion Thermal physics: Kinetic theory of gases Text reference The material covered here is discussed in section(s) \\S 3 of The Oxford Solid State Basics The kinetic theory of gases electrons \u00b6 Ohm's law is an empirical observation of conductors, which states that voltage is proportional to current V=IR . Since we are interested in the properties of materials, we would like to express this in a relation that does not depend on the conductor geometry. We achieve this by expressing the terms in Ohm's law with their microscopic equivalents. Consider a conducting wire with cross-sectional area A and length l . Such a wire has resistance R = \\rho l / A where \\rho is the material-dependent resistivity. An applied voltage V in the wire creates an electric field E = V/l . The resulting current I in the wire is described by the current density j \\equiv I / A . Returning these relations to Ohm's law, we get: V = I \u03c1 \\frac{l}{A} \u21d2 E = \u03c1 j, which relates the local quantities E and j . Our mission is to understand how this relation arises by considering motion of individual electrons in metals. This path was first trodden by Drude, who applied Boltzmann's kinetic theory of gases to a \"gas\" of electrons. The assumptions of Boltzmann's kinetic theory are that: Electrons scatter randomly at uncorrelated times. The average time between scattering is \\tau . Therefore, the probability of scattering in a time interval dt is dt / \\tau After each scattering event, the electron's momentum randomizes with a zero average \u27e8\\mathbf{p}\u27e9=0 It is also important to bake in the difference between neutral atoms or molecules in a gas and electrons, namely: Electrons are charged particles with charge -e , and consequently they respond to electric and magnetic fields through the Lorentz force ( \\mathbf{F}=-e\\left(\\mathbf{E}+\\mathbf{v}\u00d7\\mathbf{B}\\right) ) Even under these simplistic assumptions, the trajectory of the electrons is hard to calculate. As you will have seen elsewhere, with random scattering events, each trajectory is very different. A simple animation below shows several example trajectories, which are markedly different: Equations of motion \u00b6 Keep in your mind that our goal is to find electric current density j . Each electron with charge -e and velocity \\mathbf{v} carries current -e\\mathbf{v} . Therefore, if the electron density is n , the average current they carry is -ne\u27e8\\mathbf{v}\u27e9 . Thus, our goal shifts to compute the average velocity. Underpinning this calculation is idea that although it is difficult to calculate the motion of an individual electron, computing the average motion of the electrons is a much more tractable task. For convenience from now on, we will omit the average brackets, and write \\mathbf{v} instead of \u27e8\\mathbf{v}\u27e9 . This also applies to F . We derive an equation of motion for the \"average\" electron in the following way: Consider everything that happens in an (infinitesimal) time interval dt . A fraction dt/\u03c4 of the electrons scatters, and their average velocity becomes zero. m\\mathbf{v}(t + dt) = 0 The rest of the electrons (1 - dt/\u03c4) are accelerated by the Lorentz force F , so their velocity becomes m\\mathbf{v}(t + dt) = m\\mathbf{v}(t) + \\mathbf{F}\u22c5dt. To find the average velocity, we take a weighted average of these two groups of particles: \\begin{aligned} m\\mathbf{v}(t+dt) &= [m\\mathbf{v}(t) + F dt]\\left(1 - \\frac{dt}{\\tau}\\right) + 0\u22c5\\frac{dt}{\\tau} \\\\ &= [m\\mathbf{v}(t) + \\mathbf{F} dt] \\left(1 - \\frac{dt}{\\tau}\\right) \\\\ &= m\\mathbf{v}(t) + dt [\\mathbf{F} - m\\frac{\\mathbf{v(t)}}{\\tau}] - \\frac{\\mathbf{F}}{\\tau} dt^2 \\end{aligned} We now neglect the term proportional to dt\u00b2 (it vanishes when dt \u2192 0 ). Finally, we recognize that \\left[\\mathbf{v}(t+dt) - \\mathbf{v}(t)\\right]/dt = d\\mathbf{v}(t)/dt , which results in m\\frac{d\\mathbf{v}}{dt} = -m\\frac{\\mathbf{v}}{\u03c4} + \\mathbf{F}. Observe that the first term on the right-hand side has the same form as a drag force: it always decelerates the electrons. This equation equation of motion of the average electron is our main result: now we only need to apply it. Consequences of the Drude model \u00b6 Let us first consider the case without magnetic fields, \\mathbf{B} = 0 , and with constant electric field \\mathbf{E} . For many properties of interest, we are interested in the steady-state behaviour of the system, i.e. d\\mathbf{v}/dt = 0 , which upon solving the equation of motion yields: \\mathbf{v}=\\frac{-e\u03c4}{m}\\mathbf{E}=-|\u03bc|\\mathbf{E}. In the above equation, we define the mobility \u03bc\\equiv |e|\u03c4/m to be the ratio between the electron drift velocity and the electric field. The mobility is an extremely important quantity: it describes the response of the electron to an electric field. We can then substitute the steady-state velocity into the definition of current density: \\mathbf{j}=-en\\mathbf{v}=\\frac{n e^2\u03c4}{m}\\mathbf{E}=\\sigma\\mathbf{E} where \\sigma is the conductivity \\sigma=\\frac{ne^2\u03c4}{m}=ne\\mu such that \u03c1=1/\\sigma . The Hall effect \u00b6 Let us now consider the case where both and electric field \\mathbf{E} and magnetic field \\mathbf{B} are non-zero. Imagine a conductor with a current I flowing perpendicular to an external magnetic field \\mathbf{B} as shown below: Looking at the equations of motion: m\\frac{d\\mathbf{v}}{dt} = -m\\frac{\\mathbf{v}}{\u03c4} - e(\\mathbf{E} + \\mathbf{v}\\times\\mathbf{B}) we once again consider the steady state d\\mathbf{v}/dt = 0 . After substituting \\mathbf{v} = -\\mathbf{j}/ne , we arrive at \\mathbf{E}=\\frac{m}{ne^2\u03c4}\\mathbf{j} + \\frac{1}{ne}\\mathbf{j}\\times\\mathbf{B}. The first term is the same as before and describes the electric field parallel to the current, while the second is the electric field perpendicular to the current flow. In other words, if we send a current through a sample and apply a magnetic field, a voltage develops in the direction perpendicular to the current. This phenomenon is known as the Hall effect , with the perpendicular voltage called the Hall voltage , and the proportionality coefficient B/ne the Hall resistivity . Because of the Lorentz force, the electrons are deflected in a direction perpendicular to \\mathbf{B} and \\mathbf{j} . The deflection creates a charge imbalance, which in turn creates the electric field \\mathbf{E}_\\mathrm{H} compensating the Lorentz force. The above relation between the electric field and the current is linear, which allows us to write it in matrix form \\mathbf{E} = \\bar{\\rho} \\mathbf{j} where \\bar{\\rho} the resistivity matrix . Its diagonal elements are \\rho_{xx}=\\rho_{yy}=\\rho_{zz}=m/ne^2\\tau , which is the same as without magnetic field. The only nonzero off-diagonal elements when \\mathbf{B} points in the z -direction are \u03c1_{xy}=-\u03c1_{yx}=\\frac{B}{ne}\\equiv -R_\\mathrm{H}B, where R_H=-1/ne is the Hall coefficient . So by measuring the Hall voltage and knowing the electron charge, we can determine the density of free electrons in a material. While most materials have R_\\mathrm{H}<0 , interestingly some materials are found to have R_\\mathrm{H}>0 . What would be the implications of a negative hall coefficient? With the density is negative, or that the charge carrier has a positive charge and thus not an electron. Thermal transport \u00b6 Given that Drude had cobbled together a kinetic theory for electrons, he decided that it was worthwhile to keep going, and make predictions about the properties of the \"gas\" in the same way as Boltzmann. Thermal conductivity \u00b6 Explicitly, Boltzmann derived the thermal conductivity \\kappa : \\kappa = \\frac{1}{3}n c_v \\langle v \\rangle \\lambda where c_v is the heat capacity per particle, \\langle v \\rangle is the average thermal velocity and \\lambda = \\langle v \\rangle \\tau is the scattering length. For a monatomic gas c_v = \\frac{3}{2} k_{\\mathrm{B}} and \\langle v \\rangle = \\sqrt{\\frac{8 k_{\\mathrm{B}} T}{\\pi m}} Without any grounds for justification, we can just give these a whirl and see how they go for electrons: \\kappa = \\frac{4}{\\pi}\\frac{n \\tau k_{\\mathrm{B}} T}{m} which still holds the phenomenological scattering rate \\tau , meaning makes independent measurement impossible. However, the conductivity \\sigma also contains \\tau , so by measuring their ratio we can eliminate the dependence and define the Lorenz number: L = \\frac{\\kappa}{T\\sigma} = \\frac{4}{\\pi}\\left(\\frac{k_{\\mathrm{B}}}{e}\\right) \\approx 1 \\times 10^{-8}~\\mathrm{W\\Omega~K^{-2}} which was close to the measured values of the Lorenz number (within a factor of 2 or so), and given there had never been any explanation at all for this behaviour, this result served was hailed as a major accomplishment. The Peltier effect \u00b6 A stack of peltier (thermoelectric cooling) devices can be used for highly-effective heat transfer Aside from being amazingly cool, we look at the Peltier effect to see that whilst the model well predicts the Lorenz number, this is actually somewhat of a fluke. The Peltier effect arises when a current flows through a material, as that current necessarily transports heat. The Peltier coefficient is defined by \\mathbf{j}^q = \\Pi \\mathbf{j} Where \\mathbf{j}^q is the heat current density and \\mathbf{j} is the electrical current density. In kinetic theory, the thermal current is \\mathbf{j}^q = \\frac{1}{3} (c_v T) n \\mathbf{v} where c_v T is the heat carried by one particle and c_v = 3 k_{\\mathrm{B}}/2 the heat capacity per particle, n the density of particles, and the factor of 1/3 from geometry. The electric current is \\mathbf{j} = -en\\mathbf{v} and thus \\Pi = \\frac{-c_v T}{3 e} = \\frac{-k_\\mathrm{B} T}{2 e} which yield the temperature independent ratio S = \\frac{\\Pi}{T} = \\frac{-k_{\\textrm{B}}}{2e} = -4.3 \\times 10^{-4} \\mathrm{V/K} where S is Seebeck coefficient (also the thermopower). And how well does this agree? Well, unlike \\kappa which was only a factor of 2 from the measure values, most values of S are on the order of 10^{-6} \\mathrm{V/K} . So unfortunately, whilst the Drude model gives us a \"broad brushstrokes\" picture of what is happening in a metal, it fails to accurately predict the specific behaviour and the quantities about which we care. Conclusions \u00b6 Drude theory is a kinetic theory and microscopic justification of the Ohm's law. We can calculate the resistivity from the characteristic scattering time \\tau . The Lorentz force leads to the Hall voltage that is perpendicular to the direction of both the electric current and the magnetic field. Drude theory does some things well, but ultimately falls short. Exercises \u00b6 Preliminary provocations \u00b6 How does the resistance of a purely 2D material depend on its size? Check that the units of mobility and the Hall coefficient are correct. (As you should always do!) Explain why the scattering times due to different types of scattering events add up in a reciprocal way. Exercise 1: Extracting quantities from basic Hall measurements \u00b6 We apply a magnetic field \\bf B along the z -direction to a planar (two-dimensional) sample that sits in the xy plane. The sample has width W in the y -direction, length L in the x -direction and we apply a current I along the x -direction. What is the relation between the electric field and the electric potential? V_b - V_a = -\\int_{\\Gamma} \\mathbf{E} \\cdot d\\mathbf{\\ell} if \\Gamma is a path from a to b . Suppose we measure a Hall voltage V_H . Express the Hall resistance R_{xy} = V_H/I as a function of magnetic field. Does R_{xy} depend on the geometry of the sample? Also express R_{xy} in terms of the Hall coefficient R_H . Assuming we control the magnetic field \\mathbf{B} , what quantity can we extract from a measurement of the Hall resistance? Would a large or a small magnetic field give a Hall voltage that is easier to measure? Express the longitudinal resistance R=V/I , where V is the voltage difference over the sample along the x direction, in terms of the longitudinal resistivity \u03c1_{xx} . Suppose we extracted n from a measurement of the Hall resistance, what quantity can we extract from a measurement of the longitudinal resistance? Does the result depend on the geometry of the sample? Exercise 2: Motion of an electron in a magnetic and an electric field. \u00b6 Consider an electron in free space experiencing a magnetic field \\mathbf{B} along the z -direction. Assume that the electron starts at the origin with a velocity v_0 along the x -direction. Write down the Newton's equation of motion for the electron, compute \\frac{d\\mathbf{v}}{{dt}} . What is the shape of the motion of the electron? Calculate the characteristic frequency and time-period T_c of this motion for B=1 Tesla. Now we accelerate the electron by adding an electric field \\mathbf{E} = E \\hat{x} . Adjust the differential equation for \\frac{d\\mathbf{v}}{{dt}} found in (1) to include \\mathbf{E} . Sketch the motion of the electron. Exercise 3: Temperature dependence of resistance in the Drude model \u00b6 We consider copper, which has a density of 8960 kg/m ^3 , an atomic weight of 63.55 g/mol, and a room-temperature resistivity of \u03c1=1.68\\cdot 10^{-8} \\Omega m. Each copper atom provides one free electron. Calculate the Drude scattering time \u03c4 at room temperature. Assuming that electrons move with the thermal velocity \\langle v \\rangle = \\sqrt{\\frac{8k_BT}{\\pi m}} , calculate the electron mean free path \\lambda , defined as the average distance an electron travels in between scattering events. The Drude model assumes that \\lambda is independent of temperature. How does the electrical resistivity \u03c1 depend on temperature under this assumption? Sketch \u03c1(T) . Compare your sketch of \u03c1(T) with that in the lecture notes. In what respect do they differ? Discuss possible reasons for differences. Exercise 4: The Hall conductivity matrix and the Hall coefficient \u00b6 We apply a magnetic field \\bf B along the z -direction to a current carrying 2D sample in the xy plane. In this situation, the electric field \\mathbf{E} is related to the current density \\mathbf{j} by the resistivity matrix: \\mathbf{E} = \\begin{pmatrix} \u03c1_{xx} & \u03c1_{xy} \\\\ \u03c1_{yx} & \u03c1_{yy} \\end{pmatrix} \\mathbf{j} Sketch the expressions for \u03c1_{xx} and \u03c1_{xy} derived in the lecture notes as a function of the magnetic field \\bf{B} . Invert the resistivity matrix to obtain the conductivity matrix, \\begin{pmatrix} \\sigma_{xx} & \\sigma_{xy} \\\\ \\sigma_{yx} & \\sigma_{yy} \\end{pmatrix} allowing you to express \\mathbf{j} as a function of \\mathbf{E} .","title":"Electrons in metals I"},{"location":"03emetalsI/#electrons-in-metals-i","text":"","title":"Electrons in metals I"},{"location":"03emetalsI/#introduction","text":"Metals are awesome, and this has long been known. People have been drawn to their shininess since the first chunks of the stuff were found, and it mustn't have been long before it was realised that they were different to other materials. To nail down exactly what is the difference would take some time (of order 10,000 years!) but it boils down to metals being conductive, and this comes from the ability of electrons in the material to move more freely. It turns out that one can apply a somewhat crude kinetic theory to understand the transport of electrons in metals, in the same way kinetic theory can be used to understand the transport of gasses. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Electromagnetism: The influence of fields of charged particles Mechanics: Construct and solve equations of motion Thermal physics: Kinetic theory of gases Text reference The material covered here is discussed in section(s) \\S 3 of The Oxford Solid State Basics","title":"Introduction"},{"location":"03emetalsI/#the-kinetic-theory-of-gases-electrons","text":"Ohm's law is an empirical observation of conductors, which states that voltage is proportional to current V=IR . Since we are interested in the properties of materials, we would like to express this in a relation that does not depend on the conductor geometry. We achieve this by expressing the terms in Ohm's law with their microscopic equivalents. Consider a conducting wire with cross-sectional area A and length l . Such a wire has resistance R = \\rho l / A where \\rho is the material-dependent resistivity. An applied voltage V in the wire creates an electric field E = V/l . The resulting current I in the wire is described by the current density j \\equiv I / A . Returning these relations to Ohm's law, we get: V = I \u03c1 \\frac{l}{A} \u21d2 E = \u03c1 j, which relates the local quantities E and j . Our mission is to understand how this relation arises by considering motion of individual electrons in metals. This path was first trodden by Drude, who applied Boltzmann's kinetic theory of gases to a \"gas\" of electrons. The assumptions of Boltzmann's kinetic theory are that: Electrons scatter randomly at uncorrelated times. The average time between scattering is \\tau . Therefore, the probability of scattering in a time interval dt is dt / \\tau After each scattering event, the electron's momentum randomizes with a zero average \u27e8\\mathbf{p}\u27e9=0 It is also important to bake in the difference between neutral atoms or molecules in a gas and electrons, namely: Electrons are charged particles with charge -e , and consequently they respond to electric and magnetic fields through the Lorentz force ( \\mathbf{F}=-e\\left(\\mathbf{E}+\\mathbf{v}\u00d7\\mathbf{B}\\right) ) Even under these simplistic assumptions, the trajectory of the electrons is hard to calculate. As you will have seen elsewhere, with random scattering events, each trajectory is very different. A simple animation below shows several example trajectories, which are markedly different:","title":"The kinetic theory of gases electrons"},{"location":"03emetalsI/#equations-of-motion","text":"Keep in your mind that our goal is to find electric current density j . Each electron with charge -e and velocity \\mathbf{v} carries current -e\\mathbf{v} . Therefore, if the electron density is n , the average current they carry is -ne\u27e8\\mathbf{v}\u27e9 . Thus, our goal shifts to compute the average velocity. Underpinning this calculation is idea that although it is difficult to calculate the motion of an individual electron, computing the average motion of the electrons is a much more tractable task. For convenience from now on, we will omit the average brackets, and write \\mathbf{v} instead of \u27e8\\mathbf{v}\u27e9 . This also applies to F . We derive an equation of motion for the \"average\" electron in the following way: Consider everything that happens in an (infinitesimal) time interval dt . A fraction dt/\u03c4 of the electrons scatters, and their average velocity becomes zero. m\\mathbf{v}(t + dt) = 0 The rest of the electrons (1 - dt/\u03c4) are accelerated by the Lorentz force F , so their velocity becomes m\\mathbf{v}(t + dt) = m\\mathbf{v}(t) + \\mathbf{F}\u22c5dt. To find the average velocity, we take a weighted average of these two groups of particles: \\begin{aligned} m\\mathbf{v}(t+dt) &= [m\\mathbf{v}(t) + F dt]\\left(1 - \\frac{dt}{\\tau}\\right) + 0\u22c5\\frac{dt}{\\tau} \\\\ &= [m\\mathbf{v}(t) + \\mathbf{F} dt] \\left(1 - \\frac{dt}{\\tau}\\right) \\\\ &= m\\mathbf{v}(t) + dt [\\mathbf{F} - m\\frac{\\mathbf{v(t)}}{\\tau}] - \\frac{\\mathbf{F}}{\\tau} dt^2 \\end{aligned} We now neglect the term proportional to dt\u00b2 (it vanishes when dt \u2192 0 ). Finally, we recognize that \\left[\\mathbf{v}(t+dt) - \\mathbf{v}(t)\\right]/dt = d\\mathbf{v}(t)/dt , which results in m\\frac{d\\mathbf{v}}{dt} = -m\\frac{\\mathbf{v}}{\u03c4} + \\mathbf{F}. Observe that the first term on the right-hand side has the same form as a drag force: it always decelerates the electrons. This equation equation of motion of the average electron is our main result: now we only need to apply it.","title":"Equations of motion"},{"location":"03emetalsI/#consequences-of-the-drude-model","text":"Let us first consider the case without magnetic fields, \\mathbf{B} = 0 , and with constant electric field \\mathbf{E} . For many properties of interest, we are interested in the steady-state behaviour of the system, i.e. d\\mathbf{v}/dt = 0 , which upon solving the equation of motion yields: \\mathbf{v}=\\frac{-e\u03c4}{m}\\mathbf{E}=-|\u03bc|\\mathbf{E}. In the above equation, we define the mobility \u03bc\\equiv |e|\u03c4/m to be the ratio between the electron drift velocity and the electric field. The mobility is an extremely important quantity: it describes the response of the electron to an electric field. We can then substitute the steady-state velocity into the definition of current density: \\mathbf{j}=-en\\mathbf{v}=\\frac{n e^2\u03c4}{m}\\mathbf{E}=\\sigma\\mathbf{E} where \\sigma is the conductivity \\sigma=\\frac{ne^2\u03c4}{m}=ne\\mu such that \u03c1=1/\\sigma .","title":"Consequences of the Drude model"},{"location":"03emetalsI/#the-hall-effect","text":"Let us now consider the case where both and electric field \\mathbf{E} and magnetic field \\mathbf{B} are non-zero. Imagine a conductor with a current I flowing perpendicular to an external magnetic field \\mathbf{B} as shown below: Looking at the equations of motion: m\\frac{d\\mathbf{v}}{dt} = -m\\frac{\\mathbf{v}}{\u03c4} - e(\\mathbf{E} + \\mathbf{v}\\times\\mathbf{B}) we once again consider the steady state d\\mathbf{v}/dt = 0 . After substituting \\mathbf{v} = -\\mathbf{j}/ne , we arrive at \\mathbf{E}=\\frac{m}{ne^2\u03c4}\\mathbf{j} + \\frac{1}{ne}\\mathbf{j}\\times\\mathbf{B}. The first term is the same as before and describes the electric field parallel to the current, while the second is the electric field perpendicular to the current flow. In other words, if we send a current through a sample and apply a magnetic field, a voltage develops in the direction perpendicular to the current. This phenomenon is known as the Hall effect , with the perpendicular voltage called the Hall voltage , and the proportionality coefficient B/ne the Hall resistivity . Because of the Lorentz force, the electrons are deflected in a direction perpendicular to \\mathbf{B} and \\mathbf{j} . The deflection creates a charge imbalance, which in turn creates the electric field \\mathbf{E}_\\mathrm{H} compensating the Lorentz force. The above relation between the electric field and the current is linear, which allows us to write it in matrix form \\mathbf{E} = \\bar{\\rho} \\mathbf{j} where \\bar{\\rho} the resistivity matrix . Its diagonal elements are \\rho_{xx}=\\rho_{yy}=\\rho_{zz}=m/ne^2\\tau , which is the same as without magnetic field. The only nonzero off-diagonal elements when \\mathbf{B} points in the z -direction are \u03c1_{xy}=-\u03c1_{yx}=\\frac{B}{ne}\\equiv -R_\\mathrm{H}B, where R_H=-1/ne is the Hall coefficient . So by measuring the Hall voltage and knowing the electron charge, we can determine the density of free electrons in a material. While most materials have R_\\mathrm{H}<0 , interestingly some materials are found to have R_\\mathrm{H}>0 . What would be the implications of a negative hall coefficient? With the density is negative, or that the charge carrier has a positive charge and thus not an electron.","title":"The Hall effect"},{"location":"03emetalsI/#thermal-transport","text":"Given that Drude had cobbled together a kinetic theory for electrons, he decided that it was worthwhile to keep going, and make predictions about the properties of the \"gas\" in the same way as Boltzmann.","title":"Thermal transport"},{"location":"03emetalsI/#thermal-conductivity","text":"Explicitly, Boltzmann derived the thermal conductivity \\kappa : \\kappa = \\frac{1}{3}n c_v \\langle v \\rangle \\lambda where c_v is the heat capacity per particle, \\langle v \\rangle is the average thermal velocity and \\lambda = \\langle v \\rangle \\tau is the scattering length. For a monatomic gas c_v = \\frac{3}{2} k_{\\mathrm{B}} and \\langle v \\rangle = \\sqrt{\\frac{8 k_{\\mathrm{B}} T}{\\pi m}} Without any grounds for justification, we can just give these a whirl and see how they go for electrons: \\kappa = \\frac{4}{\\pi}\\frac{n \\tau k_{\\mathrm{B}} T}{m} which still holds the phenomenological scattering rate \\tau , meaning makes independent measurement impossible. However, the conductivity \\sigma also contains \\tau , so by measuring their ratio we can eliminate the dependence and define the Lorenz number: L = \\frac{\\kappa}{T\\sigma} = \\frac{4}{\\pi}\\left(\\frac{k_{\\mathrm{B}}}{e}\\right) \\approx 1 \\times 10^{-8}~\\mathrm{W\\Omega~K^{-2}} which was close to the measured values of the Lorenz number (within a factor of 2 or so), and given there had never been any explanation at all for this behaviour, this result served was hailed as a major accomplishment.","title":"Thermal conductivity"},{"location":"03emetalsI/#the-peltier-effect","text":"A stack of peltier (thermoelectric cooling) devices can be used for highly-effective heat transfer Aside from being amazingly cool, we look at the Peltier effect to see that whilst the model well predicts the Lorenz number, this is actually somewhat of a fluke. The Peltier effect arises when a current flows through a material, as that current necessarily transports heat. The Peltier coefficient is defined by \\mathbf{j}^q = \\Pi \\mathbf{j} Where \\mathbf{j}^q is the heat current density and \\mathbf{j} is the electrical current density. In kinetic theory, the thermal current is \\mathbf{j}^q = \\frac{1}{3} (c_v T) n \\mathbf{v} where c_v T is the heat carried by one particle and c_v = 3 k_{\\mathrm{B}}/2 the heat capacity per particle, n the density of particles, and the factor of 1/3 from geometry. The electric current is \\mathbf{j} = -en\\mathbf{v} and thus \\Pi = \\frac{-c_v T}{3 e} = \\frac{-k_\\mathrm{B} T}{2 e} which yield the temperature independent ratio S = \\frac{\\Pi}{T} = \\frac{-k_{\\textrm{B}}}{2e} = -4.3 \\times 10^{-4} \\mathrm{V/K} where S is Seebeck coefficient (also the thermopower). And how well does this agree? Well, unlike \\kappa which was only a factor of 2 from the measure values, most values of S are on the order of 10^{-6} \\mathrm{V/K} . So unfortunately, whilst the Drude model gives us a \"broad brushstrokes\" picture of what is happening in a metal, it fails to accurately predict the specific behaviour and the quantities about which we care.","title":"The Peltier effect"},{"location":"03emetalsI/#conclusions","text":"Drude theory is a kinetic theory and microscopic justification of the Ohm's law. We can calculate the resistivity from the characteristic scattering time \\tau . The Lorentz force leads to the Hall voltage that is perpendicular to the direction of both the electric current and the magnetic field. Drude theory does some things well, but ultimately falls short.","title":"Conclusions"},{"location":"03emetalsI/#exercises","text":"","title":"Exercises"},{"location":"03emetalsI/#preliminary-provocations","text":"How does the resistance of a purely 2D material depend on its size? Check that the units of mobility and the Hall coefficient are correct. (As you should always do!) Explain why the scattering times due to different types of scattering events add up in a reciprocal way.","title":"Preliminary provocations"},{"location":"03emetalsI/#exercise-1-extracting-quantities-from-basic-hall-measurements","text":"We apply a magnetic field \\bf B along the z -direction to a planar (two-dimensional) sample that sits in the xy plane. The sample has width W in the y -direction, length L in the x -direction and we apply a current I along the x -direction. What is the relation between the electric field and the electric potential? V_b - V_a = -\\int_{\\Gamma} \\mathbf{E} \\cdot d\\mathbf{\\ell} if \\Gamma is a path from a to b . Suppose we measure a Hall voltage V_H . Express the Hall resistance R_{xy} = V_H/I as a function of magnetic field. Does R_{xy} depend on the geometry of the sample? Also express R_{xy} in terms of the Hall coefficient R_H . Assuming we control the magnetic field \\mathbf{B} , what quantity can we extract from a measurement of the Hall resistance? Would a large or a small magnetic field give a Hall voltage that is easier to measure? Express the longitudinal resistance R=V/I , where V is the voltage difference over the sample along the x direction, in terms of the longitudinal resistivity \u03c1_{xx} . Suppose we extracted n from a measurement of the Hall resistance, what quantity can we extract from a measurement of the longitudinal resistance? Does the result depend on the geometry of the sample?","title":"Exercise 1: Extracting quantities from basic Hall measurements"},{"location":"03emetalsI/#exercise-2-motion-of-an-electron-in-a-magnetic-and-an-electric-field","text":"Consider an electron in free space experiencing a magnetic field \\mathbf{B} along the z -direction. Assume that the electron starts at the origin with a velocity v_0 along the x -direction. Write down the Newton's equation of motion for the electron, compute \\frac{d\\mathbf{v}}{{dt}} . What is the shape of the motion of the electron? Calculate the characteristic frequency and time-period T_c of this motion for B=1 Tesla. Now we accelerate the electron by adding an electric field \\mathbf{E} = E \\hat{x} . Adjust the differential equation for \\frac{d\\mathbf{v}}{{dt}} found in (1) to include \\mathbf{E} . Sketch the motion of the electron.","title":"Exercise 2: Motion of an electron in a magnetic and an electric field."},{"location":"03emetalsI/#exercise-3-temperature-dependence-of-resistance-in-the-drude-model","text":"We consider copper, which has a density of 8960 kg/m ^3 , an atomic weight of 63.55 g/mol, and a room-temperature resistivity of \u03c1=1.68\\cdot 10^{-8} \\Omega m. Each copper atom provides one free electron. Calculate the Drude scattering time \u03c4 at room temperature. Assuming that electrons move with the thermal velocity \\langle v \\rangle = \\sqrt{\\frac{8k_BT}{\\pi m}} , calculate the electron mean free path \\lambda , defined as the average distance an electron travels in between scattering events. The Drude model assumes that \\lambda is independent of temperature. How does the electrical resistivity \u03c1 depend on temperature under this assumption? Sketch \u03c1(T) . Compare your sketch of \u03c1(T) with that in the lecture notes. In what respect do they differ? Discuss possible reasons for differences.","title":"Exercise 3: Temperature dependence of resistance in the Drude model"},{"location":"03emetalsI/#exercise-4-the-hall-conductivity-matrix-and-the-hall-coefficient","text":"We apply a magnetic field \\bf B along the z -direction to a current carrying 2D sample in the xy plane. In this situation, the electric field \\mathbf{E} is related to the current density \\mathbf{j} by the resistivity matrix: \\mathbf{E} = \\begin{pmatrix} \u03c1_{xx} & \u03c1_{xy} \\\\ \u03c1_{yx} & \u03c1_{yy} \\end{pmatrix} \\mathbf{j} Sketch the expressions for \u03c1_{xx} and \u03c1_{xy} derived in the lecture notes as a function of the magnetic field \\bf{B} . Invert the resistivity matrix to obtain the conductivity matrix, \\begin{pmatrix} \\sigma_{xx} & \\sigma_{xy} \\\\ \\sigma_{yx} & \\sigma_{yy} \\end{pmatrix} allowing you to express \\mathbf{j} as a function of \\mathbf{E} .","title":"Exercise 4: The Hall conductivity matrix and the Hall coefficient"},{"location":"04emetalsII/","text":"Electrons in metals II \u00b6 Introduction \u00b6 The kinetic theory of Drude was a great first step in trying to answer the question \"metals, how do they work?\", but it was clear from the outset that there were problems with the theory. But with the discovery of the Pauli exclusion principle, it seemed only logical that with the inclusion of the fundamental property of the electrons, life would improve. Indeed it does... Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Statistical mechanics: familiarity with Fermi-Dirac statistics Quantum mechanics: Wavefunction of a free (unbound) electron Text reference The material covered here is discussed in section(s) \\S 4 of The Oxford Solid State Basics The free electron model \u00b6 Fermi statistics \u00b6 In studying the Debye model , we saw the properties and physical behavior which arise from considering modes of oscillation in a material. The model we look at there, the Sommerfeld model, applies the same conceptual approach to electrons in metals. Sommerfeld considered the electrons as free particles that are not interacting with atomic nuclei, which is why the model is also called the free electron model . Similar to the Debye model, we consider a cubic box of size L \\times L \\times L with periodic boundary conditions. The solutions to the Schr\u00f6dinger equation of a free particle are plane waves: \\psi \\propto \\exp(i\\mathbf{k} \\cdot \\mathbf{r}), where \\mathbf{k} is the electron wave vector. Because we impose periodic boundary conditions, \\mathbf{k} must take discrete values \\frac{2\\pi}{L} (n_x, n_y, n_z) . The plane waves have eigenenergies given by the dispersion relation \\varepsilon(\\mathbf{k}) = \\frac{\\hbar^2 \\mathbf{k}^2}{2m}, with m being the mass of the electron. Let us plot \\varepsilon(k) as a function of k for a 1D system: A plot of the energy $\\varepsilon$ as a function of $k$, where black dot represent possible electron states In is worth highlighting the differences between the modes of oscillation in a solid we have considered previously, and the states of electrons which we now consider: electrons have a quadratic dispersion dispersion relation, and critically, electrons obey fermionic statistics. Conseqeuntly, the occupation of electron states is described by the Fermi-Dirac distribution n_{F}(\\beta(\\varepsilon-\\mu)) = \\frac{1}{e^{\\beta(\\varepsilon-\\mu)}+1} where \\beta = 1/k_{\\textrm{B}} T , \\varepsilon is the energy, and \\mu the chemical potential of an electron. The Fermi-Dirac distribution defines the number of electrons in the system: \\begin{align} N &= 2 \\sum_{\\mathbf{k}} n_{F}(\\beta(\\varepsilon-\\mu))\\\\ &= 2 \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ n_{F}(\\beta(\\varepsilon(\\mathbf{k})-\\mu)). \\end{align} Where we have again replaced a discrete sum over k with a volume integral. From where does the factor of 2 come from in the above equation? Contrast this to the Debye model. The factor 2 accounts for the spin degeneracy, whereas in the Debye model we had a factor of 3 to account for the distinct polarisations. To keep track of the origin of this term we will denote the spin degeneracy as 2_s . In the same way that we compute the number of electrons, we can compute the total energy of the electrons via E = 2_s \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ \\varepsilon(\\mathbf{k}) n_{F}(\\beta(\\varepsilon(\\mathbf{k})-\\mu)) . To cement the differences between Debye theory and Sommerfeld theory, different parameters are listed below: Crystal oscillations Electrons Dispersion relation \\omega = v_s \\lvert\\mathbf{k}\\rvert \\varepsilon = \\frac{\\hbar^2\\mathbf{k}^2}{2m} Statistics Bose-Einstein Fermi-Dirac n(\\varepsilon) = 1/(e^{\\beta \\varepsilon} - 1) 1/(e^{\\beta(\\varepsilon - \\mu)} + 1) Degeneracy per \\mathbf{k} 3 (polarization) 2 (spin) Total particle number temperature-dependent constant Note that the last element is important: in the case of oscillations within a material, warming said material creates more more oscillations. In contrast, the number of electrons stays generally remains the same. The Fermi sea \u00b6 To determine the chemical potential \\mu let us consider a 2D system with zero temperature and a finite number of electrons. At T=0 , the Fermi-Dirac distribution is step function n_{F}(\\beta(\\varepsilon-\\mu)) = \\Theta(-(\\varepsilon-\\varepsilon_F)). The chemical potential at T=0 is called the Fermi energy \\varepsilon_F and in this scenario, all electronic states with lower energies are occupied and all the states with higher energies are empty. In the reciprocal space, the occupied \\mathbf{k} -states form a circle (in 1D it is a line and in 3D a sphere). Reciprical space in two dimensions at $T=0$: states within the circle are occuplied and those outside are not A all-pervasive metaphor for describing this state of many electrons is the idea of the Fermi sea : electrons occupy a finite area in reciprocal space, starting from the \"deepest\" points with the lowest energy all the way up to the chemical potential. The border of the Fermi sea is called the Fermi surface , and in the free electron model it is a sphere with the radius equal to the Fermi wave vector . Can you identify the pattern in the nomencalture of important concepts? Pick an object or concept x, and name it the Fermi x. In an attempt to clarify the relationship between these concepts, let us take a look at the dispersion relation in 1D: The dispersion relation for electrons in one dimension By using the dispersion relation, we arrive to the relation \\varepsilon_F = \\frac{\\hbar^2 \\mathbf{k}_F^2}{2m}. The Fermi wavevector \\mathbf{k}_F also defines the Fermi momentum \\mathbf{p}_F = \\hbar \\mathbf{k}_F and the Fermi velocity : \\mathbf{v}_F = \\frac{\\mathbf{p}_F}{m} = \\frac{\\hbar \\mathbf{k}_F}{m}. The Fermi energy of copper is ~7 eV. What is the corresponding Fermi velocity? The Fermi velocity v_F\\approx 1700 km/s or 0.3% of the speed of light! Heat capacity \u00b6 Density of states \u00b6 As were have done previously, we want to compute the heat capacity, and to do this, we need to find the density of states: the number of states per energy interval. We have expression for both the number N and the energy E from above : \\begin{aligned} N & = 2_s \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ n_{F}(\\beta(\\varepsilon-\\mu)) \\\\ E & = 2_s \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ \\varepsilon(\\mathbf{k}) n_{F}(\\beta(\\varepsilon-\\mu)) \\end{aligned} which we seek to evaluate. Using the same tricks as last time, we move to spherical coordinates to reduce the inegral over three dimension to an intergral over one dimension, we can arrive at the expressions \\begin{aligned} N & = 2_s \\frac{V}{(2 \\pi)^3} \\int_0^\\infty \\mathrm{d} k ~ 4\\pi k^2 ~ n_{F}(\\beta(\\varepsilon(k)-\\mu)) \\\\ E & = 2_s \\frac{V}{(2 \\pi)^3} \\int_0^\\infty \\mathrm{d} k ~ 4\\pi k^2 ~ \\varepsilon(k) ~ n_{F}(\\beta(\\varepsilon(k)-\\mu)) \\end{aligned} We rewrite the expression above by substituting k=\\sqrt{2m\\varepsilon/\\hbar^2} and \\mathrm{d}k=\\sqrt{m/2\\varepsilon\\hbar^2} d\\varepsilon : \\begin{aligned} N & = V \\int_0^\\infty \\mathrm{d} \\varepsilon ~ g(\\varepsilon) ~ n_{F}(\\beta(\\varepsilon-\\mu)) \\\\ E & = V \\int_0^\\infty \\mathrm{d} \\varepsilon ~ \\varepsilon ~ g(\\varepsilon) ~ n_{F}(\\beta(\\varepsilon-\\mu)) \\end{aligned} where the density of states per unit volume is given by \\begin{aligned} g(\\varepsilon) \\mathrm{d} \\varepsilon & = \\frac{2}{(2\\pi)^3} 4 \\pi k^2 \\mathrm{d} k \\\\ & = \\frac{(2m)^{3/2}}{2 \\pi^2 \\hbar^3} \\varepsilon^{1/2} \\mathrm{d} \\varepsilon \\end{aligned} and quantifies the number of energy eigenstates between \\varepsilon and \\varepsilon + \\mathrm{d} \\varepsilon . This expression can be more cleanly written as g(\\varepsilon) \\mathrm{d} \\varepsilon = \\frac{3n}{2\\varepsilon_F}\\left(\\frac{\\varepsilon}{\\varepsilon_F}\\right)^{1/2} Verify the above expression. A good starting point would be to find a value for the number of electrons inside the sphere defined by k_F for T=0 Do the maths , integral of the Heaviside just means intergral is the volume of a sphere. We observe that the density of states of a 3D solid is proportional to a square root of energy: g(\\varepsilon) \\mathrm{d} \\varepsilon \\propto\\sqrt{\\varepsilon} Repeating the similar derivations, we find the density of states of 1D and 2D systems: 1D: g(\\varepsilon) = \\frac{2 L}{\\pi} \\frac{ \\mathrm{d}k}{ \\mathrm{d}\\varepsilon} \\propto 1/\\sqrt{\\varepsilon} 2D: g(\\varepsilon) = \\frac{k L^2}{\\pi} \\frac{ \\mathrm{d}k}{ \\mathrm{d}\\varepsilon} \\propto \\text{constant} which we can plot for a comparison of the behaviour of the system with different dimensionalities: Crank the handle \u00b6 Given we have an expression for E , we can set about computing the heat capacity. Sommerfeld expansion To explicitly calculate the heat capacity is a lot of work, and is the definition of a mathematical persuit with little reward. With a bit of hand waving, we can arrive at the same point, so that is what we are going to do. Some will think this lazy, and by all means, feel free to pursue the full calcuation - the Sommerfeld expansion may be of use. To effectively hand wave, let us begin by taking a closer look at the Fermi-Dirac distribution n_{F}(\\beta(\\varepsilon-\\mu)) = \\frac{1}{e^{\\beta(\\varepsilon-\\mu)}+1} which is plotted below for T = 0 and T > 0 with the same chemical potential \\mu = \\varepsilon_F . The Fermi-Dirac distribution at both $T = 0$ and $T > 0$ with the same chemical potential With a finite temperature T>0 , thermal excitations smear out the sharp change in the number of occupied electrons near \\varepsilon_F . Because the Fermi energy is typically in the range of electronvolts, the temperature of \\sim 10 000 ~\\mathrm{K} would be required in order for thermal excitations to give an electron a similar amount of energy! Therefore at room temperature T = 300~\\mathrm{K} the electron distribution over energies is very similar to that at T=0 . Below we compare the number of occupied electron states at each energy g(\\varepsilon) n_{F}(\\beta(\\varepsilon-\\mu)) at T = 0 (blue shaded area) with T > 0 (orange shaded area). In order to estimate the electron energy increase, we approximate difference between the blue and orange areas by triangles, as shown in the figure. This approximation is appropriate because the thermal smearing happens at the energies E \u223c k_B T , and it is much smaller than the Fermi energy \\varepsilon_{F} . At a finite temperature, the electrons occupying the top triangle (blue) are thermally excited to occupy the bottom triangle (orange). The base of the triangle is proportional to k_\\mathrm{B}T and the height is \\sim g(\\varepsilon_F) . Hence the number of excited electrons is N_\\mathrm{exc} \\approx g(\\varepsilon_F)k_BT (neglecting constants not depending on \\varepsilon_{F} ). These electrons gain k_BT of thermal energy, such that the total extra energy is \\begin{align} E(T) &= E(T = 0) + N_\\mathrm{exc}k_BT\\\\ &\\approx E(T = 0) + g(\\varepsilon_F)k_B^2T^2. \\end{align} Therefore, the electron heat capacity C_e is \\begin{align} C_e &= \\frac{ \\mathrm{d}E}{ \\mathrm{d}T}\\\\ &\\approx 2 g(\u03b5_F)k_B^2T\\\\ &\\overset{\\mathrm{3D}}{=} 3 Nk_B\\frac{T}{T_F}\\\\ &\\propto T, \\end{align} where we used N=\\frac{2}{3}\\varepsilon_Fg(\\varepsilon_F) and defined the Fermi temperature T_F \\equiv \\varepsilon_F/k_B . So what does all of this mean? Well, our algebraic journey has left us with a heat capacity that is linear in T , which to contrast to the model of Debye, had dependence on T^3 , which fitted the measurements pretty well. Does this mean that we have made things worse? Well let's look closely: The heat capacity of Silver divided by temperature versus the square of the temperature as taken from Atomic Heats of Copper, Silver, and Gold from 1\u00b0K to 5\u00b0K What is the expected behaviour of the plot above as predicted by the Debye model and the Sommerfeld model? We now have two contributions to the heat capacity C_{\\textrm{Sommerfeld}} = \\gamma T and C_{\\textrm{Debye}} = \\alpha T^3 , which should manifest as C = \\gamma T + \\alpha T^3. In the plot above, if we plot C/T , any offest at T=0 is indicative of free-electron behaviour, which we indeed observe. It is worth noting that At room temperature C_{\\textrm{Debye}}\\approx 3Nk_B\\gg C_{\\textrm{Sommerfeld}} \\propto k_B T / T_F , because T \\ll T_F . Near T=0 , the heat capacity due to ocillations C_{\\textrm{Debye}} \\propto k_B (T/T_D)^3 , which becomes smaller than the electron heat capacity at T \\lesssim \\sqrt{T_D^3/T_F} The scaling of C \u00b6 The behavior of contribution to C from the free-electron component at low temperature can be intuited via particles within an energy range of \\sim k_{B}T to the Fermi energy \\varepsilon_F become thermally excited, and each carries an extra energy k_{B}T : N_\\mathrm{exc} \\approx g(\\varepsilon_F)k_BT \\\\ E \\sim N_\\mathrm{exc} k_\\mathrm{B} T Example 1: 3D free electrons \u00b6 In 3D, g(\\varepsilon_F) is roughly constant. Thus the total energy obtained through thermal excitation is proportional to T \\times \\left( T\\times g(\\varepsilon_F) \\right) , from which it follows that C_e \\propto T . Example 2: graphene \u00b6 Graphene has a Fermi energy \\varepsilon_F = 0 and a density of states g(\\varepsilon) \\propto \\varepsilon . Therefore, within the energy range of k_BT , g(\\varepsilon) \\propto k_BT . Thus the total energy is proportional to T \\times T^2 and the heat capacity C_e \\propto T^2 . Conclusions \u00b6 The Sommerfeld free-electron model treats electrons as free particles with energy dispersion \\varepsilon = \\frac{\\hbar^2k^2}{2m} . The Fermi-Dirac distribution gives the probability of an electron state to be occupied. The electron contribution to the heat capacity is proportional to T . It is much lower than the heat capacity due to oscillations at high temperatures, and much higher at low temperatures. The scaling of heat capacity with T can be quickly estimated by estimating the number of particles in an energy range k_\\mathrm{B}T from the Fermi energy. Exercises \u00b6 Preliminary provocations \u00b6 Write down the expression for the total energy of particles with the density of states g(\\varepsilon) and the occupation number n_{F}(\\beta(\\varepsilon - \\mu)) . Explain what happens if a material is heated up to its Fermi temperature (assuming that material where this is possible exists). Why can we not use the Sommerfeld expansion with a Fermi energy of the order of the thermal energy? Is the heat capacity of a solid at temperatures near T=0 dominated by electrons or vibrations? Exercise 1: potassium \u00b6 The Sommerfeld model provides a good description of free electrons in alkali metals such as potassium (element K), which has a Fermi energy of \\varepsilon_{F} = 2.12 eV (data from Ashcroft, N. W. and Mermin, N. D., Solid State Physics, Saunders, 1976.). Check the Fermi surface database . Explain why potassium and (most) other alkali metals can be described well with the Sommerfeld model. Calculate the Fermi temperature, Fermi wave vector and Fermi velocity for potassium. Why is the Fermi temperature much higher than room temperature? Calculate the free electron density n in potassium. Compare this with the actual electron density of potassium, which can be calculated by using the density, atomic mass and atomic number of potassium. What can you conclude from this? Exercise 2: a hypothetical material \u00b6 A hypothetical metal has a Fermi energy \\varepsilon_F = 5.2 \\, \\mathrm{eV} and a density of states g(\\varepsilon) = 2 \\times 10^{10} \\, \\mathrm{eV}^{-\\frac{3}{2}} \\sqrt{\\varepsilon} . Give an integral expression for the total energy of the electrons in this hypothetical material in terms of the density of states g(\\varepsilon) , the temperature T and the chemical potential \\mu = \\varepsilon_F . Find the ground state energy at T = 0 . In order to obtain a good approximation of the integral for non-zero T , one can make use of the Sommerfeld expansion (the first equation is all you need and you can neglect the O\\left(\\frac{1}{\\beta \\mu}\\right)^{4} term). Using this expansion, find the difference between the total energy of the electrons for T = 1000 \\, \\mathrm{K} with that of the ground state. Now, find this difference in energy by calculating the integral found in 1 numerically. Compare your result with 3. Hint You can do numerical integration in python with scipy.integrate.quad(func, xmin, xmax) Calculate the heat capacity for T = 1000 \\, \\mathrm{K} in eV/K. Numerically compute the heat capacity by approximating the derivative of energy difference found in 4 with respect to T . To this end, make use of the fact that \\frac{dy}{dx}=\\lim_{\\Delta x \\to 0} \\frac{y(x + \\Delta x) - y(x - \\Delta x)}{2 \\Delta x}. Compare your result with 5. Exercise 4: graphene \u00b6 One of the most famous recently discovered materials is graphene . It consists of carbon atoms arranged in a 2D honeycomb structure. In this exercise, we will focus on the electrons in bulk graphene. Unlike in metals, electrons in graphene cannot be treated as 'free'. However, close to the Fermi level, the dispersion relation can be approximated by a linear relation: \\varepsilon(\\mathbf{k}) = \\pm c|\\mathbf{k}|. Note that the \\pm here means that there are two energy levels at a specified \\mathbf{k} . The Fermi level is set at \\varepsilon_F = 0 . Make a sketch of the dispersion relation. What other well-known particles have a linear dispersion relation? Using the dispersion relation and assuming periodic boundary conditions, derive an expression for the density of states of graphene. Do not forget spin degeneracy, and take into account that graphene has an additional two-fold 'valley degeneracy' (hence there is a total of a fourfold degeneracy instead of two). Your result should be linear with |\\varepsilon| . Hint It is convenient to first start by only considering the positive energy contributions \\varepsilon(\\mathbf{k}) = + c|\\mathbf{k}| and calculate the density of states for it. Then account for the negative energy contributions \\varepsilon(\\mathbf{k}) = - c|\\mathbf{k}| by adding it to the density of states for the positive energies. You can also make use of \\frac{\\rm{d} |k|}{\\rm{d}k} = \\frac{k}{|k|} . At finite temperatures, assume that electrons close to the Fermi level (i.e. not more than k_B T below the Fermi level) will get thermally excited, thereby increasing their energy by k_B T . Calculate the difference between the energy of the thermally excited state and that of the ground state E(T)-E_0 . To do so, show first that the number of electrons that will get excited is given by n_{ex} = \\frac{1}{2} g(-k_B T) k_B T. Calculate the heat capacity C_e as a function of the temperature T .","title":"Electrons in metals II"},{"location":"04emetalsII/#electrons-in-metals-ii","text":"","title":"Electrons in metals II"},{"location":"04emetalsII/#introduction","text":"The kinetic theory of Drude was a great first step in trying to answer the question \"metals, how do they work?\", but it was clear from the outset that there were problems with the theory. But with the discovery of the Pauli exclusion principle, it seemed only logical that with the inclusion of the fundamental property of the electrons, life would improve. Indeed it does... Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Statistical mechanics: familiarity with Fermi-Dirac statistics Quantum mechanics: Wavefunction of a free (unbound) electron Text reference The material covered here is discussed in section(s) \\S 4 of The Oxford Solid State Basics","title":"Introduction"},{"location":"04emetalsII/#the-free-electron-model","text":"","title":"The free electron model"},{"location":"04emetalsII/#fermi-statistics","text":"In studying the Debye model , we saw the properties and physical behavior which arise from considering modes of oscillation in a material. The model we look at there, the Sommerfeld model, applies the same conceptual approach to electrons in metals. Sommerfeld considered the electrons as free particles that are not interacting with atomic nuclei, which is why the model is also called the free electron model . Similar to the Debye model, we consider a cubic box of size L \\times L \\times L with periodic boundary conditions. The solutions to the Schr\u00f6dinger equation of a free particle are plane waves: \\psi \\propto \\exp(i\\mathbf{k} \\cdot \\mathbf{r}), where \\mathbf{k} is the electron wave vector. Because we impose periodic boundary conditions, \\mathbf{k} must take discrete values \\frac{2\\pi}{L} (n_x, n_y, n_z) . The plane waves have eigenenergies given by the dispersion relation \\varepsilon(\\mathbf{k}) = \\frac{\\hbar^2 \\mathbf{k}^2}{2m}, with m being the mass of the electron. Let us plot \\varepsilon(k) as a function of k for a 1D system: A plot of the energy $\\varepsilon$ as a function of $k$, where black dot represent possible electron states In is worth highlighting the differences between the modes of oscillation in a solid we have considered previously, and the states of electrons which we now consider: electrons have a quadratic dispersion dispersion relation, and critically, electrons obey fermionic statistics. Conseqeuntly, the occupation of electron states is described by the Fermi-Dirac distribution n_{F}(\\beta(\\varepsilon-\\mu)) = \\frac{1}{e^{\\beta(\\varepsilon-\\mu)}+1} where \\beta = 1/k_{\\textrm{B}} T , \\varepsilon is the energy, and \\mu the chemical potential of an electron. The Fermi-Dirac distribution defines the number of electrons in the system: \\begin{align} N &= 2 \\sum_{\\mathbf{k}} n_{F}(\\beta(\\varepsilon-\\mu))\\\\ &= 2 \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ n_{F}(\\beta(\\varepsilon(\\mathbf{k})-\\mu)). \\end{align} Where we have again replaced a discrete sum over k with a volume integral. From where does the factor of 2 come from in the above equation? Contrast this to the Debye model. The factor 2 accounts for the spin degeneracy, whereas in the Debye model we had a factor of 3 to account for the distinct polarisations. To keep track of the origin of this term we will denote the spin degeneracy as 2_s . In the same way that we compute the number of electrons, we can compute the total energy of the electrons via E = 2_s \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ \\varepsilon(\\mathbf{k}) n_{F}(\\beta(\\varepsilon(\\mathbf{k})-\\mu)) . To cement the differences between Debye theory and Sommerfeld theory, different parameters are listed below: Crystal oscillations Electrons Dispersion relation \\omega = v_s \\lvert\\mathbf{k}\\rvert \\varepsilon = \\frac{\\hbar^2\\mathbf{k}^2}{2m} Statistics Bose-Einstein Fermi-Dirac n(\\varepsilon) = 1/(e^{\\beta \\varepsilon} - 1) 1/(e^{\\beta(\\varepsilon - \\mu)} + 1) Degeneracy per \\mathbf{k} 3 (polarization) 2 (spin) Total particle number temperature-dependent constant Note that the last element is important: in the case of oscillations within a material, warming said material creates more more oscillations. In contrast, the number of electrons stays generally remains the same.","title":"Fermi statistics"},{"location":"04emetalsII/#the-fermi-sea","text":"To determine the chemical potential \\mu let us consider a 2D system with zero temperature and a finite number of electrons. At T=0 , the Fermi-Dirac distribution is step function n_{F}(\\beta(\\varepsilon-\\mu)) = \\Theta(-(\\varepsilon-\\varepsilon_F)). The chemical potential at T=0 is called the Fermi energy \\varepsilon_F and in this scenario, all electronic states with lower energies are occupied and all the states with higher energies are empty. In the reciprocal space, the occupied \\mathbf{k} -states form a circle (in 1D it is a line and in 3D a sphere). Reciprical space in two dimensions at $T=0$: states within the circle are occuplied and those outside are not A all-pervasive metaphor for describing this state of many electrons is the idea of the Fermi sea : electrons occupy a finite area in reciprocal space, starting from the \"deepest\" points with the lowest energy all the way up to the chemical potential. The border of the Fermi sea is called the Fermi surface , and in the free electron model it is a sphere with the radius equal to the Fermi wave vector . Can you identify the pattern in the nomencalture of important concepts? Pick an object or concept x, and name it the Fermi x. In an attempt to clarify the relationship between these concepts, let us take a look at the dispersion relation in 1D: The dispersion relation for electrons in one dimension By using the dispersion relation, we arrive to the relation \\varepsilon_F = \\frac{\\hbar^2 \\mathbf{k}_F^2}{2m}. The Fermi wavevector \\mathbf{k}_F also defines the Fermi momentum \\mathbf{p}_F = \\hbar \\mathbf{k}_F and the Fermi velocity : \\mathbf{v}_F = \\frac{\\mathbf{p}_F}{m} = \\frac{\\hbar \\mathbf{k}_F}{m}. The Fermi energy of copper is ~7 eV. What is the corresponding Fermi velocity? The Fermi velocity v_F\\approx 1700 km/s or 0.3% of the speed of light!","title":"The Fermi sea"},{"location":"04emetalsII/#heat-capacity","text":"","title":"Heat capacity"},{"location":"04emetalsII/#density-of-states","text":"As were have done previously, we want to compute the heat capacity, and to do this, we need to find the density of states: the number of states per energy interval. We have expression for both the number N and the energy E from above : \\begin{aligned} N & = 2_s \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ n_{F}(\\beta(\\varepsilon-\\mu)) \\\\ E & = 2_s \\frac{V}{(2 \\pi)^3} \\int \\mathrm{d} \\mathbf{k} ~ \\varepsilon(\\mathbf{k}) n_{F}(\\beta(\\varepsilon-\\mu)) \\end{aligned} which we seek to evaluate. Using the same tricks as last time, we move to spherical coordinates to reduce the inegral over three dimension to an intergral over one dimension, we can arrive at the expressions \\begin{aligned} N & = 2_s \\frac{V}{(2 \\pi)^3} \\int_0^\\infty \\mathrm{d} k ~ 4\\pi k^2 ~ n_{F}(\\beta(\\varepsilon(k)-\\mu)) \\\\ E & = 2_s \\frac{V}{(2 \\pi)^3} \\int_0^\\infty \\mathrm{d} k ~ 4\\pi k^2 ~ \\varepsilon(k) ~ n_{F}(\\beta(\\varepsilon(k)-\\mu)) \\end{aligned} We rewrite the expression above by substituting k=\\sqrt{2m\\varepsilon/\\hbar^2} and \\mathrm{d}k=\\sqrt{m/2\\varepsilon\\hbar^2} d\\varepsilon : \\begin{aligned} N & = V \\int_0^\\infty \\mathrm{d} \\varepsilon ~ g(\\varepsilon) ~ n_{F}(\\beta(\\varepsilon-\\mu)) \\\\ E & = V \\int_0^\\infty \\mathrm{d} \\varepsilon ~ \\varepsilon ~ g(\\varepsilon) ~ n_{F}(\\beta(\\varepsilon-\\mu)) \\end{aligned} where the density of states per unit volume is given by \\begin{aligned} g(\\varepsilon) \\mathrm{d} \\varepsilon & = \\frac{2}{(2\\pi)^3} 4 \\pi k^2 \\mathrm{d} k \\\\ & = \\frac{(2m)^{3/2}}{2 \\pi^2 \\hbar^3} \\varepsilon^{1/2} \\mathrm{d} \\varepsilon \\end{aligned} and quantifies the number of energy eigenstates between \\varepsilon and \\varepsilon + \\mathrm{d} \\varepsilon . This expression can be more cleanly written as g(\\varepsilon) \\mathrm{d} \\varepsilon = \\frac{3n}{2\\varepsilon_F}\\left(\\frac{\\varepsilon}{\\varepsilon_F}\\right)^{1/2} Verify the above expression. A good starting point would be to find a value for the number of electrons inside the sphere defined by k_F for T=0 Do the maths , integral of the Heaviside just means intergral is the volume of a sphere. We observe that the density of states of a 3D solid is proportional to a square root of energy: g(\\varepsilon) \\mathrm{d} \\varepsilon \\propto\\sqrt{\\varepsilon} Repeating the similar derivations, we find the density of states of 1D and 2D systems: 1D: g(\\varepsilon) = \\frac{2 L}{\\pi} \\frac{ \\mathrm{d}k}{ \\mathrm{d}\\varepsilon} \\propto 1/\\sqrt{\\varepsilon} 2D: g(\\varepsilon) = \\frac{k L^2}{\\pi} \\frac{ \\mathrm{d}k}{ \\mathrm{d}\\varepsilon} \\propto \\text{constant} which we can plot for a comparison of the behaviour of the system with different dimensionalities:","title":"Density of states"},{"location":"04emetalsII/#crank-the-handle","text":"Given we have an expression for E , we can set about computing the heat capacity. Sommerfeld expansion To explicitly calculate the heat capacity is a lot of work, and is the definition of a mathematical persuit with little reward. With a bit of hand waving, we can arrive at the same point, so that is what we are going to do. Some will think this lazy, and by all means, feel free to pursue the full calcuation - the Sommerfeld expansion may be of use. To effectively hand wave, let us begin by taking a closer look at the Fermi-Dirac distribution n_{F}(\\beta(\\varepsilon-\\mu)) = \\frac{1}{e^{\\beta(\\varepsilon-\\mu)}+1} which is plotted below for T = 0 and T > 0 with the same chemical potential \\mu = \\varepsilon_F . The Fermi-Dirac distribution at both $T = 0$ and $T > 0$ with the same chemical potential With a finite temperature T>0 , thermal excitations smear out the sharp change in the number of occupied electrons near \\varepsilon_F . Because the Fermi energy is typically in the range of electronvolts, the temperature of \\sim 10 000 ~\\mathrm{K} would be required in order for thermal excitations to give an electron a similar amount of energy! Therefore at room temperature T = 300~\\mathrm{K} the electron distribution over energies is very similar to that at T=0 . Below we compare the number of occupied electron states at each energy g(\\varepsilon) n_{F}(\\beta(\\varepsilon-\\mu)) at T = 0 (blue shaded area) with T > 0 (orange shaded area). In order to estimate the electron energy increase, we approximate difference between the blue and orange areas by triangles, as shown in the figure. This approximation is appropriate because the thermal smearing happens at the energies E \u223c k_B T , and it is much smaller than the Fermi energy \\varepsilon_{F} . At a finite temperature, the electrons occupying the top triangle (blue) are thermally excited to occupy the bottom triangle (orange). The base of the triangle is proportional to k_\\mathrm{B}T and the height is \\sim g(\\varepsilon_F) . Hence the number of excited electrons is N_\\mathrm{exc} \\approx g(\\varepsilon_F)k_BT (neglecting constants not depending on \\varepsilon_{F} ). These electrons gain k_BT of thermal energy, such that the total extra energy is \\begin{align} E(T) &= E(T = 0) + N_\\mathrm{exc}k_BT\\\\ &\\approx E(T = 0) + g(\\varepsilon_F)k_B^2T^2. \\end{align} Therefore, the electron heat capacity C_e is \\begin{align} C_e &= \\frac{ \\mathrm{d}E}{ \\mathrm{d}T}\\\\ &\\approx 2 g(\u03b5_F)k_B^2T\\\\ &\\overset{\\mathrm{3D}}{=} 3 Nk_B\\frac{T}{T_F}\\\\ &\\propto T, \\end{align} where we used N=\\frac{2}{3}\\varepsilon_Fg(\\varepsilon_F) and defined the Fermi temperature T_F \\equiv \\varepsilon_F/k_B . So what does all of this mean? Well, our algebraic journey has left us with a heat capacity that is linear in T , which to contrast to the model of Debye, had dependence on T^3 , which fitted the measurements pretty well. Does this mean that we have made things worse? Well let's look closely: The heat capacity of Silver divided by temperature versus the square of the temperature as taken from Atomic Heats of Copper, Silver, and Gold from 1\u00b0K to 5\u00b0K What is the expected behaviour of the plot above as predicted by the Debye model and the Sommerfeld model? We now have two contributions to the heat capacity C_{\\textrm{Sommerfeld}} = \\gamma T and C_{\\textrm{Debye}} = \\alpha T^3 , which should manifest as C = \\gamma T + \\alpha T^3. In the plot above, if we plot C/T , any offest at T=0 is indicative of free-electron behaviour, which we indeed observe. It is worth noting that At room temperature C_{\\textrm{Debye}}\\approx 3Nk_B\\gg C_{\\textrm{Sommerfeld}} \\propto k_B T / T_F , because T \\ll T_F . Near T=0 , the heat capacity due to ocillations C_{\\textrm{Debye}} \\propto k_B (T/T_D)^3 , which becomes smaller than the electron heat capacity at T \\lesssim \\sqrt{T_D^3/T_F}","title":"Crank the handle"},{"location":"04emetalsII/#the-scaling-of-c","text":"The behavior of contribution to C from the free-electron component at low temperature can be intuited via particles within an energy range of \\sim k_{B}T to the Fermi energy \\varepsilon_F become thermally excited, and each carries an extra energy k_{B}T : N_\\mathrm{exc} \\approx g(\\varepsilon_F)k_BT \\\\ E \\sim N_\\mathrm{exc} k_\\mathrm{B} T","title":"The scaling of C"},{"location":"04emetalsII/#example-1-3d-free-electrons","text":"In 3D, g(\\varepsilon_F) is roughly constant. Thus the total energy obtained through thermal excitation is proportional to T \\times \\left( T\\times g(\\varepsilon_F) \\right) , from which it follows that C_e \\propto T .","title":"Example 1: 3D free electrons"},{"location":"04emetalsII/#example-2-graphene","text":"Graphene has a Fermi energy \\varepsilon_F = 0 and a density of states g(\\varepsilon) \\propto \\varepsilon . Therefore, within the energy range of k_BT , g(\\varepsilon) \\propto k_BT . Thus the total energy is proportional to T \\times T^2 and the heat capacity C_e \\propto T^2 .","title":"Example 2: graphene"},{"location":"04emetalsII/#conclusions","text":"The Sommerfeld free-electron model treats electrons as free particles with energy dispersion \\varepsilon = \\frac{\\hbar^2k^2}{2m} . The Fermi-Dirac distribution gives the probability of an electron state to be occupied. The electron contribution to the heat capacity is proportional to T . It is much lower than the heat capacity due to oscillations at high temperatures, and much higher at low temperatures. The scaling of heat capacity with T can be quickly estimated by estimating the number of particles in an energy range k_\\mathrm{B}T from the Fermi energy.","title":"Conclusions"},{"location":"04emetalsII/#exercises","text":"","title":"Exercises"},{"location":"04emetalsII/#preliminary-provocations","text":"Write down the expression for the total energy of particles with the density of states g(\\varepsilon) and the occupation number n_{F}(\\beta(\\varepsilon - \\mu)) . Explain what happens if a material is heated up to its Fermi temperature (assuming that material where this is possible exists). Why can we not use the Sommerfeld expansion with a Fermi energy of the order of the thermal energy? Is the heat capacity of a solid at temperatures near T=0 dominated by electrons or vibrations?","title":"Preliminary provocations"},{"location":"04emetalsII/#exercise-1-potassium","text":"The Sommerfeld model provides a good description of free electrons in alkali metals such as potassium (element K), which has a Fermi energy of \\varepsilon_{F} = 2.12 eV (data from Ashcroft, N. W. and Mermin, N. D., Solid State Physics, Saunders, 1976.). Check the Fermi surface database . Explain why potassium and (most) other alkali metals can be described well with the Sommerfeld model. Calculate the Fermi temperature, Fermi wave vector and Fermi velocity for potassium. Why is the Fermi temperature much higher than room temperature? Calculate the free electron density n in potassium. Compare this with the actual electron density of potassium, which can be calculated by using the density, atomic mass and atomic number of potassium. What can you conclude from this?","title":"Exercise 1: potassium"},{"location":"04emetalsII/#exercise-2-a-hypothetical-material","text":"A hypothetical metal has a Fermi energy \\varepsilon_F = 5.2 \\, \\mathrm{eV} and a density of states g(\\varepsilon) = 2 \\times 10^{10} \\, \\mathrm{eV}^{-\\frac{3}{2}} \\sqrt{\\varepsilon} . Give an integral expression for the total energy of the electrons in this hypothetical material in terms of the density of states g(\\varepsilon) , the temperature T and the chemical potential \\mu = \\varepsilon_F . Find the ground state energy at T = 0 . In order to obtain a good approximation of the integral for non-zero T , one can make use of the Sommerfeld expansion (the first equation is all you need and you can neglect the O\\left(\\frac{1}{\\beta \\mu}\\right)^{4} term). Using this expansion, find the difference between the total energy of the electrons for T = 1000 \\, \\mathrm{K} with that of the ground state. Now, find this difference in energy by calculating the integral found in 1 numerically. Compare your result with 3. Hint You can do numerical integration in python with scipy.integrate.quad(func, xmin, xmax) Calculate the heat capacity for T = 1000 \\, \\mathrm{K} in eV/K. Numerically compute the heat capacity by approximating the derivative of energy difference found in 4 with respect to T . To this end, make use of the fact that \\frac{dy}{dx}=\\lim_{\\Delta x \\to 0} \\frac{y(x + \\Delta x) - y(x - \\Delta x)}{2 \\Delta x}. Compare your result with 5.","title":"Exercise 2: a hypothetical material"},{"location":"04emetalsII/#exercise-4-graphene","text":"One of the most famous recently discovered materials is graphene . It consists of carbon atoms arranged in a 2D honeycomb structure. In this exercise, we will focus on the electrons in bulk graphene. Unlike in metals, electrons in graphene cannot be treated as 'free'. However, close to the Fermi level, the dispersion relation can be approximated by a linear relation: \\varepsilon(\\mathbf{k}) = \\pm c|\\mathbf{k}|. Note that the \\pm here means that there are two energy levels at a specified \\mathbf{k} . The Fermi level is set at \\varepsilon_F = 0 . Make a sketch of the dispersion relation. What other well-known particles have a linear dispersion relation? Using the dispersion relation and assuming periodic boundary conditions, derive an expression for the density of states of graphene. Do not forget spin degeneracy, and take into account that graphene has an additional two-fold 'valley degeneracy' (hence there is a total of a fourfold degeneracy instead of two). Your result should be linear with |\\varepsilon| . Hint It is convenient to first start by only considering the positive energy contributions \\varepsilon(\\mathbf{k}) = + c|\\mathbf{k}| and calculate the density of states for it. Then account for the negative energy contributions \\varepsilon(\\mathbf{k}) = - c|\\mathbf{k}| by adding it to the density of states for the positive energies. You can also make use of \\frac{\\rm{d} |k|}{\\rm{d}k} = \\frac{k}{|k|} . At finite temperatures, assume that electrons close to the Fermi level (i.e. not more than k_B T below the Fermi level) will get thermally excited, thereby increasing their energy by k_B T . Calculate the difference between the energy of the thermally excited state and that of the ground state E(T)-E_0 . To do so, show first that the number of electrons that will get excited is given by n_{ex} = \\frac{1}{2} g(-k_B T) k_B T. Calculate the heat capacity C_e as a function of the temperature T .","title":"Exercise 4: graphene"},{"location":"05chemistry/","text":"Chemisty 101 \u00b6 Cooking in progress The content here is actively being developed; anything before this is \"safe\" and after this is unsafe. Introduction \u00b6 Our journey thus far has been considering the basic properties of solids, and our descriptions have been based around the properties of electrons and vibrations in solids, which can provide useful results but our endeavour is much grander: we would like to explain all the properties of all the solids. The first step on this journey is to no longer consider a collection of free electrons; solids are made up of many atoms, so we best find a way of baking this into whatever we do! Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Quantum mechanics: the Schr\u00f6dinger equation, wavefunction of the Hydrogen atom Mathematics: linear algebra Text reference The material covered here is discussed in section(s) \\S 5, 6.3 of The Oxford Solid State Basics A retrospective \u00b6 Up to this point, we have: Introduced reciprocal ( k -space) Postulated the dispersion relations for free electrons and oscillations in a solid Calculated the heat capacity of free electrons and oscillations in a solid which has premitted The understanding of how materials can store heat via oscillations (Debye model) The understanding of how free electrons conduct (Drude model) and store heat/energy (Sommerfeld model) In constructing these models, we have made several approximations and postulations, and there are a few big questions to answer: In the Debye model, Why is there a cutoff frequency for oscillations? Why are there no modes of ocillation beyond this frequency? In the Drude model, we have electrons modelled as a gas, but why don't electrons scatter off from every the atoms in solid? Why are some materials metallic, and others not metallic? If we are to have a hope of understanding any of the above, we are going to have to understand better what is happening on the atomic scale. Atoms, how do they work? \u00b6 It is no exaggeration to say that everything can be pretty-well described by the Schr\u00f6dinger equation: \\hat{H}\u03c8 = E\u03c8, with \\hat{H} is the Hamiltonian of the system: the sum of kinetic and potential energies. For the hydrogen atom, the potential arises due to the Coulomb interaction between the electron and the nucleus: H=-\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial {\\mathbf r^2}} - \\frac{e^2}{4\\pi\\varepsilon_0|r|} which you will have solved in detail elsewhere. If we move to the next-most-simple atom, helium, the Hamiltonian immediately becomes more complex, containing not just the Coulomb interaction between the individual electrons and the nuclei, but also Coulomb repulsion between the two electrons: H=-\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial {\\mathbf r_1^2}} -\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial {\\mathbf r_2^2}}- \\frac{2e^2}{4\\pi\\varepsilon_0|r_1|} - \\frac{2e^2}{4\\pi\\varepsilon_0|r_2|} + \\frac{e^2}{4\\pi\\varepsilon_0|r_1 - r_2|}. From a purely mathematical point of view, this means we need find eigenvalues and eigenvectors of a six-dimensional PDE, which is much tougher work than the three-dimensional PDE descirbing hydrogen. You have likely seen the variational method to construct appoximate wavefunctions, any even in this case it is a fair amount of work. Let us now turn to another system, a single copper atom. Copper has 29 electrons, so to find the energy spectrum of copper we would need to solve an 87-dimensional Schr\u00f6dinger equation. Such things are totally intractable: there is simply no way to solve such a thing, even with really big computers. It is this growth in complexity with the number of interacting quantum particles is why many-body quantum physics is very much an active research area in solid-state physics and quantum chemistry. But we need not have an analytic solution for everything in order to be satisfied, on the contrary, we can use physical insight and approximations to construct models of complex systems based on simpler, easier to handle systems. To some extent, this is exactly where chemisty takes over: it is often said that Chemisty is applied physics, but they should simply be thought of as the same thing, but with a focus on different parts of the spectrum: the complexity of solving problems in chemistry is the reason why we need to accept empirical observations as chemical laws , even though they work with limited precision and ultimately consequences of the underlying physics as modelled by the Schr\u00f6dinger equation. Quantum numbers and shell filling \u00b6 The electrons in a hydrogen atom can be described by the following four quantum numbers: |n, l, l_z, m_s\u27e9 Quantum numbers: n=1,2,\\ldots is the azimuthal (principal) quantum number l=0, 1, \\ldots, n-1 is the angular momentum (also known as s, p, d, f orbitals) l_z=-l, -l+1\\ldots, l is the z -component of angular momentum m_s is the z -compoment of the spin Below is an illustration of several lowest energy orbitals in hydrogen: (image source: Wikipedia \u00a9 Geek3 CC-BY-SA) It turns out that electrons in other atoms occupy orbitals similar to those of hydrogen, however the electron energies are very different due to the Coulomb interaction. Therefore, we can use our knowledge of the hydrogen orbitals to describe other atoms. When we consider an atom with multiple electrons, we need to determine which orbitals are filled and which are not. The order of orbital filling is set by several rules: Aufbau principle : electrons first fill a complete shell (all electrons with the same n ) before going to the next one Madelung's rule : electrons first occupy the shells with the lowest n+l . If there are several orbitals with equal n+l , electrons occupy those with smaller n Combining the two rules, we obtain the shell filing order: 1s, 2s, 2p, 3s, 3p, 4s, 3d, etc. While these rules accurately predict the electronic structure of most elements, they are only approximate, and fail to describe some of the heavier elements . Shell filing is important to us because the valence electrons (those in the outermost shell) are the only ones participating in chemical reactions and electric conduction. From the valence electrons' point of view, the inner shell electrons act like a negatively charged cloud. The electrostatic repulsion between them reduces the effective charge of the atomic nucleus, but does not play any further role. Covalent bonds and linear combination of atomic orbitals \u00b6 Two atoms \u00b6 Consider two atoms next to each other which form a diatomic molecule. The total Hamiltonian of the system is H = V\u2081 + V\u2082 + K, with V\u2081 the potential due to the first nucleus, V\u2082 due to the second nucleus, and K is the kinetic energy of the electron. Since different orbitals of an atom are separated in energy, we consider one orbital per atom (even though this is often a bad starting point and it should only work for s -orbitals). Let's additionally consider the atoms being sufficiently far apart, such that the shape of the orbitals barely changes due to the presence of the other atom. Let's denote the wave function of an electron bound to the first and second atom |1\u27e9 and |2\u27e9 respectively: \\begin{align} (V\u2081 + K)|1\u27e9 = \u025b_0|1\u27e9,\\\\ (V\u2082 + K)|2\u27e9 = \u025b_0|2\u27e9. \\end{align} Our main idea is to search for a solution in the form: |\u03c8\u27e9 = \u03c6_{1}|1\u27e9 + \u03c6_{2}|2\u27e9. where \u03c6_{1} and \u03c6_{2} are the probability amplitudes of the respective orbitals. The orbital |\u03c8\u27e9 is called a molecular orbital because it describes the entire orbital of the diatomic molecule. The molecular orbital is created as a Linear Combination of Atomic Orbitals ( LCAO ) . For simplicity, we assume that the atomic orbitals are orthogonal 1 , i.e. \u27e81|2\u27e9=0 . Orthogonality ensures that |\u03c8\u27e9 is normalized whenever |\u03c6_1|^2 + |\u03c6_2|^2 = 1 . We apply the Hamiltonian to the molecular orbital |\u03c8\u27e9 : H|\u03c8\u27e9 = E|\u03c8\u27e9 = \u03c6_{1}H|1\u27e9 + \u03c6_{2}H|2\u27e9. Taking the left inner product with \u27e81| , we obtain \u27e81|E|\u03c8\u27e9 = \u03c6_{1}\u27e81|H|1\u27e9 + \u03c6_{2}\u27e81|H|2\u27e9 = E \u03c6_{1}. Similarly, taking the inner product with \u27e82| yields: E \u03c6_2 = \u03c6_{1}\u27e82|H|1\u27e9 + \u03c6_{2}\u27e82|H|2\u27e9. We combine these two equations into an eigenvalue problem: E \\begin{pmatrix} \u03c6_1 \\\\ \u03c6_2 \\end{pmatrix} = \\begin{pmatrix} \u27e81|H|1\u27e9 & \u27e81|H|2\u27e9 \\\\ \u27e82|H|1\u27e9 & \u27e82|H|2\u27e9 \\end{pmatrix} \\begin{pmatrix} \u03c6_1 \\\\ \u03c6_2\\end{pmatrix}. The eigenvalue problem depends only on two parameters: the onsite energy \u27e81|H|1\u27e9 = \u27e82|H|2\u27e9 \\equiv E_0 that gives the energy of an electron occupying either of the orbitals, and the hopping integral (or just hopping ) \u27e81|H|2\u27e9 \\equiv -t that characterizes the energy associated with the electron moving between the two orbitals. Let us examine what contitutes the onsite energy and the hopping: E_0 = \u27e81|H|1\u27e9 = \u27e81|V\u2081 + V\u2082 + K|1\u27e9 = \u025b_0 + \u27e81|V_2|1\u27e9, where we used that V\u2081 + K|1\u27e9 = \u025b_0|1\u27e9 . In other words the onsite energy is the combination of the energy of the original orbital plus the energy shift \u27e81|V_2|1\u27e9 of the electron due to the potential of the neighboring atom. Turning to the hopping, we obtain t = -\u27e81|H|2\u27e9 = -\u27e81|V\u2081 + V\u2082 + K|2\u27e9 = -\u27e81|V\u2081|2\u27e9. All orbitals |n\u27e9 are purely real because we consider bound state solutions of the Schr\u00f6dinger equation. Hence t is real as well. The eigenvalue problem we obtained describes a particle with a discrete 2\u00d72 Hamiltonian: H = \\begin{pmatrix} E_0 & -t \\\\ -t & E_0 \\end{pmatrix}. Diagonalizing this LCAO Hamiltonian yields the following two eigenvalues: E_{\u00b1} = E_0 \u2213 t. The eigenvector corresponding to the eigenvalue E_+ = E_0 - t is even and symmetric: |\u03c8_{+}\u27e9 = \\tfrac{1}{\\sqrt{2}}(|1\u27e9 + |2\u27e9), while the eigenvector with energy E_- = E_0 + t |\u03c8_{-}\u27e9 = \\tfrac{1}{\\sqrt{2}}(|1\u27e9 - |2\u27e9) is odd/antisymmetric. The molecular orbitals are shown in the figure below. According to the node theorem of quantum mechanics, wave functions with lower energies have fewer points where \u03c8=0 . Because \u03c8_- = 0 between the two atoms, and \u03c8_+ is not, we conclude that E_+ < E_- , and therefore t > 0 . Bonding vs antibonding \u00b6 If we decrease the interatomic distance, the two atoms get closer and their atomic orbitals have more overlap. The increase in orbital overlap increases the hopping t . We plot the symmetric and anti-symmetric energies as a function of the inter-atomic distance: When an electron (or two, because there are two states with opposite spin) occupies |\u03c8_+\u27e9 , the atoms attract (or bond ) because the total energy is lowered. Therefore, if t is positive, |\u03c8_+\u27e9 is called the bonding orbital . If an electron occupies the |\u03c8_{-}\u27e9 orbital, the molecular energy increases with decreasing interatomic distance. This means that the atoms repel each other. Hence, if t is positive, |\u03c8_{-}\u27e9 is called the antibonding orbital . Therefore if each atom has a single electron in the outermost shell, these atoms attract because the bonding orbital hosts two electrons with opposite spins. On the other hand, if each atom has 0 or 2 electrons in the outermost shell, the net force from the bonding and antibonding orbitals cancels out, but Coulomb repulsion remains. Summary \u00b6 Electrons in atoms occupy shells, with only electrons in the outermost shell (valence electrons) contributing to interatomic interactions. The molecular orbital can be written as a Linear Combination of Atomic Orbitals ( LCAO ) The LCAO method reduces the full Hamiltonian to a finite size problem written in the basis of individual orbitals. If two atoms have one orbital and one electron each, they occupy the bonding orbital. Exercises \u00b6 Warm-up questions \u00b6 Is the assumption that the atomic orbitals are orthogonal always a reasonable assumption? What happens if the hopping t is chosen to be negative? How does the size of the Hamiltonian matrix change with the number of atoms? How does the size of the Hamiltonian matrix change if each atom now has two orbitals? Assuming that we have two atoms with a single orbital each, what is the size of the Hamiltonian matrix if we also consider the spin of the electron? Exercise 1: Shell-filling model of atoms \u00b6 Describe the shell-filling model of atoms. Use Madelung\u2019s rule to deduce the atomic shellfilling configuration of the element tungsten, which has atomic number 74. Although Madelung\u2019s rule for the filling of electronic shells holds extremely well, there are a number of exceptions to the rule. Here are a few of them: Cu = [Ar] 4s^1 3d^{10} Pd = [Kr] 5s^0 4d^{10} Ag = [Kr] 5s^1 4d^{10} Au = [Xe] 6s^1 4f^{14} 5d^{10} What should the electron configurations be if these elements followed Madelung\u2019s rule and the Aufbau principle? What could be the reason for the deficiency of Madelung's rule? Exercise 2: Application of the LCAO model to the delta-function potential \u00b6 Consider an electron moving in 1D between two negative delta-function shaped potential wells. The complete Hamiltonian of this one-dimensional system is then: \\hat{H} = \\frac{\\hat{p}^2}{2m}-V_0\\delta(x_1-x)-V_0\\delta(x_2-x), where V_0>0 is the potential strength, \\hat{p} the momentum of the electron, and x_1 , x_2 the positions of the potential wells. Properties of a single \\delta -function potential A delta function \\delta(x_0 - x) centered at x_0 is defined to be zero everywhere except for x_0 , where it tends to infinity. Further, a delta function has the property: \\int_{-\\infty}^{\\infty} f(x)\\delta(x_0-x)dx = f(x_0). The procedure to find the energy and a wave function of a state bound in a \\delta -function potential, V=-V_0\\delta(x-x_0) , is similar to that of a quantum well: Assume that we have a bound state with energy E<0 . Compute the wave function \\phi in different regions of space: namely x < x_0 and x > x_0 . Apply the boundary conditions at x = x_0 . The wave function \\phi must be continuous, but d\\phi/dx is not. Instead due to the presence of the delta-function: \\frac{d\\phi}{dx}\\Bigr|_{x_0+\\epsilon} - \\frac{d\\phi}{dx}\\Bigr|_{x_0-\\epsilon}= -\\frac{2mV_0}{\\hbar^2}\\phi(x_0). Find at which energy the boundary conditions at x = x_0 are satisfied. This is the energy of the bound state. Normalize the wave function. Let us apply the LCAO model to solve this problem. Consider the trial wave function for the ground state to be a linear combination of two orbitals |1\u27e9 and |2\u27e9 : |\u03c8\u27e9 = \u03c6_1|1\u27e9 + \u03c6_2|2\u27e9. The orbitals |1\u27e9 and |2\u27e9 correspond to the wave functions of the electron when there is only a single delta peak present: H_1 |1\u27e9 = \\epsilon_1 |1\u27e9, H_2 |2\u27e9 = \\epsilon_2 |2\u27e9. We start of by calculating the wavefunction of an electron bound to a single delta-peak. To do so, you first need to set up the Schr\u00f6dinger equation of a single electron bound to a single delta-peak. You do not have to solve the Schr\u00f6dinger equation twice\u2014you can use the symmetry of the system to calculate the wavefunction of the other electron bound to the second delta-peak. Find the expressions for the wave functions of the states |1\u27e9 and |2\u27e9 : \u03c8_1(x) and \u03c8_2(x) . Also find an expression for their energies \\epsilon_1 and \\epsilon_2 . Remember that you need to normalize the wave functions. Construct the LCAO Hamiltonian. To simplify the calculations, assume that the orbitals are orthogonal. Diagonalize the LCAO Hamiltonian and find an expression for the eigenenergies of the system. It was previously mentioned that V_0>0 . Using this, determine which energy corresponds to the bonding energy. Exercise 3: Polarization of a hydrogen molecule \u00b6 Consider a hydrogen molecule as a one-dimensional system with two identical nuclei at x=-\\frac{d}{2} and x=+\\frac{d}{2} , so that the center of the molecule is at x=0 . Each atom contains a single electron with charge -e . The LCAO Hamiltonian of the system is given by H_{\\textrm{eff}} = \\begin{pmatrix} E_0&&-t \\\\ -t&&E_0 \\end{pmatrix}. Let us add an electric field \\mathcal{E} \\hat{\\bf{x}} to the system. Which term needs to be added to the Hamiltonian of each electron? The electric potential is given by V_{\\mathbf{E}}=-\\int_{C} \\mathbf{E} \\cdot \\mathrm{d} \\boldsymbol{\\ell} Compute the LCAO Hamiltonian of the system in presence of the electric field. What are the new onsite energies of the two orbitals? Diagonalize the modified LCAO Hamiltonian. Find the ground state wavefunction \u03c8 . Find the polarization P of the molecule in the ground state. Reminder: polarization The polarization P of a molecule with n\\leq 2 electrons at its ground state |\u03c8\u27e9 is: P = n e \u27e8\u03c8|x|\u03c8\u27e9. Use that ground state you found in 3.2 is a linear superposition of two orthogonal orbitals centered at -\\frac{d}{2} and +\\frac{d}{2} . See the book exercise 6.5 for relaxing the orthogonality assumption. \u21a9","title":"Chemistry 101"},{"location":"05chemistry/#chemisty-101","text":"Cooking in progress The content here is actively being developed; anything before this is \"safe\" and after this is unsafe.","title":"Chemisty 101"},{"location":"05chemistry/#introduction","text":"Our journey thus far has been considering the basic properties of solids, and our descriptions have been based around the properties of electrons and vibrations in solids, which can provide useful results but our endeavour is much grander: we would like to explain all the properties of all the solids. The first step on this journey is to no longer consider a collection of free electrons; solids are made up of many atoms, so we best find a way of baking this into whatever we do! Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Quantum mechanics: the Schr\u00f6dinger equation, wavefunction of the Hydrogen atom Mathematics: linear algebra Text reference The material covered here is discussed in section(s) \\S 5, 6.3 of The Oxford Solid State Basics","title":"Introduction"},{"location":"05chemistry/#a-retrospective","text":"Up to this point, we have: Introduced reciprocal ( k -space) Postulated the dispersion relations for free electrons and oscillations in a solid Calculated the heat capacity of free electrons and oscillations in a solid which has premitted The understanding of how materials can store heat via oscillations (Debye model) The understanding of how free electrons conduct (Drude model) and store heat/energy (Sommerfeld model) In constructing these models, we have made several approximations and postulations, and there are a few big questions to answer: In the Debye model, Why is there a cutoff frequency for oscillations? Why are there no modes of ocillation beyond this frequency? In the Drude model, we have electrons modelled as a gas, but why don't electrons scatter off from every the atoms in solid? Why are some materials metallic, and others not metallic? If we are to have a hope of understanding any of the above, we are going to have to understand better what is happening on the atomic scale.","title":"A retrospective"},{"location":"05chemistry/#atoms-how-do-they-work","text":"It is no exaggeration to say that everything can be pretty-well described by the Schr\u00f6dinger equation: \\hat{H}\u03c8 = E\u03c8, with \\hat{H} is the Hamiltonian of the system: the sum of kinetic and potential energies. For the hydrogen atom, the potential arises due to the Coulomb interaction between the electron and the nucleus: H=-\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial {\\mathbf r^2}} - \\frac{e^2}{4\\pi\\varepsilon_0|r|} which you will have solved in detail elsewhere. If we move to the next-most-simple atom, helium, the Hamiltonian immediately becomes more complex, containing not just the Coulomb interaction between the individual electrons and the nuclei, but also Coulomb repulsion between the two electrons: H=-\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial {\\mathbf r_1^2}} -\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial {\\mathbf r_2^2}}- \\frac{2e^2}{4\\pi\\varepsilon_0|r_1|} - \\frac{2e^2}{4\\pi\\varepsilon_0|r_2|} + \\frac{e^2}{4\\pi\\varepsilon_0|r_1 - r_2|}. From a purely mathematical point of view, this means we need find eigenvalues and eigenvectors of a six-dimensional PDE, which is much tougher work than the three-dimensional PDE descirbing hydrogen. You have likely seen the variational method to construct appoximate wavefunctions, any even in this case it is a fair amount of work. Let us now turn to another system, a single copper atom. Copper has 29 electrons, so to find the energy spectrum of copper we would need to solve an 87-dimensional Schr\u00f6dinger equation. Such things are totally intractable: there is simply no way to solve such a thing, even with really big computers. It is this growth in complexity with the number of interacting quantum particles is why many-body quantum physics is very much an active research area in solid-state physics and quantum chemistry. But we need not have an analytic solution for everything in order to be satisfied, on the contrary, we can use physical insight and approximations to construct models of complex systems based on simpler, easier to handle systems. To some extent, this is exactly where chemisty takes over: it is often said that Chemisty is applied physics, but they should simply be thought of as the same thing, but with a focus on different parts of the spectrum: the complexity of solving problems in chemistry is the reason why we need to accept empirical observations as chemical laws , even though they work with limited precision and ultimately consequences of the underlying physics as modelled by the Schr\u00f6dinger equation.","title":"Atoms, how do they work?"},{"location":"05chemistry/#quantum-numbers-and-shell-filling","text":"The electrons in a hydrogen atom can be described by the following four quantum numbers: |n, l, l_z, m_s\u27e9 Quantum numbers: n=1,2,\\ldots is the azimuthal (principal) quantum number l=0, 1, \\ldots, n-1 is the angular momentum (also known as s, p, d, f orbitals) l_z=-l, -l+1\\ldots, l is the z -component of angular momentum m_s is the z -compoment of the spin Below is an illustration of several lowest energy orbitals in hydrogen: (image source: Wikipedia \u00a9 Geek3 CC-BY-SA) It turns out that electrons in other atoms occupy orbitals similar to those of hydrogen, however the electron energies are very different due to the Coulomb interaction. Therefore, we can use our knowledge of the hydrogen orbitals to describe other atoms. When we consider an atom with multiple electrons, we need to determine which orbitals are filled and which are not. The order of orbital filling is set by several rules: Aufbau principle : electrons first fill a complete shell (all electrons with the same n ) before going to the next one Madelung's rule : electrons first occupy the shells with the lowest n+l . If there are several orbitals with equal n+l , electrons occupy those with smaller n Combining the two rules, we obtain the shell filing order: 1s, 2s, 2p, 3s, 3p, 4s, 3d, etc. While these rules accurately predict the electronic structure of most elements, they are only approximate, and fail to describe some of the heavier elements . Shell filing is important to us because the valence electrons (those in the outermost shell) are the only ones participating in chemical reactions and electric conduction. From the valence electrons' point of view, the inner shell electrons act like a negatively charged cloud. The electrostatic repulsion between them reduces the effective charge of the atomic nucleus, but does not play any further role.","title":"Quantum numbers and shell filling"},{"location":"05chemistry/#covalent-bonds-and-linear-combination-of-atomic-orbitals","text":"","title":"Covalent bonds and linear combination of atomic orbitals"},{"location":"05chemistry/#two-atoms","text":"Consider two atoms next to each other which form a diatomic molecule. The total Hamiltonian of the system is H = V\u2081 + V\u2082 + K, with V\u2081 the potential due to the first nucleus, V\u2082 due to the second nucleus, and K is the kinetic energy of the electron. Since different orbitals of an atom are separated in energy, we consider one orbital per atom (even though this is often a bad starting point and it should only work for s -orbitals). Let's additionally consider the atoms being sufficiently far apart, such that the shape of the orbitals barely changes due to the presence of the other atom. Let's denote the wave function of an electron bound to the first and second atom |1\u27e9 and |2\u27e9 respectively: \\begin{align} (V\u2081 + K)|1\u27e9 = \u025b_0|1\u27e9,\\\\ (V\u2082 + K)|2\u27e9 = \u025b_0|2\u27e9. \\end{align} Our main idea is to search for a solution in the form: |\u03c8\u27e9 = \u03c6_{1}|1\u27e9 + \u03c6_{2}|2\u27e9. where \u03c6_{1} and \u03c6_{2} are the probability amplitudes of the respective orbitals. The orbital |\u03c8\u27e9 is called a molecular orbital because it describes the entire orbital of the diatomic molecule. The molecular orbital is created as a Linear Combination of Atomic Orbitals ( LCAO ) . For simplicity, we assume that the atomic orbitals are orthogonal 1 , i.e. \u27e81|2\u27e9=0 . Orthogonality ensures that |\u03c8\u27e9 is normalized whenever |\u03c6_1|^2 + |\u03c6_2|^2 = 1 . We apply the Hamiltonian to the molecular orbital |\u03c8\u27e9 : H|\u03c8\u27e9 = E|\u03c8\u27e9 = \u03c6_{1}H|1\u27e9 + \u03c6_{2}H|2\u27e9. Taking the left inner product with \u27e81| , we obtain \u27e81|E|\u03c8\u27e9 = \u03c6_{1}\u27e81|H|1\u27e9 + \u03c6_{2}\u27e81|H|2\u27e9 = E \u03c6_{1}. Similarly, taking the inner product with \u27e82| yields: E \u03c6_2 = \u03c6_{1}\u27e82|H|1\u27e9 + \u03c6_{2}\u27e82|H|2\u27e9. We combine these two equations into an eigenvalue problem: E \\begin{pmatrix} \u03c6_1 \\\\ \u03c6_2 \\end{pmatrix} = \\begin{pmatrix} \u27e81|H|1\u27e9 & \u27e81|H|2\u27e9 \\\\ \u27e82|H|1\u27e9 & \u27e82|H|2\u27e9 \\end{pmatrix} \\begin{pmatrix} \u03c6_1 \\\\ \u03c6_2\\end{pmatrix}. The eigenvalue problem depends only on two parameters: the onsite energy \u27e81|H|1\u27e9 = \u27e82|H|2\u27e9 \\equiv E_0 that gives the energy of an electron occupying either of the orbitals, and the hopping integral (or just hopping ) \u27e81|H|2\u27e9 \\equiv -t that characterizes the energy associated with the electron moving between the two orbitals. Let us examine what contitutes the onsite energy and the hopping: E_0 = \u27e81|H|1\u27e9 = \u27e81|V\u2081 + V\u2082 + K|1\u27e9 = \u025b_0 + \u27e81|V_2|1\u27e9, where we used that V\u2081 + K|1\u27e9 = \u025b_0|1\u27e9 . In other words the onsite energy is the combination of the energy of the original orbital plus the energy shift \u27e81|V_2|1\u27e9 of the electron due to the potential of the neighboring atom. Turning to the hopping, we obtain t = -\u27e81|H|2\u27e9 = -\u27e81|V\u2081 + V\u2082 + K|2\u27e9 = -\u27e81|V\u2081|2\u27e9. All orbitals |n\u27e9 are purely real because we consider bound state solutions of the Schr\u00f6dinger equation. Hence t is real as well. The eigenvalue problem we obtained describes a particle with a discrete 2\u00d72 Hamiltonian: H = \\begin{pmatrix} E_0 & -t \\\\ -t & E_0 \\end{pmatrix}. Diagonalizing this LCAO Hamiltonian yields the following two eigenvalues: E_{\u00b1} = E_0 \u2213 t. The eigenvector corresponding to the eigenvalue E_+ = E_0 - t is even and symmetric: |\u03c8_{+}\u27e9 = \\tfrac{1}{\\sqrt{2}}(|1\u27e9 + |2\u27e9), while the eigenvector with energy E_- = E_0 + t |\u03c8_{-}\u27e9 = \\tfrac{1}{\\sqrt{2}}(|1\u27e9 - |2\u27e9) is odd/antisymmetric. The molecular orbitals are shown in the figure below. According to the node theorem of quantum mechanics, wave functions with lower energies have fewer points where \u03c8=0 . Because \u03c8_- = 0 between the two atoms, and \u03c8_+ is not, we conclude that E_+ < E_- , and therefore t > 0 .","title":"Two atoms"},{"location":"05chemistry/#bonding-vs-antibonding","text":"If we decrease the interatomic distance, the two atoms get closer and their atomic orbitals have more overlap. The increase in orbital overlap increases the hopping t . We plot the symmetric and anti-symmetric energies as a function of the inter-atomic distance: When an electron (or two, because there are two states with opposite spin) occupies |\u03c8_+\u27e9 , the atoms attract (or bond ) because the total energy is lowered. Therefore, if t is positive, |\u03c8_+\u27e9 is called the bonding orbital . If an electron occupies the |\u03c8_{-}\u27e9 orbital, the molecular energy increases with decreasing interatomic distance. This means that the atoms repel each other. Hence, if t is positive, |\u03c8_{-}\u27e9 is called the antibonding orbital . Therefore if each atom has a single electron in the outermost shell, these atoms attract because the bonding orbital hosts two electrons with opposite spins. On the other hand, if each atom has 0 or 2 electrons in the outermost shell, the net force from the bonding and antibonding orbitals cancels out, but Coulomb repulsion remains.","title":"Bonding vs antibonding"},{"location":"05chemistry/#summary","text":"Electrons in atoms occupy shells, with only electrons in the outermost shell (valence electrons) contributing to interatomic interactions. The molecular orbital can be written as a Linear Combination of Atomic Orbitals ( LCAO ) The LCAO method reduces the full Hamiltonian to a finite size problem written in the basis of individual orbitals. If two atoms have one orbital and one electron each, they occupy the bonding orbital.","title":"Summary"},{"location":"05chemistry/#exercises","text":"","title":"Exercises"},{"location":"05chemistry/#warm-up-questions","text":"Is the assumption that the atomic orbitals are orthogonal always a reasonable assumption? What happens if the hopping t is chosen to be negative? How does the size of the Hamiltonian matrix change with the number of atoms? How does the size of the Hamiltonian matrix change if each atom now has two orbitals? Assuming that we have two atoms with a single orbital each, what is the size of the Hamiltonian matrix if we also consider the spin of the electron?","title":"Warm-up questions"},{"location":"05chemistry/#exercise-1-shell-filling-model-of-atoms","text":"Describe the shell-filling model of atoms. Use Madelung\u2019s rule to deduce the atomic shellfilling configuration of the element tungsten, which has atomic number 74. Although Madelung\u2019s rule for the filling of electronic shells holds extremely well, there are a number of exceptions to the rule. Here are a few of them: Cu = [Ar] 4s^1 3d^{10} Pd = [Kr] 5s^0 4d^{10} Ag = [Kr] 5s^1 4d^{10} Au = [Xe] 6s^1 4f^{14} 5d^{10} What should the electron configurations be if these elements followed Madelung\u2019s rule and the Aufbau principle? What could be the reason for the deficiency of Madelung's rule?","title":"Exercise 1: Shell-filling model of atoms"},{"location":"05chemistry/#exercise-2-application-of-the-lcao-model-to-the-delta-function-potential","text":"Consider an electron moving in 1D between two negative delta-function shaped potential wells. The complete Hamiltonian of this one-dimensional system is then: \\hat{H} = \\frac{\\hat{p}^2}{2m}-V_0\\delta(x_1-x)-V_0\\delta(x_2-x), where V_0>0 is the potential strength, \\hat{p} the momentum of the electron, and x_1 , x_2 the positions of the potential wells. Properties of a single \\delta -function potential A delta function \\delta(x_0 - x) centered at x_0 is defined to be zero everywhere except for x_0 , where it tends to infinity. Further, a delta function has the property: \\int_{-\\infty}^{\\infty} f(x)\\delta(x_0-x)dx = f(x_0). The procedure to find the energy and a wave function of a state bound in a \\delta -function potential, V=-V_0\\delta(x-x_0) , is similar to that of a quantum well: Assume that we have a bound state with energy E<0 . Compute the wave function \\phi in different regions of space: namely x < x_0 and x > x_0 . Apply the boundary conditions at x = x_0 . The wave function \\phi must be continuous, but d\\phi/dx is not. Instead due to the presence of the delta-function: \\frac{d\\phi}{dx}\\Bigr|_{x_0+\\epsilon} - \\frac{d\\phi}{dx}\\Bigr|_{x_0-\\epsilon}= -\\frac{2mV_0}{\\hbar^2}\\phi(x_0). Find at which energy the boundary conditions at x = x_0 are satisfied. This is the energy of the bound state. Normalize the wave function. Let us apply the LCAO model to solve this problem. Consider the trial wave function for the ground state to be a linear combination of two orbitals |1\u27e9 and |2\u27e9 : |\u03c8\u27e9 = \u03c6_1|1\u27e9 + \u03c6_2|2\u27e9. The orbitals |1\u27e9 and |2\u27e9 correspond to the wave functions of the electron when there is only a single delta peak present: H_1 |1\u27e9 = \\epsilon_1 |1\u27e9, H_2 |2\u27e9 = \\epsilon_2 |2\u27e9. We start of by calculating the wavefunction of an electron bound to a single delta-peak. To do so, you first need to set up the Schr\u00f6dinger equation of a single electron bound to a single delta-peak. You do not have to solve the Schr\u00f6dinger equation twice\u2014you can use the symmetry of the system to calculate the wavefunction of the other electron bound to the second delta-peak. Find the expressions for the wave functions of the states |1\u27e9 and |2\u27e9 : \u03c8_1(x) and \u03c8_2(x) . Also find an expression for their energies \\epsilon_1 and \\epsilon_2 . Remember that you need to normalize the wave functions. Construct the LCAO Hamiltonian. To simplify the calculations, assume that the orbitals are orthogonal. Diagonalize the LCAO Hamiltonian and find an expression for the eigenenergies of the system. It was previously mentioned that V_0>0 . Using this, determine which energy corresponds to the bonding energy.","title":"Exercise 2: Application of the LCAO model to the delta-function potential"},{"location":"05chemistry/#exercise-3-polarization-of-a-hydrogen-molecule","text":"Consider a hydrogen molecule as a one-dimensional system with two identical nuclei at x=-\\frac{d}{2} and x=+\\frac{d}{2} , so that the center of the molecule is at x=0 . Each atom contains a single electron with charge -e . The LCAO Hamiltonian of the system is given by H_{\\textrm{eff}} = \\begin{pmatrix} E_0&&-t \\\\ -t&&E_0 \\end{pmatrix}. Let us add an electric field \\mathcal{E} \\hat{\\bf{x}} to the system. Which term needs to be added to the Hamiltonian of each electron? The electric potential is given by V_{\\mathbf{E}}=-\\int_{C} \\mathbf{E} \\cdot \\mathrm{d} \\boldsymbol{\\ell} Compute the LCAO Hamiltonian of the system in presence of the electric field. What are the new onsite energies of the two orbitals? Diagonalize the modified LCAO Hamiltonian. Find the ground state wavefunction \u03c8 . Find the polarization P of the molecule in the ground state. Reminder: polarization The polarization P of a molecule with n\\leq 2 electrons at its ground state |\u03c8\u27e9 is: P = n e \u27e8\u03c8|x|\u03c8\u27e9. Use that ground state you found in 3.2 is a linear superposition of two orthogonal orbitals centered at -\\frac{d}{2} and +\\frac{d}{2} . See the book exercise 6.5 for relaxing the orthogonality assumption. \u21a9","title":"Exercise 3: Polarization of a hydrogen molecule"},{"location":"06tightbinding/","text":"The tight binding model \u00b6 Unbaked The content here is still very much under development. Please come back soon! Introduction \u00b6 The kinetic theory of Drude was a great first step in trying to answer the question \"metals, how do they work?\", but it was clear from the outset that there were problems with the theory. But with the discovery of the Pauli exclusion principle, it seemed only logical that with the inclusion of the fundamental property of the electrons, life would improve. Indeed it does... Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Statistical mechanics: familiarity with Fermi-Dirac statistics Quantum mechanics: Wavefunction of a free (unbound) electron Text reference The material covered here is discussed in section(s) \\S 4 of The Oxford Solid State Basics Electrons and phonons in 1D \u00b6 (based on chapters 9.1-9.3 & 11.1-11.3 of the book) Expected prior knowledge Before the start of this lecture, you should be able to: Derive Newton's equations of motion of a triatomic chain (previous lecture). Write down the dispersion relation of phonons in the Debye model. Express complex exponentials through trigonometric functions and vice versa. Apply Taylor expansion trigonometric functions. Take derivatives inverse trigonometric functions. Learning goals After this lecture you will be able to: Formulate the equations of motion of electrons and phonons in 1D. Derive the dispersion relation from the equations of motion. Derive the group velocity, effective mass, and density of states from the dispersion relation. Last lecture: Vibrational modes of few-atom chains (analyzed using Newton's equations) Orbital energies of electrons in few-atom chains (analyzed using LCAOs) This lecture: Phonons and electrons in chains of infinitely many atoms. Main idea: use periodicity in space, similar to periodicity in time To emphasize the similarities and the differences between electrons and phonons, we will deal with both types of particles at once. Equations of motion \u00b6 Phonons \u00b6 In the Debye model, we assumed that the dispersion relation is strictly linear in k . Now is the time to revisit this assumption. To do that, let us consider a 1D homogeneous chain of atoms. We assume that the atoms in the chain interact only with their nearest neighbors through a harmonic potential, like we derived in the previous lecture . In other words, we model the atoms as point masses connected by identical springs. We denote the displacement of atom n from equilibrium by u_n . Within this convention, Newton's equation of motion for the n -th atom is given by: m \\ddot{u}_n = -\\kappa (u_n - u_{n-1}) -\\kappa (u_n - u_{n+1}). We use the periodic boundary conditions just like we did in the Sommerfield model. The boundary conditions imply that in a system of size L = Na , we have u_N = u_0 . Electrons \u00b6 The following figure shows the interatomic potential with atoms placed at x_k = ka with k \\in \\mathbb{Z} : x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 )) ax . set_ylim ( -. 7 , . 5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ -. 05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) Similarly to the triatomic system case, we formulate the molecular orbital via the LCAO model: \\vert \\Psi \\rangle = \\sum_n \\phi_n |n \\rangle. We assume only nearest-neighbor hopping -t and an on-site energy E_0 . The coupled Schr\u00f6dinger equation of the |n \\rangle orbital is: E \\phi_n = E_0 \\phi_n - t \\phi_{n+1} - t \\phi_{n-1}. Again, the periodic boundary conditions imply \\phi_N = \\phi_0 . We now have the equations of motion of both phonons and electrons. All that remains is to solve them. Key idea for solving these equations \u00b6 In order to solve the equations of motion, we need to come up with a reasonable guess. If we take a look at the equations of motion, we see that they are the same for all atoms. To be specific, the structure of the equations is the same no matter what value of n we choose. Since these equations define the solutions, we reason that the solutions should also be independent of the choice of n . As a result, we assume a plane wave solution, also called a plane wave ansatz , with the same amplitude for each atom. In the case of phonons, we obtain u_n = Ae^{i \\omega t - i k x_n}, and the ansatz for electrons is given similarly by \\phi_n = Be^{i E t/\\hbar - i k x_n}. We wrote x_n=na and we wrote the time-dependent solution of the Schr\u00f6dinger equation to emphasize the similarity between the two systems. We already know that the periodic boundary conditions only allow plane waves with k being a multiple of 2\\pi/L . In the case of the electron system, periodic boundary conditions give \\phi_0 = \\phi_N , which results in 1 = e^{ik0} = e^{ikNa}. The above equation defines the allowed values of k : k = \\frac{2 \\pi p}{Na}, \\quad \\text{with} p \\in \\mathbb{Z}. We use the quantized values of k in our plane wave ansatz: e^{ikx_n} = e^{i p \\frac{2\\pi}{Na} n a} = e^{i \\frac{2 \\pi n p}{N}} . We notice something interesting if we investigate the case of p\u2192p+N . In this case, the plane wave ansatz becomes e^{i \\frac{2\\pi n(p+N)}{N}} = e^{i \\frac{2\\pi np}{N} + i2\\pi n} = e^{i \\frac{2\\pi np}{N}} , which is exactly the same solution. Counting the number of inequivalent plane waves, we find exactly N different solutions in total. All that is left is to find the energy of each solution! The reason why solutions with different values of k are identical is aliasing : because the plane wave is only defined at discrete positions, acquiring a phase factor of 2\u03c0 between two atoms is equivalent to nothing happening: x = np . linspace ( -. 2 , 2.8 , 500 ) fig , ax = pyplot . subplots () ax . plot ( x , np . cos ( pi * ( x )), label = r '$k=\\pi/a$' ) ax . plot ( x , np . cos ( 3 * pi * ( x )), label = r '$k=3\\pi/a$' ) ax . plot ( x , np . cos ( 5 * pi * ( x )), label = r '$k=5\\pi/a$' ) sites = np . arange ( 3 ) ax . scatter ( sites , np . cos ( pi * ( sites )), c = 'k' , s = 64 , zorder = 5 ) ax . set_xlabel ( '$x$' ) ax . set_ylabel ( '$u_n$' ) ax . set_xlim (( -. 1 , 3.2 )) ax . set_ylim (( - 1.3 , 1.3 )) ax . legend ( loc = 'lower right' ) draw_classic_axes ( ax ) ax . annotate ( s = '' , xy = ( 0 , - 1.1 ), xytext = ( 1 , - 1.1 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) ax . text ( . 5 , - 1.25 , '$a$' , ha = 'center' ); How many different solutions did we expect to find? We have a system with N degrees of freedom (either u_n or \\phi_n ), and therefore we expect N normal modes (or eigenstates). Solving the equations of motion \u00b6 Phonons \u00b6 We substitute the plane wave ansatz into the equations of motion: -m \\omega^2 A e^{i\\omega t - ikx_n} = \\kappa A e^{i\\omega t}(-2 e^{-ikx_n} + e^{-ikx_n+ika}+ e^{-ikx_n-ika}). Searching for solutions with A \\neq 0 we obtain -m \\omega^2 = \\kappa (-2 + e^{ika}+ e^{-ika})=\\kappa [-2 + 2\\cos(ka)]. Or after a further simplification: \\omega = \\sqrt{\\frac{2\\kappa}{m}}\\sqrt{1-\\cos(ka)}= 2\\sqrt{\\frac{\\kappa}{m}}|\\sin(ka/2)|, where we substituted 1-\\cos(x) = 2\\sin^2(x/2) . We arrive at the phonon dispersion relation shown below. k = np . linspace ( - 2 * pi , 6 * pi , 500 ) fig , ax = pyplot . subplots () pyplot . plot ( k , np . abs ( np . sin ( k / 2 ))) ax . set_ylim ( bottom = 0 , top = 1.2 ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\\omega$' ) pyplot . xticks ( list ( 2 * pi * np . arange ( - 1 , 4 )) + [ - pi , pi ], [ r '$-2\\pi$' , '$0$' , r '$2\\pi$' , r '$4\\pi$' , r '$6\\pi$' , r '$-\\pi$' , r '$\\pi$' ]) pyplot . yticks ([ 1 ], [ r '$2\\sqrt{\\frac{\\kappa} {m} }$' ]) pyplot . vlines ([ - pi , pi ], 0 , 1.1 , linestyles = 'dashed' ) pyplot . hlines ([ 1 ], . 1 * pi , 1.3 * pi , linestyles = 'dashed' ) draw_classic_axes ( ax ); # ax.annotate(s='', xy=(-pi, -.15), xytext=(pi, -.15), # arrowprops=dict(arrowstyle='<->', shrinkA=0, shrinkB=0)) # ax.text(0, -.25, '1st Brillouin zone', ha='center') # ax.set_ylim(bottom=-.3); The periodicity of the dispersion relation is a consequence of what we observed before: since plane waves with k -vectors differing by 2\u03c0/a are exactly the same, the repeated periods of the dispersion relation describe the same plane waves. Comparison to the Debye model \u00b6 Sound velocity: At small k , \\sin(ka/2)\\approx ka/2 . Therefore \\omega \\approx \\sqrt{\\kappa/m} k a = v_sk , with v_s the sound velocity. We therefore justify the linear dispersion approximation in the Debye model! Cut-off frequency: The Debye model introduces the cutoff frequency \\omega_D to limit the number of phonon modes, and does not identify the origin of the cutoff. Now because of the finite number of plane waves, the integration over the k -space has a finite size: \\sum_p \u2192 \\frac{L}{2\\pi}\\int_{-\\pi/a}^{\\pi/a}dk . This automatically gives us a maximal frequency without additional assumptions. Electrons \u00b6 Once again we substitute the plane wave ansatz into the equations of motion: E Ae^{iEt/\\hbar-ikna} = E_0 Ae^{iEt/\\hbar-ikna} - t Ae^{iEt/\\hbar-ik(n+1)a} - t Ae^{iEt/\\hbar-ik(n-1)a}, Again, we are not interested in a trivial solution, hence we assume A \\neq 0 and thus E = E_0 -te^{-ika} -te^{ika} = E_0 - 2t\\cos(ka), which gives us the dispersion relation below. pyplot . figure () k = np . linspace ( - pi , pi , 300 ) pyplot . plot ( k , - np . cos ( k )) pyplot . xlabel ( '$ka$' ); pyplot . ylabel ( '$E$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , 0 , r '$\\pi$' ]) pyplot . yticks ([ - 1 , 0 , 1 ], [ '$E_0-2t$' , '$E_0$' , '$E_0+2t$' ]); We see that the electron dispersion consists of a band of allowed energies E_0 -2t < E < E_0 + 2t . That particles occupy bands of allowed energies is why a dispersion relation is also often called a band structure . Due to the spin degeneracy, each band has 2 N possible states if we consider a system with N atoms. If each atom contains 2 electrons and a single orbital, all the states in the band must be occupied by electrons. Because all the available states are occupied, there is always exactly the same number of electrons moving in the positive direction, as there are in the negative. Hence, no matter what we do, our system is incapable of conducting electrons, and therefore we have derived the existence of insulators! Let us also compare the electron band structure with the free electron model. Focusing on the dispersion relation close to the band bottom at k=0 , we approximate the energy as E \\approx E_0 - 2t + t (ka)^2. If we compare this to the dispersion relation E=\\hbar k^2/2m of the free electrons model, we see that the band structure is similar, but the lowest available energy is E_0-2t instead of 0 , and the electrons behave as if they had a different mass m^*=\\hbar^2/2ta^2 . Group velocity, effective mass, density of states \u00b6 (here we only discuss electrons; for phonons everything is the same except for replacing E = \\hbar \\omega ) Let us think what happens if we apply an external electric field to the crystal: x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 ) + . 2 * ( x - 1.5 )) ax . plot ( x , . 2 * ( x - 0.25 ), '--' ) ax . set_ylim ( -. 7 , . 5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ -. 05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) The full Hamiltonian of the system is H = \\frac{p^2}{2m} + U_\\textrm{atomic}(x) + e \\mathcal{E} x, where U_\\textrm{atomic} is the potential created by the nuclei, and \\mathcal{E} the electric field. A typical electric field is much smaller than the interatomic potential, and therefore we can start by obtaining the dispersion relation E(k) without electric field (by applying the LCAO method), and then solve H = E(k) + e\\mathcal{E}x. To derive how particles with an arbitrary dispersion relation move, we recall the Hamilton's equations for particle velocity v and force F : \\begin{aligned} v \\equiv \\frac{dr}{dt} &= \\frac{\\partial H(p, r)}{\\partial p}\\\\ F \\equiv \\frac{dp}{dt} &= -\\frac{\\partial H(p, r)}{\\partial r}. \\end{aligned} Substituting p = \\hbar k into the first equation we arrive to the expression for the electron group velocity v \\equiv \\hbar^{-1}\\partial E/\\partial k . From the second equation we obtain that the force acting on electron in a band stays -e\\mathcal{E} , which in turn gives results in the acceleration \\frac{dv}{dt} = \\frac{\u2202v}{\u2202p}\\frac{dp}{dt} = F/m. Comparing this expression with dv/dt = F/m , we arrive to the effective mass : m^* \\equiv \\left(\\frac{\u2202v}{\u2202p}\\right)^{-1} = \\left(\\frac{\u2202\u00b2E}{\u2202p\u00b2}\\right)^{-1} = \u0127\u00b2\\left(\\frac{\u2202\u00b2E}{\u2202k\u00b2}\\right)^{-1}. The group velocity describes how quickly electrons with a certain k -vector move, while the effective mass describes how hard they are to accelerate by applying external force. By using the dispersion relation we derived earlier, we obtain the effective mass like this: pyplot . figure ( figsize = ( 8 , 5 )) k = np . linspace ( - pi , pi , 300 ) meff = 1 / np . cos ( k ) color = list ( matplotlib . rcParams [ 'axes.prop_cycle' ])[ 0 ][ 'color' ] pyplot . plot ( k [ meff > 0 ], meff [ meff > 0 ], c = color ) pyplot . plot ( k [ meff < 0 ], meff [ meff < 0 ], c = color ) pyplot . ylim ( - 5 , 5 ) pyplot . xlabel ( '$ka$' ); pyplot . ylabel ( '$m^*$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , 0 , r '$\\pi$' ]); Notice that the effective mass can be negative, which implies the electrons accelerate in the direction opposite to the applied force. Density of states \u00b6 The DOS is the number of states per unit energy. In 1D we have g(E) = \\frac{L}{2\\pi}\\sum |dk/dE| = \\frac{L}{2\\pi}\\sum |v|^{-1} The sum goes over all possible values of k and spin which have the same energy E . If we are working in two or more dimensions, we must integrate over the values of k with the same energy. Also take note that for energies below E_0 - 2t or above E_0 + 2t , there are no values of k with that energy, so there is nothing to sum over. Once again, starting from E = E_0 - 2t \\cos(ka), we get ka = \\pm\\arccos[(E - E_0) / 2t], and |v| ^{-1} = \\left|\\frac{dk}{dE} \\right| = \\frac{1}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. You can get to this result immediately if you remember the derivative of arccosine. Otherwise you need to go the long way: compute dE/dk as a function of k , express k through E as we did above, and take the inverse. We now add together the contributions of the positive and the negative momenta as well both spin orientations, and arrive to the density of states g(E) = \\frac{L}{2\\pi}\\frac{4}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. A quick check: when the energy is close to the bottom of the band, E = E_0 - 2t + \\delta E , we get g(E) \\propto \\delta E^{-1/2} , as we expect in 1D. The process of calculating the DOS at a given energy E of a spin-independent Hamiltonian is done systematically with the following steps: At a given energy E , determine all of the values of k which correspond to that E using the dispersion relation. Compute \\rvert dk / dE \\rvert . Do this either by writing k as a (multi-valued) function of E and differentiating, or by computing (dE / dk)^{-1} . Sum or integrate dk / dE over the allowed values of k found in 1 and multiply by any degeneracies (spin/polarization). Multiply by spin degeneracy. If the Hamiltonian depends on spin, then there is no spin degeneracy and the spin number s must be treated in the same way as k . Summary \u00b6 By using plane waves in real space as an Ansatz we found all normal modes and energies for phonons and electrons in 1D Computing dispersion relations explains the problems we listed before (need for cutoff, lack of scattering with every single atom, existence of insulators). Electrons and phonons have a complicated nonlinear relation between momentum and velocity ( group velocity ), effective mass, and density of states. Exercises \u00b6 Warm-up questions \u00b6 Compare the expression of the effective mass with Newton's second law. Do you observe any similarities? Check the units of the group velocity. Is it what you expect? Do the same for the effective mass. Calculate the effective mass of the free-electron dispersion relation. Is this what was expected? Under what condition is the effective mass the same for each electron? Exercise 1: Lattice vibrations \u00b6 From the dispersion relation of a 1D monatomic chain given in the lecture notes, calculate the group velocity v_g . Using the group veolcity found above, calculate the density of states g(\\omega) . Sketch them. From the 1D dispersion relation \\omega(k) in the picture below, sketch the group velocity v_g(k) and the density of states g(\\omega) . Exercise 2: Vibrational heat capacity of a 1D monatomic chain \u00b6 Give the total energy U of a 1D monatomic chain as an integral expression. To do so, first derive the density of states from the phonon dispersion relation derived in the lecture notes. Give an integral expression for the heat capacity C . Compute the heat capacity numerically, using e.g. Python. Do the same for C in the Debye model and compare the two. What differences do you see? Exercise 3: Next-nearest neighbors chain \u00b6 Consider electrons in a 1D atomic chain again: x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 )) ax . set_ylim ( -. 7 , . 5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ -. 05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) Let's expand the one-dimensional chain model by extending the range of the interaction further than the nearest neighbors: \\langle \\phi_n | H | \\phi_{n+2}\\rangle \\equiv -t' \u2260 0. Write down the new Schr\u00f6dinger equation for this system. hint There are now two more terms in the equation: -t' \\phi_{n-2} - t' \\phi_{n+2} . Solve the Schr\u00f6dinger equation to find the dispersion relation E(k) . hint Use the same Ansatz as for the nearest neighbors case: \\phi_n = \\phi_0 \\exp(ikna) . Calculate the effective mass m^* . Sketch the effective mass as a function of k for the cases t=2t' , t=4t' and t=10t' .","title":"The tight binding model"},{"location":"06tightbinding/#the-tight-binding-model","text":"Unbaked The content here is still very much under development. Please come back soon!","title":"The tight binding model"},{"location":"06tightbinding/#introduction","text":"The kinetic theory of Drude was a great first step in trying to answer the question \"metals, how do they work?\", but it was clear from the outset that there were problems with the theory. But with the discovery of the Pauli exclusion principle, it seemed only logical that with the inclusion of the fundamental property of the electrons, life would improve. Indeed it does... Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Statistical mechanics: familiarity with Fermi-Dirac statistics Quantum mechanics: Wavefunction of a free (unbound) electron Text reference The material covered here is discussed in section(s) \\S 4 of The Oxford Solid State Basics","title":"Introduction"},{"location":"06tightbinding/#electrons-and-phonons-in-1d","text":"(based on chapters 9.1-9.3 & 11.1-11.3 of the book) Expected prior knowledge Before the start of this lecture, you should be able to: Derive Newton's equations of motion of a triatomic chain (previous lecture). Write down the dispersion relation of phonons in the Debye model. Express complex exponentials through trigonometric functions and vice versa. Apply Taylor expansion trigonometric functions. Take derivatives inverse trigonometric functions. Learning goals After this lecture you will be able to: Formulate the equations of motion of electrons and phonons in 1D. Derive the dispersion relation from the equations of motion. Derive the group velocity, effective mass, and density of states from the dispersion relation. Last lecture: Vibrational modes of few-atom chains (analyzed using Newton's equations) Orbital energies of electrons in few-atom chains (analyzed using LCAOs) This lecture: Phonons and electrons in chains of infinitely many atoms. Main idea: use periodicity in space, similar to periodicity in time To emphasize the similarities and the differences between electrons and phonons, we will deal with both types of particles at once.","title":"Electrons and phonons in 1D"},{"location":"06tightbinding/#equations-of-motion","text":"","title":"Equations of motion"},{"location":"06tightbinding/#phonons","text":"In the Debye model, we assumed that the dispersion relation is strictly linear in k . Now is the time to revisit this assumption. To do that, let us consider a 1D homogeneous chain of atoms. We assume that the atoms in the chain interact only with their nearest neighbors through a harmonic potential, like we derived in the previous lecture . In other words, we model the atoms as point masses connected by identical springs. We denote the displacement of atom n from equilibrium by u_n . Within this convention, Newton's equation of motion for the n -th atom is given by: m \\ddot{u}_n = -\\kappa (u_n - u_{n-1}) -\\kappa (u_n - u_{n+1}). We use the periodic boundary conditions just like we did in the Sommerfield model. The boundary conditions imply that in a system of size L = Na , we have u_N = u_0 .","title":"Phonons"},{"location":"06tightbinding/#electrons","text":"The following figure shows the interatomic potential with atoms placed at x_k = ka with k \\in \\mathbb{Z} : x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 )) ax . set_ylim ( -. 7 , . 5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ -. 05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) Similarly to the triatomic system case, we formulate the molecular orbital via the LCAO model: \\vert \\Psi \\rangle = \\sum_n \\phi_n |n \\rangle. We assume only nearest-neighbor hopping -t and an on-site energy E_0 . The coupled Schr\u00f6dinger equation of the |n \\rangle orbital is: E \\phi_n = E_0 \\phi_n - t \\phi_{n+1} - t \\phi_{n-1}. Again, the periodic boundary conditions imply \\phi_N = \\phi_0 . We now have the equations of motion of both phonons and electrons. All that remains is to solve them.","title":"Electrons"},{"location":"06tightbinding/#key-idea-for-solving-these-equations","text":"In order to solve the equations of motion, we need to come up with a reasonable guess. If we take a look at the equations of motion, we see that they are the same for all atoms. To be specific, the structure of the equations is the same no matter what value of n we choose. Since these equations define the solutions, we reason that the solutions should also be independent of the choice of n . As a result, we assume a plane wave solution, also called a plane wave ansatz , with the same amplitude for each atom. In the case of phonons, we obtain u_n = Ae^{i \\omega t - i k x_n}, and the ansatz for electrons is given similarly by \\phi_n = Be^{i E t/\\hbar - i k x_n}. We wrote x_n=na and we wrote the time-dependent solution of the Schr\u00f6dinger equation to emphasize the similarity between the two systems. We already know that the periodic boundary conditions only allow plane waves with k being a multiple of 2\\pi/L . In the case of the electron system, periodic boundary conditions give \\phi_0 = \\phi_N , which results in 1 = e^{ik0} = e^{ikNa}. The above equation defines the allowed values of k : k = \\frac{2 \\pi p}{Na}, \\quad \\text{with} p \\in \\mathbb{Z}. We use the quantized values of k in our plane wave ansatz: e^{ikx_n} = e^{i p \\frac{2\\pi}{Na} n a} = e^{i \\frac{2 \\pi n p}{N}} . We notice something interesting if we investigate the case of p\u2192p+N . In this case, the plane wave ansatz becomes e^{i \\frac{2\\pi n(p+N)}{N}} = e^{i \\frac{2\\pi np}{N} + i2\\pi n} = e^{i \\frac{2\\pi np}{N}} , which is exactly the same solution. Counting the number of inequivalent plane waves, we find exactly N different solutions in total. All that is left is to find the energy of each solution! The reason why solutions with different values of k are identical is aliasing : because the plane wave is only defined at discrete positions, acquiring a phase factor of 2\u03c0 between two atoms is equivalent to nothing happening: x = np . linspace ( -. 2 , 2.8 , 500 ) fig , ax = pyplot . subplots () ax . plot ( x , np . cos ( pi * ( x )), label = r '$k=\\pi/a$' ) ax . plot ( x , np . cos ( 3 * pi * ( x )), label = r '$k=3\\pi/a$' ) ax . plot ( x , np . cos ( 5 * pi * ( x )), label = r '$k=5\\pi/a$' ) sites = np . arange ( 3 ) ax . scatter ( sites , np . cos ( pi * ( sites )), c = 'k' , s = 64 , zorder = 5 ) ax . set_xlabel ( '$x$' ) ax . set_ylabel ( '$u_n$' ) ax . set_xlim (( -. 1 , 3.2 )) ax . set_ylim (( - 1.3 , 1.3 )) ax . legend ( loc = 'lower right' ) draw_classic_axes ( ax ) ax . annotate ( s = '' , xy = ( 0 , - 1.1 ), xytext = ( 1 , - 1.1 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) ax . text ( . 5 , - 1.25 , '$a$' , ha = 'center' ); How many different solutions did we expect to find? We have a system with N degrees of freedom (either u_n or \\phi_n ), and therefore we expect N normal modes (or eigenstates).","title":"Key idea for solving these equations"},{"location":"06tightbinding/#solving-the-equations-of-motion","text":"","title":"Solving the equations of motion"},{"location":"06tightbinding/#phonons_1","text":"We substitute the plane wave ansatz into the equations of motion: -m \\omega^2 A e^{i\\omega t - ikx_n} = \\kappa A e^{i\\omega t}(-2 e^{-ikx_n} + e^{-ikx_n+ika}+ e^{-ikx_n-ika}). Searching for solutions with A \\neq 0 we obtain -m \\omega^2 = \\kappa (-2 + e^{ika}+ e^{-ika})=\\kappa [-2 + 2\\cos(ka)]. Or after a further simplification: \\omega = \\sqrt{\\frac{2\\kappa}{m}}\\sqrt{1-\\cos(ka)}= 2\\sqrt{\\frac{\\kappa}{m}}|\\sin(ka/2)|, where we substituted 1-\\cos(x) = 2\\sin^2(x/2) . We arrive at the phonon dispersion relation shown below. k = np . linspace ( - 2 * pi , 6 * pi , 500 ) fig , ax = pyplot . subplots () pyplot . plot ( k , np . abs ( np . sin ( k / 2 ))) ax . set_ylim ( bottom = 0 , top = 1.2 ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\\omega$' ) pyplot . xticks ( list ( 2 * pi * np . arange ( - 1 , 4 )) + [ - pi , pi ], [ r '$-2\\pi$' , '$0$' , r '$2\\pi$' , r '$4\\pi$' , r '$6\\pi$' , r '$-\\pi$' , r '$\\pi$' ]) pyplot . yticks ([ 1 ], [ r '$2\\sqrt{\\frac{\\kappa} {m} }$' ]) pyplot . vlines ([ - pi , pi ], 0 , 1.1 , linestyles = 'dashed' ) pyplot . hlines ([ 1 ], . 1 * pi , 1.3 * pi , linestyles = 'dashed' ) draw_classic_axes ( ax ); # ax.annotate(s='', xy=(-pi, -.15), xytext=(pi, -.15), # arrowprops=dict(arrowstyle='<->', shrinkA=0, shrinkB=0)) # ax.text(0, -.25, '1st Brillouin zone', ha='center') # ax.set_ylim(bottom=-.3); The periodicity of the dispersion relation is a consequence of what we observed before: since plane waves with k -vectors differing by 2\u03c0/a are exactly the same, the repeated periods of the dispersion relation describe the same plane waves.","title":"Phonons"},{"location":"06tightbinding/#comparison-to-the-debye-model","text":"Sound velocity: At small k , \\sin(ka/2)\\approx ka/2 . Therefore \\omega \\approx \\sqrt{\\kappa/m} k a = v_sk , with v_s the sound velocity. We therefore justify the linear dispersion approximation in the Debye model! Cut-off frequency: The Debye model introduces the cutoff frequency \\omega_D to limit the number of phonon modes, and does not identify the origin of the cutoff. Now because of the finite number of plane waves, the integration over the k -space has a finite size: \\sum_p \u2192 \\frac{L}{2\\pi}\\int_{-\\pi/a}^{\\pi/a}dk . This automatically gives us a maximal frequency without additional assumptions.","title":"Comparison to the Debye model"},{"location":"06tightbinding/#electrons_1","text":"Once again we substitute the plane wave ansatz into the equations of motion: E Ae^{iEt/\\hbar-ikna} = E_0 Ae^{iEt/\\hbar-ikna} - t Ae^{iEt/\\hbar-ik(n+1)a} - t Ae^{iEt/\\hbar-ik(n-1)a}, Again, we are not interested in a trivial solution, hence we assume A \\neq 0 and thus E = E_0 -te^{-ika} -te^{ika} = E_0 - 2t\\cos(ka), which gives us the dispersion relation below. pyplot . figure () k = np . linspace ( - pi , pi , 300 ) pyplot . plot ( k , - np . cos ( k )) pyplot . xlabel ( '$ka$' ); pyplot . ylabel ( '$E$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , 0 , r '$\\pi$' ]) pyplot . yticks ([ - 1 , 0 , 1 ], [ '$E_0-2t$' , '$E_0$' , '$E_0+2t$' ]); We see that the electron dispersion consists of a band of allowed energies E_0 -2t < E < E_0 + 2t . That particles occupy bands of allowed energies is why a dispersion relation is also often called a band structure . Due to the spin degeneracy, each band has 2 N possible states if we consider a system with N atoms. If each atom contains 2 electrons and a single orbital, all the states in the band must be occupied by electrons. Because all the available states are occupied, there is always exactly the same number of electrons moving in the positive direction, as there are in the negative. Hence, no matter what we do, our system is incapable of conducting electrons, and therefore we have derived the existence of insulators! Let us also compare the electron band structure with the free electron model. Focusing on the dispersion relation close to the band bottom at k=0 , we approximate the energy as E \\approx E_0 - 2t + t (ka)^2. If we compare this to the dispersion relation E=\\hbar k^2/2m of the free electrons model, we see that the band structure is similar, but the lowest available energy is E_0-2t instead of 0 , and the electrons behave as if they had a different mass m^*=\\hbar^2/2ta^2 .","title":"Electrons"},{"location":"06tightbinding/#group-velocity-effective-mass-density-of-states","text":"(here we only discuss electrons; for phonons everything is the same except for replacing E = \\hbar \\omega ) Let us think what happens if we apply an external electric field to the crystal: x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 ) + . 2 * ( x - 1.5 )) ax . plot ( x , . 2 * ( x - 0.25 ), '--' ) ax . set_ylim ( -. 7 , . 5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ -. 05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) The full Hamiltonian of the system is H = \\frac{p^2}{2m} + U_\\textrm{atomic}(x) + e \\mathcal{E} x, where U_\\textrm{atomic} is the potential created by the nuclei, and \\mathcal{E} the electric field. A typical electric field is much smaller than the interatomic potential, and therefore we can start by obtaining the dispersion relation E(k) without electric field (by applying the LCAO method), and then solve H = E(k) + e\\mathcal{E}x. To derive how particles with an arbitrary dispersion relation move, we recall the Hamilton's equations for particle velocity v and force F : \\begin{aligned} v \\equiv \\frac{dr}{dt} &= \\frac{\\partial H(p, r)}{\\partial p}\\\\ F \\equiv \\frac{dp}{dt} &= -\\frac{\\partial H(p, r)}{\\partial r}. \\end{aligned} Substituting p = \\hbar k into the first equation we arrive to the expression for the electron group velocity v \\equiv \\hbar^{-1}\\partial E/\\partial k . From the second equation we obtain that the force acting on electron in a band stays -e\\mathcal{E} , which in turn gives results in the acceleration \\frac{dv}{dt} = \\frac{\u2202v}{\u2202p}\\frac{dp}{dt} = F/m. Comparing this expression with dv/dt = F/m , we arrive to the effective mass : m^* \\equiv \\left(\\frac{\u2202v}{\u2202p}\\right)^{-1} = \\left(\\frac{\u2202\u00b2E}{\u2202p\u00b2}\\right)^{-1} = \u0127\u00b2\\left(\\frac{\u2202\u00b2E}{\u2202k\u00b2}\\right)^{-1}. The group velocity describes how quickly electrons with a certain k -vector move, while the effective mass describes how hard they are to accelerate by applying external force. By using the dispersion relation we derived earlier, we obtain the effective mass like this: pyplot . figure ( figsize = ( 8 , 5 )) k = np . linspace ( - pi , pi , 300 ) meff = 1 / np . cos ( k ) color = list ( matplotlib . rcParams [ 'axes.prop_cycle' ])[ 0 ][ 'color' ] pyplot . plot ( k [ meff > 0 ], meff [ meff > 0 ], c = color ) pyplot . plot ( k [ meff < 0 ], meff [ meff < 0 ], c = color ) pyplot . ylim ( - 5 , 5 ) pyplot . xlabel ( '$ka$' ); pyplot . ylabel ( '$m^*$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , 0 , r '$\\pi$' ]); Notice that the effective mass can be negative, which implies the electrons accelerate in the direction opposite to the applied force.","title":"Group velocity, effective mass, density of states"},{"location":"06tightbinding/#density-of-states","text":"The DOS is the number of states per unit energy. In 1D we have g(E) = \\frac{L}{2\\pi}\\sum |dk/dE| = \\frac{L}{2\\pi}\\sum |v|^{-1} The sum goes over all possible values of k and spin which have the same energy E . If we are working in two or more dimensions, we must integrate over the values of k with the same energy. Also take note that for energies below E_0 - 2t or above E_0 + 2t , there are no values of k with that energy, so there is nothing to sum over. Once again, starting from E = E_0 - 2t \\cos(ka), we get ka = \\pm\\arccos[(E - E_0) / 2t], and |v| ^{-1} = \\left|\\frac{dk}{dE} \\right| = \\frac{1}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. You can get to this result immediately if you remember the derivative of arccosine. Otherwise you need to go the long way: compute dE/dk as a function of k , express k through E as we did above, and take the inverse. We now add together the contributions of the positive and the negative momenta as well both spin orientations, and arrive to the density of states g(E) = \\frac{L}{2\\pi}\\frac{4}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. A quick check: when the energy is close to the bottom of the band, E = E_0 - 2t + \\delta E , we get g(E) \\propto \\delta E^{-1/2} , as we expect in 1D. The process of calculating the DOS at a given energy E of a spin-independent Hamiltonian is done systematically with the following steps: At a given energy E , determine all of the values of k which correspond to that E using the dispersion relation. Compute \\rvert dk / dE \\rvert . Do this either by writing k as a (multi-valued) function of E and differentiating, or by computing (dE / dk)^{-1} . Sum or integrate dk / dE over the allowed values of k found in 1 and multiply by any degeneracies (spin/polarization). Multiply by spin degeneracy. If the Hamiltonian depends on spin, then there is no spin degeneracy and the spin number s must be treated in the same way as k .","title":"Density of states"},{"location":"06tightbinding/#summary","text":"By using plane waves in real space as an Ansatz we found all normal modes and energies for phonons and electrons in 1D Computing dispersion relations explains the problems we listed before (need for cutoff, lack of scattering with every single atom, existence of insulators). Electrons and phonons have a complicated nonlinear relation between momentum and velocity ( group velocity ), effective mass, and density of states.","title":"Summary"},{"location":"06tightbinding/#exercises","text":"","title":"Exercises"},{"location":"06tightbinding/#warm-up-questions","text":"Compare the expression of the effective mass with Newton's second law. Do you observe any similarities? Check the units of the group velocity. Is it what you expect? Do the same for the effective mass. Calculate the effective mass of the free-electron dispersion relation. Is this what was expected? Under what condition is the effective mass the same for each electron?","title":"Warm-up questions"},{"location":"06tightbinding/#exercise-1-lattice-vibrations","text":"From the dispersion relation of a 1D monatomic chain given in the lecture notes, calculate the group velocity v_g . Using the group veolcity found above, calculate the density of states g(\\omega) . Sketch them. From the 1D dispersion relation \\omega(k) in the picture below, sketch the group velocity v_g(k) and the density of states g(\\omega) .","title":"Exercise 1: Lattice vibrations"},{"location":"06tightbinding/#exercise-2-vibrational-heat-capacity-of-a-1d-monatomic-chain","text":"Give the total energy U of a 1D monatomic chain as an integral expression. To do so, first derive the density of states from the phonon dispersion relation derived in the lecture notes. Give an integral expression for the heat capacity C . Compute the heat capacity numerically, using e.g. Python. Do the same for C in the Debye model and compare the two. What differences do you see?","title":"Exercise 2: Vibrational heat capacity of a 1D monatomic chain"},{"location":"06tightbinding/#exercise-3-next-nearest-neighbors-chain","text":"Consider electrons in a 1D atomic chain again: x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 )) ax . set_ylim ( -. 7 , . 5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ -. 05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) Let's expand the one-dimensional chain model by extending the range of the interaction further than the nearest neighbors: \\langle \\phi_n | H | \\phi_{n+2}\\rangle \\equiv -t' \u2260 0. Write down the new Schr\u00f6dinger equation for this system. hint There are now two more terms in the equation: -t' \\phi_{n-2} - t' \\phi_{n+2} . Solve the Schr\u00f6dinger equation to find the dispersion relation E(k) . hint Use the same Ansatz as for the nearest neighbors case: \\phi_n = \\phi_0 \\exp(ikna) . Calculate the effective mass m^* . Sketch the effective mass as a function of k for the cases t=2t' , t=4t' and t=10t' .","title":"Exercise 3: Next-nearest neighbors chain"},{"location":"07diatomic/","text":"The diatomic chain \u00b6 Unbaked The content here is still very much under development. Please come back soon! Introduction \u00b6 The kinetic theory of Drude was a great first step in trying to answer the question \"metals, how do they work?\", but it was clear from the outset that there were problems with the theory. But with the discovery of the Pauli exclusion principle, it seemed only logical that with the inclusion of the fundamental property of the electrons, life would improve. Indeed it does... Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Statistical mechanics: familiarity with Fermi-Dirac statistics Quantum mechanics: Wavefunction of a free (unbound) electron Text reference The material covered here is discussed in section(s) \\S 4 of The Oxford Solid State Basics (based on chapters 10-11 of the book) Expected prior knowledge Before the start of this lecture, you should be able to: Write down equations of motion and the LCAO Hamiltonian (similar to the previous lectures) Solve an eigenvalue problem Learning goals After this lecture you will be able to: formulate equations of motion for electrons or phonons in 1D, with multiple degrees of freedom per unit cell. solve these equations to arrive at the dispersion relation. derive the group velocity and density of states from the dispersion relation. explain what happens with the band structure when the periodicity of the lattice is increased or reduced. More degrees of freedom per unit cell: \u00b6 In the last lecture, we modeled phonons through a 1D homogeneous chain of atoms. The model gave us insight into phonons and justified the crude approximations of the Debye model. Despite the model's usefulness, we are not always able to model problems as a homogeneous chain. Therefore, let us tackle a slightly more general problem. Consider a chain of atoms with two masses, m_1 and m_2 . In our chain, an atom with mass m_1 is always followed by an atom of mass m_2 and vice versa. Similar to before, the atoms interact via a harmonic potential with spring constant \u03ba . In the last lecture, we solved the homogenous chain problem by identifying its high level of symmetry. However, the problem here is not as symmetric. We need to re-think and generalize our ansatz. First we identify a pattern that does repeat: an atom with mass m_1 followed by one with mass m_2 . This is called a unit cell (the smallest repeated element of the system) We now label all degrees of freedom in a unit cell. The two atoms in a unit cell have displacements u_{1,n} and u_{2,n} , where the first index specifies the atom number within the unit cell and the second the unit cell number. In our choice of unit cell, atom 1 has mass m_1 and atom 2 has mass m_2 . Having specified the degrees of freedom, let's write down the equations of motion: \\begin{aligned} m_1\\ddot{u}_{1,n}&=\u03ba(u_{2,n}-2u_{1,n}+u_{2,n-1})\\\\ m_2\\ddot{u}_{2,n}&=\u03ba(u_{1, n} - 2u_{2,n}+u_{1,n+1}). \\end{aligned} The new ansatz is conceptually the same as before: all unit cells should behave the same up to a phase factor: \\begin{pmatrix} u_{1,n}\\\\ u_{2,n} \\end{pmatrix} = e^{i\u03c9 t - ik na} \\begin{pmatrix} A_{1}\\\\ A_{2} \\end{pmatrix}. Substituting this ansatz into the equations of motion (and assuming that the solution is nontrivial) we end up with an eigenvalue problem: \u03c9^2 \\begin{pmatrix} m_1 & 0 \\\\ 0 & m_2 \\end{pmatrix} \\begin{pmatrix} A_{1} \\\\ A_{2} \\end{pmatrix} = \u03ba \\begin{pmatrix} 2 & -1 - e^{ika} \\\\ -1-e^{-ika} & 2 \\end{pmatrix} \\begin{pmatrix} A_{1}\\\\ A_{2} \\end{pmatrix}, with eigenfrequencies: \u03c9^2=\\frac{\u03ba(m_1+m_2)}{m_1m_2}\\pm \u03ba\\left\\{\\left(\\frac{m_1+m_2}{m_1m_2}\\right)^2-\\frac{4}{m_1m_2}\\sin^2\\left(\\frac{1}{2}ka\\right)\\right\\}^{\\frac{1}{2}} Looking at the eigenvectors we see that for every k there are now two values of \u03c9 : one corresponding to in-phase motion (\u2013) and anti-phase (+). def dispersion_2m ( k , kappa = 1 , M = 1.4 , m = 1 , acoustic = True ): Mm = M * m m_harm = ( M + m ) / Mm root = kappa * np . sqrt ( m_harm ** 2 - 4 * np . sin ( k / 2 ) ** 2 / Mm ) if acoustic : root *= - 1 return np . sqrt ( kappa * m_harm + root ) # TODO: Add panels with eigenvectors k = np . linspace ( - 2 * pi , 6 * pi , 300 ) fig , ax = pyplot . subplots () ax . plot ( k , dispersion_2m ( k , acoustic = False ), label = 'optical' ) ax . plot ( k , dispersion_2m ( k ), label = 'acoustic' ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\u03c9$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , '$0$' , r '$\\pi$' ]) pyplot . yticks ([], []) pyplot . vlines ([ - pi , pi ], 0 , 2.2 , linestyles = 'dashed' ) pyplot . legend () pyplot . xlim ( - 1.75 * pi , 3.5 * pi ) pyplot . ylim ( bottom = 0 ) draw_classic_axes ( ax ) ax . annotate ( s = '' , xy = ( - pi , -. 3 ), xytext = ( pi , -. 3 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) ax . text ( 0 , -. 55 , '1st Brillouin zone' , ha = 'center' ); #draw_classic_axes(ax, xlabeloffset=.2) The figure above shows a plot of the eigenfrequencies as a function of ka . Just like last time, the plot is periodic in k , with k -values which differ by a multiple of 2 \\pi / a corresponding to the same solution. Therefore we only look at the k -values between k - \\pi / a and k + \\pi / a . This range (in between the dashed lines) is called the first Brillouin zone , and functions as a unit cell in reciprocal space. The Brillouin zone will be explained in more detail in the lecture about X-ray diffraction. Unlike the simple atomic chain, the dispersion relation now has two branches (or bands). The reason an additional branch appears in the solution is due to the 2 degrees of freedom per unit cell. If we had started with 3 different atoms, the eigenvalue problem would contain 3 equation, so that there would be three eigenfrequencies per k and the dispersion relation would have 3 branches. The lower branch is called acoustic because its linear dispersion near \u03c9=0 matches the behavior of regular sound waves. The upper branch is the optical branch because it can cross with the (linear) dispersion relation of photons, allowing these phonons to efficiently emit and absorb photons. Like before, the phonon group velocity is v=\\textrm{d}\u03c9/\\textrm{d}k , and the density of states is g(\u03c9)=\\textrm{d}N/\\textrm{d}\u03c9 = \\frac{L}{2\u03c0} \u2211| \\textrm{d}k/\\textrm{d} \u03c9| . The sum goes over all states at a given energy. In this case, the sum ensures we include the contribution to the DOS from both the positive and negative momenta. Since the energy of this system is symmetric with respect to momentum reversal, the sum only introduces a factor of 2. An intuitive way to visualize the density of states g(\u03c9) is to consider it a histogram of the samples drawn from the dispersion relation \u03c9(k) : matplotlib . rcParams [ 'font.size' ] = 24 k = np . linspace ( -. 25 * pi , 1.5 * pi , 300 ) k_dos = np . linspace ( 0 , pi , 20 ) fig , ( ax , ax2 ) = pyplot . subplots ( ncols = 2 , sharey = True , figsize = ( 10 , 5 )) ax . plot ( k , dispersion_2m ( k , acoustic = False ), label = 'optical' ) ax . plot ( k , dispersion_2m ( k ), label = 'acoustic' ) ax . vlines ( k_dos , 0 , dispersion_2m ( k_dos , acoustic = False ), colors = ( 0.5 , 0.5 , 0.5 , 0.5 )) ax . hlines ( np . hstack (( dispersion_2m ( k_dos , acoustic = False ), dispersion_2m ( k_dos ))), np . hstack (( k_dos , k_dos )), 1.8 * pi , colors = ( 0.5 , 0.5 , 0.5 , 0.5 ) ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\u03c9$' ) ax . set_xticks ([ 0 , pi ]) ax . set_xticklabels ([ '$0$' , r '$\\pi$' ]) ax . set_yticks ([]) ax . set_yticklabels ([]) ax . set_xlim ( - pi / 4 , 2 * pi ) ax . set_ylim (( 0 , dispersion_2m ( 0 , acoustic = False ) + . 2 )) draw_classic_axes ( ax , xlabeloffset =. 2 ) k = np . linspace ( 0 , pi , 1000 ) omegas = np . hstack (( dispersion_2m ( k , acoustic = False ), dispersion_2m ( k ) )) ax2 . hist ( omegas , orientation = 'horizontal' , bins = 75 ) ax2 . set_xlabel ( r '$g(\u03c9)$' ) ax2 . set_ylabel ( r '$\u03c9$' ) # Truncate the singularity in the DOS max_x = ax2 . get_xlim ()[ 1 ] ax2 . set_xlim (( 0 , max_x / 2 )) draw_classic_axes ( ax2 , xlabeloffset =. 1 ) matplotlib . rcParams [ 'font.size' ] = 16 Note that g(\u03c9) is generally plotted along the vertical axis and \u03c9 along the horizontal axis \u2013 the right plot above is just to demonstrate the relation between the dispersion and the DOS. The singularities in g(\u03c9) at the bottom and top of each branch are called van Hove singularities . Consistency check with 1 atom per cell \u00b6 To check if our result is consistent with the previous lecture, we examine what happens when we take m_1\\rightarrow m_2 . Physically, the system is then exactly the same as the 1D monatomic chain, so we would want our solutions to also be the same. But at first glance the two solutions seem very different: the solution with one atom has only one band, but the solution with two atoms has two bands. To reconcile the two pictures, let's plot two unit cells in reciprocal space. k = np . linspace ( 0 , 2 * pi , 300 ) k_dos = np . linspace ( 0 , pi , 20 ) fig , ax = pyplot . subplots () ax . plot ( k , dispersion_2m ( k , acoustic = False ), label = 'optical' ) ax . plot ( k , dispersion_2m ( k ), label = 'acoustic' ) omega_max = dispersion_2m ( 0 , acoustic = False ) ax . plot ( k , omega_max * np . sin ( k / 4 ), label = 'equal masses' ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\u03c9$' ) ax . set_xticks ([ 0 , pi , 2 * pi ]) ax . set_xticklabels ([ '$0$' , r '$\\pi/2a$' , r '$\\pi/a$' ]) ax . set_yticks ([]) ax . set_yticklabels ([]) ax . set_xlim ( - pi / 8 , 2 * pi +. 4 ) ax . set_ylim (( 0 , dispersion_2m ( 0 , acoustic = False ) + . 2 )) ax . legend ( loc = 'lower right' ) pyplot . vlines ([ pi , 2 * pi ], 0 , 2.2 , linestyles = 'dashed' ) draw_classic_axes ( ax , xlabeloffset =. 2 ) We must be careful when considering the lattice constant a . In the 1D monatomic chain, a was the distance between two neighbouring atoms, but in our diatomic chain a is the size of the unit cell, which is twice as big. Therefore we take the size of our unit cell in the diatomic case to be 2a , so the physical systems are the same. Looking at the graph we see that doubling the lattice constant \"folds\" the band structure on itself. There are then 2 possible values of \u03c9 for each k , creating the 2 branches of the non-periodic system. We can look at the graph in two distinct ways: We can consider the green line (monatomic chain solution). Its Brillouin zone extends from 0 to \\pi / a . Alternatively, we consider the orange and blue lines together. In this case, the Brillouin zone is smaller ranging from 0 to \\pi / 2a (because of the larger lattice constant). Despite the two band structures look different, the density of states only changes very little: when m_1 \u2248 m_2 only the states near the band touching point slightly move in frequency. Summary \u00b6 By using plane waves in real space as an ansatz, we found all normal modes of an atom chain with two different atoms. (Just like in the case of 1 degree of freedom per unit cell). The density of states can be derived graphically from the dispersion relation. The dispersion relation of a system with period a in real space is periodic with period 2\\pi/a in k -space. In a system with more than one degree of freedom per unit cell we need to consider independent amplitudes for each degree of freedom, and we get multiple bands. Systems with different band structures can have the same density of states. Exercises \u00b6 Warm-up questions \u00b6 Verify that the expression for \u03c9^2 is always positive. Why is this important? Work out the expression of \u03c9^2 in the case m_1 = m_2 . Compare this to the solution for the monatomic chain. When calculating the DOS, we only look at the first Brillouin zone. Why? Exercise 1: analyzing the diatomic vibrating chain \u00b6 As we have derived, the eigenfreqencies of a diatomic vibrating chain with 2 different masses are: \u03c9^2=\\frac{\u03ba(m_1+m_2)}{m_1m_2}\\pm \u03ba\\left\\{\\left(\\frac{m_1+m_2}{m_1m_2}\\right)^2-\\frac{4}{m_1m_2}\\sin^2\\left(\\frac{1}{2}ka\\right)\\right\\}^{\\frac{1}{2}}, where the plus sign corresponds to the optical branch and the minus sign to the acoustic branch. Find the magnitude of the group velocity near k=0 for the acoustic branch. Hint Make use of a Taylor expansion. Show that the group velocity at k=0 for the optical branch is zero. Derive an expression of the density of states g(\u03c9) for the acoustic branch and small k . Make use of your expression of the group velocity in 1. Compare this expression with that of the derived density of states from exercise 1 of the Debye lecture. Exercise 2: the Peierls transition \u00b6 In the previous lecture, we have derived the electronic band structure of an 1D, equally spaced atomic chain. Such chains, however, are in fact not stable and the equal spacing will be distorted. This is also known as the Peierls transition . The spacing of the distorted chain alternates between two different distances and this also causes the hopping energy to alternate between t_1 and t_2 . We further set the onsite energies of the atoms to \\epsilon . The situation is depicted in the figure below. Due to the alternating hopping energies, we must treat two consecutive atoms as two different orbitals ( |n,1\u27e9 and |n,2 \u27e9 in the figure) from the same unit cell. The corresponding LCAO of this chain is given by \\left|\\Psi \\right\\rangle = \\sum_n \\left(\\phi_n \\left| n,1 \\right\\rangle + \\psi_n \\left| n,2 \\right\\rangle\\right) As usual, we assume that all these atomic orbitals are orthogonal to each other. Indicate the length of the unit cell a in the figure. Using the Schr\u00f6dinger equation, write the equations of motion of the electrons. Hint To this end, find expressions for E \\left< n,1 \\vert \\Psi \\right> = \\left< n,1 \\right| H \\left|\\Psi \\right> and E \\left< n,2 \\vert \\Psi \\right> = \\left< n,2 \\right| H \\left|\\Psi \\right> . Using the trial solutions \\phi_n = \\phi_0 e^{ikna} and \\psi_n = \\psi_0 e^{ikna} , show that the Sch\u00f6dinger equation can be written in matrix form: \\begin{pmatrix} \\epsilon & t_1 + t_2 e^{-i k a} \\\\ t_1 + t_2 e^{i k a} & \\epsilon \\end{pmatrix} \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix} = E \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix}. Derive the dispersion relation of this Hamiltonian. Does it look like the figure of the band structure shown on the Wikipedia page ? Does it reduce to the 1D, equally spaced atomic chain if t_1 = t_2 ? Find an expression of the group velocity v(k) and effective mass m^*(k) of both bands. Derive an expression for the density of states g(E) of the entire band structure and make a plot of it. Does your result makes sense when considering the band structure? Exercise 3: atomic chain with 3 different spring constants \u00b6 Suppose we have a vibrating 1D atomic chain with 3 different spring constants alternating like \\kappa_ 1 , \\kappa_2 , \\kappa_3 , \\kappa_1 , etc. All the the atoms in the chain have an equal mass m . Make a sketch of this chain and indicate the length of the unit cell a in this sketch. Derive the equations of motion for this chain. By filling in the trial solutions into the equations of motion (which should be similar to Ansazt used in the lecture), show that the eigenvalue problem is \\omega^2 \\mathbf{u} = \\frac{1}{m} \\begin{pmatrix} \\kappa_1 + \\kappa_ 3 & -\\kappa_ 1 & -\\kappa_ 3 e^{i k a} \\\\ -\\kappa_ 1 & \\kappa_1+\\kappa_2 & -\\kappa_ 2 \\\\ -\\kappa_ 3 e^{-i k a} & -\\kappa_2 & \\kappa_2 + \\kappa_ 3 \\end{pmatrix} \\mathbf{u} In general, the eigenvalue problem above cannot be solved analytically, and can only be solved in specific cases. Find the eigenvalues \u03c9^2 when k a = \\pi and \\kappa_1 = \u03ba_2 = q . Hint To solve the eigenvalue problem quickly, make use of the fact that the mass-spring matrix in that case commutes with the matrix X = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix}. What can be said about eigenvectors of two matrices that commute? What will happen to the periodicity of the band structure if \\kappa_ 1 = \\kappa_ 2 = \\kappa_3 ?","title":"The diatomic chain"},{"location":"07diatomic/#the-diatomic-chain","text":"Unbaked The content here is still very much under development. Please come back soon!","title":"The diatomic chain"},{"location":"07diatomic/#introduction","text":"The kinetic theory of Drude was a great first step in trying to answer the question \"metals, how do they work?\", but it was clear from the outset that there were problems with the theory. But with the discovery of the Pauli exclusion principle, it seemed only logical that with the inclusion of the fundamental property of the electrons, life would improve. Indeed it does... Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Statistical mechanics: familiarity with Fermi-Dirac statistics Quantum mechanics: Wavefunction of a free (unbound) electron Text reference The material covered here is discussed in section(s) \\S 4 of The Oxford Solid State Basics (based on chapters 10-11 of the book) Expected prior knowledge Before the start of this lecture, you should be able to: Write down equations of motion and the LCAO Hamiltonian (similar to the previous lectures) Solve an eigenvalue problem Learning goals After this lecture you will be able to: formulate equations of motion for electrons or phonons in 1D, with multiple degrees of freedom per unit cell. solve these equations to arrive at the dispersion relation. derive the group velocity and density of states from the dispersion relation. explain what happens with the band structure when the periodicity of the lattice is increased or reduced.","title":"Introduction"},{"location":"07diatomic/#more-degrees-of-freedom-per-unit-cell","text":"In the last lecture, we modeled phonons through a 1D homogeneous chain of atoms. The model gave us insight into phonons and justified the crude approximations of the Debye model. Despite the model's usefulness, we are not always able to model problems as a homogeneous chain. Therefore, let us tackle a slightly more general problem. Consider a chain of atoms with two masses, m_1 and m_2 . In our chain, an atom with mass m_1 is always followed by an atom of mass m_2 and vice versa. Similar to before, the atoms interact via a harmonic potential with spring constant \u03ba . In the last lecture, we solved the homogenous chain problem by identifying its high level of symmetry. However, the problem here is not as symmetric. We need to re-think and generalize our ansatz. First we identify a pattern that does repeat: an atom with mass m_1 followed by one with mass m_2 . This is called a unit cell (the smallest repeated element of the system) We now label all degrees of freedom in a unit cell. The two atoms in a unit cell have displacements u_{1,n} and u_{2,n} , where the first index specifies the atom number within the unit cell and the second the unit cell number. In our choice of unit cell, atom 1 has mass m_1 and atom 2 has mass m_2 . Having specified the degrees of freedom, let's write down the equations of motion: \\begin{aligned} m_1\\ddot{u}_{1,n}&=\u03ba(u_{2,n}-2u_{1,n}+u_{2,n-1})\\\\ m_2\\ddot{u}_{2,n}&=\u03ba(u_{1, n} - 2u_{2,n}+u_{1,n+1}). \\end{aligned} The new ansatz is conceptually the same as before: all unit cells should behave the same up to a phase factor: \\begin{pmatrix} u_{1,n}\\\\ u_{2,n} \\end{pmatrix} = e^{i\u03c9 t - ik na} \\begin{pmatrix} A_{1}\\\\ A_{2} \\end{pmatrix}. Substituting this ansatz into the equations of motion (and assuming that the solution is nontrivial) we end up with an eigenvalue problem: \u03c9^2 \\begin{pmatrix} m_1 & 0 \\\\ 0 & m_2 \\end{pmatrix} \\begin{pmatrix} A_{1} \\\\ A_{2} \\end{pmatrix} = \u03ba \\begin{pmatrix} 2 & -1 - e^{ika} \\\\ -1-e^{-ika} & 2 \\end{pmatrix} \\begin{pmatrix} A_{1}\\\\ A_{2} \\end{pmatrix}, with eigenfrequencies: \u03c9^2=\\frac{\u03ba(m_1+m_2)}{m_1m_2}\\pm \u03ba\\left\\{\\left(\\frac{m_1+m_2}{m_1m_2}\\right)^2-\\frac{4}{m_1m_2}\\sin^2\\left(\\frac{1}{2}ka\\right)\\right\\}^{\\frac{1}{2}} Looking at the eigenvectors we see that for every k there are now two values of \u03c9 : one corresponding to in-phase motion (\u2013) and anti-phase (+). def dispersion_2m ( k , kappa = 1 , M = 1.4 , m = 1 , acoustic = True ): Mm = M * m m_harm = ( M + m ) / Mm root = kappa * np . sqrt ( m_harm ** 2 - 4 * np . sin ( k / 2 ) ** 2 / Mm ) if acoustic : root *= - 1 return np . sqrt ( kappa * m_harm + root ) # TODO: Add panels with eigenvectors k = np . linspace ( - 2 * pi , 6 * pi , 300 ) fig , ax = pyplot . subplots () ax . plot ( k , dispersion_2m ( k , acoustic = False ), label = 'optical' ) ax . plot ( k , dispersion_2m ( k ), label = 'acoustic' ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\u03c9$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , '$0$' , r '$\\pi$' ]) pyplot . yticks ([], []) pyplot . vlines ([ - pi , pi ], 0 , 2.2 , linestyles = 'dashed' ) pyplot . legend () pyplot . xlim ( - 1.75 * pi , 3.5 * pi ) pyplot . ylim ( bottom = 0 ) draw_classic_axes ( ax ) ax . annotate ( s = '' , xy = ( - pi , -. 3 ), xytext = ( pi , -. 3 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) ax . text ( 0 , -. 55 , '1st Brillouin zone' , ha = 'center' ); #draw_classic_axes(ax, xlabeloffset=.2) The figure above shows a plot of the eigenfrequencies as a function of ka . Just like last time, the plot is periodic in k , with k -values which differ by a multiple of 2 \\pi / a corresponding to the same solution. Therefore we only look at the k -values between k - \\pi / a and k + \\pi / a . This range (in between the dashed lines) is called the first Brillouin zone , and functions as a unit cell in reciprocal space. The Brillouin zone will be explained in more detail in the lecture about X-ray diffraction. Unlike the simple atomic chain, the dispersion relation now has two branches (or bands). The reason an additional branch appears in the solution is due to the 2 degrees of freedom per unit cell. If we had started with 3 different atoms, the eigenvalue problem would contain 3 equation, so that there would be three eigenfrequencies per k and the dispersion relation would have 3 branches. The lower branch is called acoustic because its linear dispersion near \u03c9=0 matches the behavior of regular sound waves. The upper branch is the optical branch because it can cross with the (linear) dispersion relation of photons, allowing these phonons to efficiently emit and absorb photons. Like before, the phonon group velocity is v=\\textrm{d}\u03c9/\\textrm{d}k , and the density of states is g(\u03c9)=\\textrm{d}N/\\textrm{d}\u03c9 = \\frac{L}{2\u03c0} \u2211| \\textrm{d}k/\\textrm{d} \u03c9| . The sum goes over all states at a given energy. In this case, the sum ensures we include the contribution to the DOS from both the positive and negative momenta. Since the energy of this system is symmetric with respect to momentum reversal, the sum only introduces a factor of 2. An intuitive way to visualize the density of states g(\u03c9) is to consider it a histogram of the samples drawn from the dispersion relation \u03c9(k) : matplotlib . rcParams [ 'font.size' ] = 24 k = np . linspace ( -. 25 * pi , 1.5 * pi , 300 ) k_dos = np . linspace ( 0 , pi , 20 ) fig , ( ax , ax2 ) = pyplot . subplots ( ncols = 2 , sharey = True , figsize = ( 10 , 5 )) ax . plot ( k , dispersion_2m ( k , acoustic = False ), label = 'optical' ) ax . plot ( k , dispersion_2m ( k ), label = 'acoustic' ) ax . vlines ( k_dos , 0 , dispersion_2m ( k_dos , acoustic = False ), colors = ( 0.5 , 0.5 , 0.5 , 0.5 )) ax . hlines ( np . hstack (( dispersion_2m ( k_dos , acoustic = False ), dispersion_2m ( k_dos ))), np . hstack (( k_dos , k_dos )), 1.8 * pi , colors = ( 0.5 , 0.5 , 0.5 , 0.5 ) ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\u03c9$' ) ax . set_xticks ([ 0 , pi ]) ax . set_xticklabels ([ '$0$' , r '$\\pi$' ]) ax . set_yticks ([]) ax . set_yticklabels ([]) ax . set_xlim ( - pi / 4 , 2 * pi ) ax . set_ylim (( 0 , dispersion_2m ( 0 , acoustic = False ) + . 2 )) draw_classic_axes ( ax , xlabeloffset =. 2 ) k = np . linspace ( 0 , pi , 1000 ) omegas = np . hstack (( dispersion_2m ( k , acoustic = False ), dispersion_2m ( k ) )) ax2 . hist ( omegas , orientation = 'horizontal' , bins = 75 ) ax2 . set_xlabel ( r '$g(\u03c9)$' ) ax2 . set_ylabel ( r '$\u03c9$' ) # Truncate the singularity in the DOS max_x = ax2 . get_xlim ()[ 1 ] ax2 . set_xlim (( 0 , max_x / 2 )) draw_classic_axes ( ax2 , xlabeloffset =. 1 ) matplotlib . rcParams [ 'font.size' ] = 16 Note that g(\u03c9) is generally plotted along the vertical axis and \u03c9 along the horizontal axis \u2013 the right plot above is just to demonstrate the relation between the dispersion and the DOS. The singularities in g(\u03c9) at the bottom and top of each branch are called van Hove singularities .","title":"More degrees of freedom per unit cell:"},{"location":"07diatomic/#consistency-check-with-1-atom-per-cell","text":"To check if our result is consistent with the previous lecture, we examine what happens when we take m_1\\rightarrow m_2 . Physically, the system is then exactly the same as the 1D monatomic chain, so we would want our solutions to also be the same. But at first glance the two solutions seem very different: the solution with one atom has only one band, but the solution with two atoms has two bands. To reconcile the two pictures, let's plot two unit cells in reciprocal space. k = np . linspace ( 0 , 2 * pi , 300 ) k_dos = np . linspace ( 0 , pi , 20 ) fig , ax = pyplot . subplots () ax . plot ( k , dispersion_2m ( k , acoustic = False ), label = 'optical' ) ax . plot ( k , dispersion_2m ( k ), label = 'acoustic' ) omega_max = dispersion_2m ( 0 , acoustic = False ) ax . plot ( k , omega_max * np . sin ( k / 4 ), label = 'equal masses' ) ax . set_xlabel ( '$ka$' ) ax . set_ylabel ( r '$\u03c9$' ) ax . set_xticks ([ 0 , pi , 2 * pi ]) ax . set_xticklabels ([ '$0$' , r '$\\pi/2a$' , r '$\\pi/a$' ]) ax . set_yticks ([]) ax . set_yticklabels ([]) ax . set_xlim ( - pi / 8 , 2 * pi +. 4 ) ax . set_ylim (( 0 , dispersion_2m ( 0 , acoustic = False ) + . 2 )) ax . legend ( loc = 'lower right' ) pyplot . vlines ([ pi , 2 * pi ], 0 , 2.2 , linestyles = 'dashed' ) draw_classic_axes ( ax , xlabeloffset =. 2 ) We must be careful when considering the lattice constant a . In the 1D monatomic chain, a was the distance between two neighbouring atoms, but in our diatomic chain a is the size of the unit cell, which is twice as big. Therefore we take the size of our unit cell in the diatomic case to be 2a , so the physical systems are the same. Looking at the graph we see that doubling the lattice constant \"folds\" the band structure on itself. There are then 2 possible values of \u03c9 for each k , creating the 2 branches of the non-periodic system. We can look at the graph in two distinct ways: We can consider the green line (monatomic chain solution). Its Brillouin zone extends from 0 to \\pi / a . Alternatively, we consider the orange and blue lines together. In this case, the Brillouin zone is smaller ranging from 0 to \\pi / 2a (because of the larger lattice constant). Despite the two band structures look different, the density of states only changes very little: when m_1 \u2248 m_2 only the states near the band touching point slightly move in frequency.","title":"Consistency check with 1 atom per cell"},{"location":"07diatomic/#summary","text":"By using plane waves in real space as an ansatz, we found all normal modes of an atom chain with two different atoms. (Just like in the case of 1 degree of freedom per unit cell). The density of states can be derived graphically from the dispersion relation. The dispersion relation of a system with period a in real space is periodic with period 2\\pi/a in k -space. In a system with more than one degree of freedom per unit cell we need to consider independent amplitudes for each degree of freedom, and we get multiple bands. Systems with different band structures can have the same density of states.","title":"Summary"},{"location":"07diatomic/#exercises","text":"","title":"Exercises"},{"location":"07diatomic/#warm-up-questions","text":"Verify that the expression for \u03c9^2 is always positive. Why is this important? Work out the expression of \u03c9^2 in the case m_1 = m_2 . Compare this to the solution for the monatomic chain. When calculating the DOS, we only look at the first Brillouin zone. Why?","title":"Warm-up questions"},{"location":"07diatomic/#exercise-1-analyzing-the-diatomic-vibrating-chain","text":"As we have derived, the eigenfreqencies of a diatomic vibrating chain with 2 different masses are: \u03c9^2=\\frac{\u03ba(m_1+m_2)}{m_1m_2}\\pm \u03ba\\left\\{\\left(\\frac{m_1+m_2}{m_1m_2}\\right)^2-\\frac{4}{m_1m_2}\\sin^2\\left(\\frac{1}{2}ka\\right)\\right\\}^{\\frac{1}{2}}, where the plus sign corresponds to the optical branch and the minus sign to the acoustic branch. Find the magnitude of the group velocity near k=0 for the acoustic branch. Hint Make use of a Taylor expansion. Show that the group velocity at k=0 for the optical branch is zero. Derive an expression of the density of states g(\u03c9) for the acoustic branch and small k . Make use of your expression of the group velocity in 1. Compare this expression with that of the derived density of states from exercise 1 of the Debye lecture.","title":"Exercise 1: analyzing the diatomic vibrating chain"},{"location":"07diatomic/#exercise-2-the-peierls-transition","text":"In the previous lecture, we have derived the electronic band structure of an 1D, equally spaced atomic chain. Such chains, however, are in fact not stable and the equal spacing will be distorted. This is also known as the Peierls transition . The spacing of the distorted chain alternates between two different distances and this also causes the hopping energy to alternate between t_1 and t_2 . We further set the onsite energies of the atoms to \\epsilon . The situation is depicted in the figure below. Due to the alternating hopping energies, we must treat two consecutive atoms as two different orbitals ( |n,1\u27e9 and |n,2 \u27e9 in the figure) from the same unit cell. The corresponding LCAO of this chain is given by \\left|\\Psi \\right\\rangle = \\sum_n \\left(\\phi_n \\left| n,1 \\right\\rangle + \\psi_n \\left| n,2 \\right\\rangle\\right) As usual, we assume that all these atomic orbitals are orthogonal to each other. Indicate the length of the unit cell a in the figure. Using the Schr\u00f6dinger equation, write the equations of motion of the electrons. Hint To this end, find expressions for E \\left< n,1 \\vert \\Psi \\right> = \\left< n,1 \\right| H \\left|\\Psi \\right> and E \\left< n,2 \\vert \\Psi \\right> = \\left< n,2 \\right| H \\left|\\Psi \\right> . Using the trial solutions \\phi_n = \\phi_0 e^{ikna} and \\psi_n = \\psi_0 e^{ikna} , show that the Sch\u00f6dinger equation can be written in matrix form: \\begin{pmatrix} \\epsilon & t_1 + t_2 e^{-i k a} \\\\ t_1 + t_2 e^{i k a} & \\epsilon \\end{pmatrix} \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix} = E \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix}. Derive the dispersion relation of this Hamiltonian. Does it look like the figure of the band structure shown on the Wikipedia page ? Does it reduce to the 1D, equally spaced atomic chain if t_1 = t_2 ? Find an expression of the group velocity v(k) and effective mass m^*(k) of both bands. Derive an expression for the density of states g(E) of the entire band structure and make a plot of it. Does your result makes sense when considering the band structure?","title":"Exercise 2: the Peierls transition"},{"location":"07diatomic/#exercise-3-atomic-chain-with-3-different-spring-constants","text":"Suppose we have a vibrating 1D atomic chain with 3 different spring constants alternating like \\kappa_ 1 , \\kappa_2 , \\kappa_3 , \\kappa_1 , etc. All the the atoms in the chain have an equal mass m . Make a sketch of this chain and indicate the length of the unit cell a in this sketch. Derive the equations of motion for this chain. By filling in the trial solutions into the equations of motion (which should be similar to Ansazt used in the lecture), show that the eigenvalue problem is \\omega^2 \\mathbf{u} = \\frac{1}{m} \\begin{pmatrix} \\kappa_1 + \\kappa_ 3 & -\\kappa_ 1 & -\\kappa_ 3 e^{i k a} \\\\ -\\kappa_ 1 & \\kappa_1+\\kappa_2 & -\\kappa_ 2 \\\\ -\\kappa_ 3 e^{-i k a} & -\\kappa_2 & \\kappa_2 + \\kappa_ 3 \\end{pmatrix} \\mathbf{u} In general, the eigenvalue problem above cannot be solved analytically, and can only be solved in specific cases. Find the eigenvalues \u03c9^2 when k a = \\pi and \\kappa_1 = \u03ba_2 = q . Hint To solve the eigenvalue problem quickly, make use of the fact that the mass-spring matrix in that case commutes with the matrix X = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix}. What can be said about eigenvectors of two matrices that commute? What will happen to the periodicity of the band structure if \\kappa_ 1 = \\kappa_ 2 = \\kappa_3 ?","title":"Exercise 3: atomic chain with 3 different spring constants"},{"location":"additional/","text":"Additional resources \u00b6 This page is the space for additional resources which may prove to be of some use and/or interest for curious individuals. Websites Open Solid State Notes from Delft University of Technology : a site after my own heart, given the usage of the same reference text and the same static site generator . Moreover, the open-source nature of their project has proven to be an invaluable resource in providing ideas and aiding content production. Britney Spears' Guide to Semiconductor Physics : a relic of the time. A viral website before the phrase existed, the site does not hold up to modern standards - especially in light of the recent details of the singer's probate conservatorship - but sports surprisingly high-quality quality content relating to semiconductors, especially semiconductor lasers. Texts Quantum Mechanics and Quantum and Atom Optics by Daniel A. Steck from the University of Oregon : marvellous books that have been diligently curated and provide excellent reading for both revision and learning new content. Note that the Quantum and Atom Optics text contains relevant content and includes some of the most interesting material one is likely to encounter in the realm of quantum mechanics 1 , but it pitched at the graduate level and assumed knowledge of material not taught in the UTAS undergraduate program. I still think it worthwhile as an additional resource, but don't fret if it becomes a bit hard to follow once it gets into the weeds. and I am not just saying this because my research has been in this area, it is objectively true! \u21a9","title":"Additional resources"},{"location":"additional/#additional-resources","text":"This page is the space for additional resources which may prove to be of some use and/or interest for curious individuals. Websites Open Solid State Notes from Delft University of Technology : a site after my own heart, given the usage of the same reference text and the same static site generator . Moreover, the open-source nature of their project has proven to be an invaluable resource in providing ideas and aiding content production. Britney Spears' Guide to Semiconductor Physics : a relic of the time. A viral website before the phrase existed, the site does not hold up to modern standards - especially in light of the recent details of the singer's probate conservatorship - but sports surprisingly high-quality quality content relating to semiconductors, especially semiconductor lasers. Texts Quantum Mechanics and Quantum and Atom Optics by Daniel A. Steck from the University of Oregon : marvellous books that have been diligently curated and provide excellent reading for both revision and learning new content. Note that the Quantum and Atom Optics text contains relevant content and includes some of the most interesting material one is likely to encounter in the realm of quantum mechanics 1 , but it pitched at the graduate level and assumed knowledge of material not taught in the UTAS undergraduate program. I still think it worthwhile as an additional resource, but don't fret if it becomes a bit hard to follow once it gets into the weeds. and I am not just saying this because my research has been in this area, it is objectively true! \u21a9","title":"Additional resources"},{"location":"particulars/","text":"Course information \u00b6 Administration \u00b6 The solid-state component of the course will run for seven weeks, beginning in week 7 and concluding at the end of semester. In previous years, the solid-state physics and semiconductor physics components of the course have been explicitly differentiated; however, in this iteration, the two will be more closely intertwined, with semiconductors being considered a flourish to the foundations that we shall construct during our adventures in describing matter. Prerequisite knowledge The content covered in this course is complicated, and without the frim bedrock of requisite knowledge and associated competencies, attempts to construct additional structures may be compromised. It is critical that one is comfortable with the following: The principles and machinery of quantum mechanics. Explicitly, an understanding of how physical systems and their evolution are modelled using the Schr\u00f6dinger equation, along with a fluency in common examples (e.g. particle in a box, the Hydrogen atom), and a vague familiarity with Dirac notation is assumed. Thermodynamic quantities and concepts abound, with statistical mechanics looming large in the background. Conveniently, you have just completed a course in statistical mechanics, but it will be assumed that you are comfortable with the content It is my intention that you will be required to call upon many of the other tools from the toolbox that you have been developing during your studies, with the explicit aim of further honing these tools, and maybe adding a few to the kit. Delivery of content \u00b6 The course will operate in a flipped-mode configuration, whereby the undergirding principle is that your out-of-class time is used to consume prepared content (e.g. lectures ) and scheduled times are used for discussions in a problem-based learning framework. I prefer to refer to the lecture-style material as the content download , and interactive, active-learning sessions as the content unpacking component. Subject matter \u00b6 The content for this course draws heavily from off the excellent text The Oxford Solid State Basics by Steven H. Simon , and the book is a prescribed text for the course, that is, it is assumed that you will access to this book. This particular text was chosen because of its concise discussion of the content, its accessibility, and the wry whit which permeates the content, in concert with the availability of freely distributed pre-print of the book . I will be working from the printed text, and I encourage you to do the same. Unsupported material Steven himself has said that the preprint is roughly 85% of the book; however, if you elect to work from the preprint, you do so at your own risk. Course outline \u00b6 Course summary This subject is designed to serve as an introduction into the field of solid-state physics. Solid-state physics is the largest field of condensed matter physics, which itself is the largest branch of physics, and so there is only so material we will cover. The trajectory we shall take begins with bulk descriptors of solids, into considering the fundamental nature of solids, collective behaviour within solids, and the place of these systems in the real world. A rough outline of the course is as follows: An introduction to solid-state physics The structure of materials Solids in one dimension The geometry of solids Electrons in solids Magnetism with approximately one week devoted to each topic, but with the natural ebb and flow ultimately dictating the timeline. Content download A brief summary of the topics discussed in the content download sessions is shown below: Video Topic(s) discussed w0v01 Introduction: solid-state physics information w1v01 Specific heat of solids w1v02 The Drude model w1v03 The Sommerfeld model Support \u00b6 You are not on this journey alone: there are many avenues available to you to help you on the journey. Depending on your inclination to play antiquated video games, you may recognise this as a scene from The Legend of Zelda . \" We are all in this together \" \u00b6 The course materials as consumed through the content download components are necessarily an individual effort, but in all other facets I strongly encourage collaboration. The structure of content unpacking sessions is deliberately geared towards discussion, the exchange of ideas, and collective problem solving moreso than the execution of a solution finding program. Computational resources \u00b6 As part of the course, it will be expected that you perform calculation and computations. You are welcome to do this in which ever language you prefer, but it is strongly recommended that you use Python , and indeed, this is the only language that will be supported. In order to ensure equitable and easy access to Python computing resources, a Jupyter Notebook server has been established, which allows for one to write and execute code via a web browser. The server is named Jove 1 , and access is through the JupyterHub portal . You will need to create an account to start using the server, but beyond this is should be click and go. Materials and exercises may be deployed directly to Jove via Binder Should you have a machine upon which you already have, or you wish to deploy, your own instance of Python , this is perfectly acceptable, but note that you will have to manually import and distributed materials into Jupyter. As it stands, there would be no requirement for any packages not included in the Anaconda distribution. For those wondering, Jove is an alternate name for the Roman god Jupiter. \u21a9","title":"Course particulars"},{"location":"particulars/#course-information","text":"","title":"Course information"},{"location":"particulars/#administration","text":"The solid-state component of the course will run for seven weeks, beginning in week 7 and concluding at the end of semester. In previous years, the solid-state physics and semiconductor physics components of the course have been explicitly differentiated; however, in this iteration, the two will be more closely intertwined, with semiconductors being considered a flourish to the foundations that we shall construct during our adventures in describing matter. Prerequisite knowledge The content covered in this course is complicated, and without the frim bedrock of requisite knowledge and associated competencies, attempts to construct additional structures may be compromised. It is critical that one is comfortable with the following: The principles and machinery of quantum mechanics. Explicitly, an understanding of how physical systems and their evolution are modelled using the Schr\u00f6dinger equation, along with a fluency in common examples (e.g. particle in a box, the Hydrogen atom), and a vague familiarity with Dirac notation is assumed. Thermodynamic quantities and concepts abound, with statistical mechanics looming large in the background. Conveniently, you have just completed a course in statistical mechanics, but it will be assumed that you are comfortable with the content It is my intention that you will be required to call upon many of the other tools from the toolbox that you have been developing during your studies, with the explicit aim of further honing these tools, and maybe adding a few to the kit.","title":"Administration"},{"location":"particulars/#delivery-of-content","text":"The course will operate in a flipped-mode configuration, whereby the undergirding principle is that your out-of-class time is used to consume prepared content (e.g. lectures ) and scheduled times are used for discussions in a problem-based learning framework. I prefer to refer to the lecture-style material as the content download , and interactive, active-learning sessions as the content unpacking component.","title":"Delivery of content"},{"location":"particulars/#subject-matter","text":"The content for this course draws heavily from off the excellent text The Oxford Solid State Basics by Steven H. Simon , and the book is a prescribed text for the course, that is, it is assumed that you will access to this book. This particular text was chosen because of its concise discussion of the content, its accessibility, and the wry whit which permeates the content, in concert with the availability of freely distributed pre-print of the book . I will be working from the printed text, and I encourage you to do the same. Unsupported material Steven himself has said that the preprint is roughly 85% of the book; however, if you elect to work from the preprint, you do so at your own risk.","title":"Subject matter"},{"location":"particulars/#course-outline","text":"Course summary This subject is designed to serve as an introduction into the field of solid-state physics. Solid-state physics is the largest field of condensed matter physics, which itself is the largest branch of physics, and so there is only so material we will cover. The trajectory we shall take begins with bulk descriptors of solids, into considering the fundamental nature of solids, collective behaviour within solids, and the place of these systems in the real world. A rough outline of the course is as follows: An introduction to solid-state physics The structure of materials Solids in one dimension The geometry of solids Electrons in solids Magnetism with approximately one week devoted to each topic, but with the natural ebb and flow ultimately dictating the timeline. Content download A brief summary of the topics discussed in the content download sessions is shown below: Video Topic(s) discussed w0v01 Introduction: solid-state physics information w1v01 Specific heat of solids w1v02 The Drude model w1v03 The Sommerfeld model","title":"Course outline"},{"location":"particulars/#support","text":"You are not on this journey alone: there are many avenues available to you to help you on the journey. Depending on your inclination to play antiquated video games, you may recognise this as a scene from The Legend of Zelda .","title":"Support"},{"location":"particulars/#we-are-all-in-this-together","text":"The course materials as consumed through the content download components are necessarily an individual effort, but in all other facets I strongly encourage collaboration. The structure of content unpacking sessions is deliberately geared towards discussion, the exchange of ideas, and collective problem solving moreso than the execution of a solution finding program.","title":"\"We are all in this together\""},{"location":"particulars/#computational-resources","text":"As part of the course, it will be expected that you perform calculation and computations. You are welcome to do this in which ever language you prefer, but it is strongly recommended that you use Python , and indeed, this is the only language that will be supported. In order to ensure equitable and easy access to Python computing resources, a Jupyter Notebook server has been established, which allows for one to write and execute code via a web browser. The server is named Jove 1 , and access is through the JupyterHub portal . You will need to create an account to start using the server, but beyond this is should be click and go. Materials and exercises may be deployed directly to Jove via Binder Should you have a machine upon which you already have, or you wish to deploy, your own instance of Python , this is perfectly acceptable, but note that you will have to manually import and distributed materials into Jupyter. As it stands, there would be no requirement for any packages not included in the Anaconda distribution. For those wondering, Jove is an alternate name for the Roman god Jupiter. \u21a9","title":"Computational resources"},{"location":"placeholder/","text":"This is blank!","title":"Empty content"},{"location":"Solutions/solutions/","text":"Solutions to exercises \u00b6 Solutions for The specific heat of solids I exercises \u00b6 Preliminary provocations \u00b6 C = 2k_B . Exercise 1: Total heat capacity of a diatomic material \u00b6 Use the formula \\omega = \\sqrt{\\frac{k}{m}} . Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}(2 + 1/2) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}(4 + 1/2). Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}\\left(n_B(\\beta\\hbar\\omega_{^6Li}) + \\frac{1}{2}\\right) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}\\left(n_B(\\beta\\hbar\\omega_{^7Li}) + \\frac{1}{2}\\right). Heat capacity per atom is given by C = \\frac{N_{^6Li}}{N}C_{^6Li} + \\frac{N_{^7Li}}{N}C_{^7Li}, Solutions for The specific heat of solids II exercises \u00b6 Preliminary provocations \u00b6 The polarization is related to the direction of the amplitudes of the waves with respect to the direction of the wave. In 3D, there are only 3 different amplitude directions possible. 2. \\int k_x k_y \\rightarrow \\int_{0}^{2\\pi} \\mathrm{d} \\theta \\int_{0}^{\\infty} k \\mathrm{d} k = 2\\pi \\int_{0}^{\\infty} k \\mathrm{d} k The Debye frequency \\omega_D . The wavelength is of the order of the interatomic spacing: \\lambda = (\\frac{4}{3}\\pi)^{1/3} a. Exercise 1: Debye model: concepts. \u00b6 k = \\frac{4\\pi}{L} and k = -\\frac{4\\pi}{L} . 2. The number of states per k or per frequency. 4. g(\\omega) = \\frac{dN}{d\\omega} = \\frac{dN}{dk}\\frac{dk}{d\\omega} = \\frac{1}{v}\\frac{dN}{dk}. We assume that in d dimensions there are d polarizations. For 1D we have that N = \\frac{L}{2\\pi}\\int_{-k}^{k} dk , hence g(\\omega) = \\frac{L}{\\pi v} . For 2D we have that N = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int d^2k = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int 2\\pi kdk , hence g(\\omega) = \\frac{L^2\\omega}{\\pi v^2} . For 3D we have that N = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int 4\\pi k^2dk , hence g(\\omega) = \\frac{3L^3\\omega^2}{2\\pi^2v^3} . Exercise 2: Debye model in 2D. \u00b6 See lecture notes. \\begin{align} E &= \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega \\\\ &= \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^2}{e^{x} - 1}dx + C. \\end{align} High temperature implies \\beta \\rightarrow 0 , hence E = \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\frac{(\\beta\\hbar\\omega_D)^2}{2} + C , and then C = \\frac{k_BL^2\\omega^2_D}{2\\pi v^2} = 2Nk_B . We've used the value for \\omega_D calculated from 2N = \\int_{0}^{\\omega_D}g(\\omega)d\\omega . In the low temperature limit we have that \\beta \\rightarrow \\infty , hence E \\approx \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx + C = \\frac{2\\zeta(3)L^2}{\\pi v^2\\hbar^2\\beta^3} + C . Finally C = \\frac{6\\zeta(3)k^3_BL^2}{\\pi v^2\\hbar^2}T^2 . We used the fact that \\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx = 2\\zeta(3) where \\zeta is the Riemann zeta function. Exercise 3: Different phonon modes. \u00b6 g(\\omega) = \\sum_{\\text{polarizations}}\\frac{dN}{dk}\\frac{dk}{d\\omega} = \\left(\\frac{L}{2\\pi}\\right)^3\\sum_{\\text{polarizations}}4\\pi k^2\\frac{dk}{d\\omega} = \\frac{L^3}{2\\pi^2}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\omega^2 E = \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega = \\frac{L^3}{2\\pi^2\\hbar^3\\beta^4}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^3}{e^{x} - 1}dx + C. Note that we can get \\omega_D from 3N = \\int_{0}^{\\omega_D}g(\\omega) so everything cancels as usual and we are left with the Dulong-Petit law C = 3Nk_B . In the low temperature limit we have that C \\sim \\frac{2\\pi^2k_B^4L^3}{15\\hbar^3}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)T^3 . We used that \\int_{0}^{\\infty}\\frac{x^3}{e^{x} - 1}dx = \\frac{\\pi^4}{15} . Exercise 4: Anisotropic sound velocities. \u00b6 E = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k\\hbar\\omega(\\mathbf{k})\\left(n_B(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) = 3\\left(\\frac{L}{2\\pi}\\right)^3\\frac{1}{v_xv_yv_z}\\int d^3\\kappa\\frac{\\hbar\\kappa}{e^{\\beta\\hbar\\kappa} - 1} + C, where we used the substitutions \\kappa_x = k_xv_x,\\kappa_y = k_yv_y, \\kappa_z = k_zv_z . Finally E = \\frac{3\\hbar L^3}{2\\pi^2}\\frac{1}{v_xv_yv_z}\\int_0^{\\kappa_D} d\\kappa\\frac{\\kappa^3}{e^{\\beta\\hbar\\kappa} - 1} + C = \\frac{3L^3}{2\\pi^2\\hbar^3\\beta^4}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1} + C, hence C = \\frac{\\partial E}{\\partial T} = \\frac{6k_B^4L^3T^3}{\\pi^2\\hbar^3}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1} . We see that the result is similar to the one with the linear dispersion, the only difference is the factor 1/v_xv_yv_z instead of 1/v^3 . Solutions for Electrons in metals I exercises \u00b6 Exercise 1: Extracting quantities from basic Hall measurements \u00b6 Hall voltage is measured across the sample width. Hence, V_H = -\\int_{0}^{W} E_ydy where E_y = -v_xB . R_{xy} = -\\frac{B}{ne} , so it does not depend on the sample geometry. If hall resistance and magnetic field are known, the charge density is calculated from R_{xy} = -\\frac{B}{ne} . As V_x = -\\frac{I_x}{ne}B , a stronger field makes Hall voltages easier to measure. 3. R_{xx} = \\frac{\\rho_{xx}L}{W} where \\rho_{xx} = \\frac{m_e}{ne^2\\tau} . Therefore, scattering time ( \\tau ) is known and R_{xx} depend upon the sample geometry. Exercise 2: Motion of an electron in a magnetic and an electric field \u00b6 1. m\\frac{d\\bf v}{dt} = -e(\\bf v \\times \\bf B) Magnetic field affects only the velocities along x and y, i.e., v_x(t) and v_y(t) as they are perpendicular to it. Therefore, the equations of motion for the electron are \\frac{dv_x}{dt} = -\\frac{e v_y B_z}{m} \\frac{dv_y}{dt} = \\frac{e v_x B_z}{m} We can compute v_x(t) and v_y(t) by solving the differential equations in 1. From v_x'' = -\\frac{e^2B_z^2}{m^2}v_x and the initial conditions, we find v_x(t) = v_0 \\cos(\\omega_c t) with \\omega_c=eB_z/m . From this we can derive v_y(t)=v_0\\sin(\\omega_c t) . We now calculate the particle position using x(t)=x(0) + \\int_0^t v_x(t')dt' (and similar for y(t) ). From this we can find a relation between the x - and y -coordinates of the particle (x(t) - x_0)^2 + (y(t) - y_0)^2 = \\frac{v_0^2}{\\omega_c^2}. This equation describes a circular motion around the point x_0=x(0), y_0=y(0)+v_0/\\omega , where the characteristic frequency \\omega_c is called the cyclotron frequency. Intuition: \\frac{mv^2}{r} = evB (centripetal force = Lorentz force due to magnetic field). Due to the applied electric field \\bf E in the x -direction, the equations of motion acquire an extra term: m v_x' = -e(E_x + v_yB_z). Differentiating w.r.t. time leads to the same 2nd-order D.E. for v_x as above. However, for v_y we get v_y'' = -\\omega_c^2(v_d+v_y), where we defined v_d=\\frac{E_x}{B_z} . The general solutions are v_y(t) = c_1\\sin(\\omega_c t)+ c_2\\cos(\\omega_c t) -v_d \\\\ v_x(t) = c_3\\sin(\\omega_c t)+ c_4\\cos(\\omega_c t). Using the initial conditions v_x(0)=v_0 and v_y(0)=0 and the 1st order D.E. above, we can show v_y(t) = v_0\\sin(\\omega_c t)+ v_d\\cos(\\omega_c t) -v_d \\\\ v_x(t) = v_d\\sin(\\omega_c t)+ v_0\\cos(\\omega_c t). By integrating the expressions for the velocity we find: (x(t)-x_0)^2 + (y(t) - y_0 + v_d t))^2 = \\frac{v_0^2}{\\omega_c^2}. This represents a cycloid : a circular motion around a point that moves in the y -direction with velocity v_d=\\frac{E_x}{B_z} . Exercise 3: Temperature dependence of resistance in the Drude model \u00b6 Find electron density from n_e = \\frac{Z n N_A}{W} where Z is valence of copper atom, n is density, N_A is Avogadro constant and W is atomic weight. Use \\rho = 1/\\sigma from the lecture notes to calculate scattering time. \\sigma = \\frac{n e^2 \\tau}{m} \\lambda = \\langle v \\rangle\\tau Scattering time \\tau \\propto \\frac{1}{\\sqrt{T}} ; \\rho \\propto \\sqrt{T} In general, \\rho \\propto T as the phonons in the system scales linearly with T (remember high temperature limit of Bose-Einstein factor becomes \\frac{kT}{\\hbar\\omega} leading to \\rho \\propto T ). Inability to explain this linear dependence is a failure of the Drude model. Exercise 4: The Hall conductivity matrix and the Hall coefficient \u00b6 \\rho_{xx} is independent of B and \\rho_{xy} \\propto B 2. \\sigma_{xx} = \\frac{\\rho_{xx}}{\\rho_{xx}^2 + \\rho_{xy}^2} \\sigma_{xy} = \\frac{-\\rho_{yx}}{\\rho_{xx}^2 + \\rho_{xy}^2} This describes a Lorentzian . Solutions for exercises lecture 4: Sommerfeld model \u00b6 Warm-up questions \u00b6 1. E = \\int \\limits_0^{\\infty} g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\varepsilon \\mathrm{d} \\varepsilon The electronic heat capacity C_e approaches 3N k_B . Thermal smearing is too significant and we can not accurately approximate the fraction of the excited electron with triangles anymore. Thus the Sommerfeld expansion breaks down. Electrons. Exercise 1: potassium \u00b6 Alkali metals mostly have a spherical Fermi surface. Their energy depends only on the magnitude of the Fermi wavevector. Refer to the lecture notes. Electrons are fermions and obey the Pauli exclusion principle. As electrons cannot occupy the same state, they are forced to occupy higher energy states resulting in high Fermi energy and high Fermi temperature. 4. n = \\frac{N}{V} = \\frac{1}{3 \\pi^{2} \\hbar^{3}}\\left(2 m \\varepsilon_{F}\\right)^{3 / 2} 5. n = \\frac{\\rho N_A Z}{M}, where \\rho is the density, N_A is the Avogadro's constant, M is molar mass and Z is the valence of potassium atom. Comparing total and free electron density, only few electrons are available for conduction which is roughly 1 free electron per potassium atom. Exercise 3: a hypothetical material \u00b6 1. E = \\int_{0}^{\\infty}\\varepsilon g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\textrm{d} \\varepsilon = 2.10^{10}eV^{-\\frac{3}{2}} \\int_{0}^{\\infty}\\frac{\\varepsilon^{\\frac{3}{2}}}{e^\\frac{\\varepsilon-5.2}{k_BT}+1} \\textrm{d} \\varepsilon 2. E = \\frac{4}{5} (5.2)^{\\frac{5}{2}} 10^{10} eV 3. \\begin{align} E(T)-E(T=0) &= \\frac{\\pi^2}{6}(k_B T)^2\\frac{\\partial}{\\partial \\varepsilon}\\left(\\varepsilon g(\\varepsilon)\\right)\\bigg|_{\\varepsilon=\\varepsilon _F}\\\\ &\\approx 8.356 10^8 eV \\end{align} 5. C_v = 1.6713.10^6 eV/K 4, 6. mu = 5.2 kB = 8.617343e-5 T = 1000 #kelvin import numpy as np from scipy import integrate np . seterr ( over = 'ignore' ) # Fermi-Dirac distribution def f ( E , T ): return 1 / ( np . exp (( E - mu ) / ( kB * T )) + 1 ) # Density of states def g ( E ): return 2e10 * np . sqrt ( E ) #integration function def integral ( E , T ): return f ( E , T ) * g ( E ) * E ## Solve integral numerically using scipy's integrate dE = integrate . quad ( integral , 0 , 1e1 , args = ( T ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dT = 0.001 dEplus = integrate . quad ( integral , 0 , 1e1 , args = ( T + dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dEmin = integrate . quad ( integral , 0 , 1e1 , args = ( T - dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) CV = ( dEplus - dEmin ) / ( 2 * dT ); print ( f 'dE = { dE : .4e } eV' ) print ( f 'Cv = { CV : .4e } eV/K' ) Check the source code written in python for solving integral using midpoint rule. Exercise 3: graphene \u00b6 1. import numpy as np import matplotlib.pyplot as plt x = np . linspace ( - 1 , 1 , 100 ) fig , ax = plt . subplots ( figsize = ( 7 , 5 )) ax . plot ( x , x , 'b' ) ax . plot ( x , - x , 'b' ) ax . spines [ 'left' ] . set_position ( 'center' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0.0 )) # Eliminate upper and right axes ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . set_xticks ([]) ax . set_yticks ([]) ax . set_xlabel ( r '$\\mid \\vec k \\mid$' , fontsize = 14 ) ax . set_ylabel ( r '$\\varepsilon$' , fontsize = 18 , rotation = 'horizontal' ) ax . yaxis . set_label_coords ( 0.5 , 1 ) ax . xaxis . set_label_coords ( 1.0 , 0.49 ) 2.The DOS for the positive energies is given by g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{\\varepsilon}{c^2}, where 2_s is the spin degeneracy and 2_v is the valley degeneracy. If we account for the negative energies as well, we obtain g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{|\\varepsilon|}{c^2}. 3. g(\\varepsilon) vs \\varepsilon is a linear plot. Here, the region marked by -k_B T is a triangle whose area gives the number of electrons that can be excited: \\begin{align} n_{ex} &= \\frac{1}{2} g(-k_B T) k_B T\\\\ &= \\frac{L^2 k_B^2T^2}{\\pi c^2}. \\end{align} From this it follows that the energy difference is given by E(T) - E_0 = \\frac{L^2 k_B^3T^3}{\\pi c^2}. 4. C_v(T) = \\frac{\\partial E}{\\partial T} = \\frac{3L^2k_B^3T^2}{\\pi c^2}","title":"Solutions to exercises"},{"location":"Solutions/solutions/#solutions-to-exercises","text":"","title":"Solutions to exercises"},{"location":"Solutions/solutions/#solutions-for-the-specific-heat-of-solids-i-exercises","text":"","title":"Solutions for The specific heat of solids I exercises"},{"location":"Solutions/solutions/#preliminary-provocations","text":"C = 2k_B .","title":"Preliminary provocations"},{"location":"Solutions/solutions/#exercise-1-total-heat-capacity-of-a-diatomic-material","text":"Use the formula \\omega = \\sqrt{\\frac{k}{m}} . Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}(2 + 1/2) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}(4 + 1/2). Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}\\left(n_B(\\beta\\hbar\\omega_{^6Li}) + \\frac{1}{2}\\right) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}\\left(n_B(\\beta\\hbar\\omega_{^7Li}) + \\frac{1}{2}\\right). Heat capacity per atom is given by C = \\frac{N_{^6Li}}{N}C_{^6Li} + \\frac{N_{^7Li}}{N}C_{^7Li},","title":"Exercise 1: Total heat capacity of a diatomic material"},{"location":"Solutions/solutions/#solutions-for-the-specific-heat-of-solids-ii-exercises","text":"","title":"Solutions for The specific heat of solids II exercises"},{"location":"Solutions/solutions/#preliminary-provocations_1","text":"The polarization is related to the direction of the amplitudes of the waves with respect to the direction of the wave. In 3D, there are only 3 different amplitude directions possible. 2. \\int k_x k_y \\rightarrow \\int_{0}^{2\\pi} \\mathrm{d} \\theta \\int_{0}^{\\infty} k \\mathrm{d} k = 2\\pi \\int_{0}^{\\infty} k \\mathrm{d} k The Debye frequency \\omega_D . The wavelength is of the order of the interatomic spacing: \\lambda = (\\frac{4}{3}\\pi)^{1/3} a.","title":"Preliminary provocations"},{"location":"Solutions/solutions/#exercise-1-debye-model-concepts","text":"k = \\frac{4\\pi}{L} and k = -\\frac{4\\pi}{L} . 2. The number of states per k or per frequency. 4. g(\\omega) = \\frac{dN}{d\\omega} = \\frac{dN}{dk}\\frac{dk}{d\\omega} = \\frac{1}{v}\\frac{dN}{dk}. We assume that in d dimensions there are d polarizations. For 1D we have that N = \\frac{L}{2\\pi}\\int_{-k}^{k} dk , hence g(\\omega) = \\frac{L}{\\pi v} . For 2D we have that N = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int d^2k = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int 2\\pi kdk , hence g(\\omega) = \\frac{L^2\\omega}{\\pi v^2} . For 3D we have that N = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int 4\\pi k^2dk , hence g(\\omega) = \\frac{3L^3\\omega^2}{2\\pi^2v^3} .","title":"Exercise 1: Debye model: concepts."},{"location":"Solutions/solutions/#exercise-2-debye-model-in-2d","text":"See lecture notes. \\begin{align} E &= \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega \\\\ &= \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^2}{e^{x} - 1}dx + C. \\end{align} High temperature implies \\beta \\rightarrow 0 , hence E = \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\frac{(\\beta\\hbar\\omega_D)^2}{2} + C , and then C = \\frac{k_BL^2\\omega^2_D}{2\\pi v^2} = 2Nk_B . We've used the value for \\omega_D calculated from 2N = \\int_{0}^{\\omega_D}g(\\omega)d\\omega . In the low temperature limit we have that \\beta \\rightarrow \\infty , hence E \\approx \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx + C = \\frac{2\\zeta(3)L^2}{\\pi v^2\\hbar^2\\beta^3} + C . Finally C = \\frac{6\\zeta(3)k^3_BL^2}{\\pi v^2\\hbar^2}T^2 . We used the fact that \\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx = 2\\zeta(3) where \\zeta is the Riemann zeta function.","title":"Exercise 2: Debye model in 2D."},{"location":"Solutions/solutions/#exercise-3-different-phonon-modes","text":"g(\\omega) = \\sum_{\\text{polarizations}}\\frac{dN}{dk}\\frac{dk}{d\\omega} = \\left(\\frac{L}{2\\pi}\\right)^3\\sum_{\\text{polarizations}}4\\pi k^2\\frac{dk}{d\\omega} = \\frac{L^3}{2\\pi^2}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\omega^2 E = \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega = \\frac{L^3}{2\\pi^2\\hbar^3\\beta^4}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^3}{e^{x} - 1}dx + C. Note that we can get \\omega_D from 3N = \\int_{0}^{\\omega_D}g(\\omega) so everything cancels as usual and we are left with the Dulong-Petit law C = 3Nk_B . In the low temperature limit we have that C \\sim \\frac{2\\pi^2k_B^4L^3}{15\\hbar^3}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)T^3 . We used that \\int_{0}^{\\infty}\\frac{x^3}{e^{x} - 1}dx = \\frac{\\pi^4}{15} .","title":"Exercise 3: Different phonon modes."},{"location":"Solutions/solutions/#exercise-4-anisotropic-sound-velocities","text":"E = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k\\hbar\\omega(\\mathbf{k})\\left(n_B(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) = 3\\left(\\frac{L}{2\\pi}\\right)^3\\frac{1}{v_xv_yv_z}\\int d^3\\kappa\\frac{\\hbar\\kappa}{e^{\\beta\\hbar\\kappa} - 1} + C, where we used the substitutions \\kappa_x = k_xv_x,\\kappa_y = k_yv_y, \\kappa_z = k_zv_z . Finally E = \\frac{3\\hbar L^3}{2\\pi^2}\\frac{1}{v_xv_yv_z}\\int_0^{\\kappa_D} d\\kappa\\frac{\\kappa^3}{e^{\\beta\\hbar\\kappa} - 1} + C = \\frac{3L^3}{2\\pi^2\\hbar^3\\beta^4}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1} + C, hence C = \\frac{\\partial E}{\\partial T} = \\frac{6k_B^4L^3T^3}{\\pi^2\\hbar^3}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1} . We see that the result is similar to the one with the linear dispersion, the only difference is the factor 1/v_xv_yv_z instead of 1/v^3 .","title":"Exercise 4: Anisotropic sound velocities."},{"location":"Solutions/solutions/#solutions-for-electrons-in-metals-i-exercises","text":"","title":"Solutions for Electrons in metals I exercises"},{"location":"Solutions/solutions/#exercise-1-extracting-quantities-from-basic-hall-measurements","text":"Hall voltage is measured across the sample width. Hence, V_H = -\\int_{0}^{W} E_ydy where E_y = -v_xB . R_{xy} = -\\frac{B}{ne} , so it does not depend on the sample geometry. If hall resistance and magnetic field are known, the charge density is calculated from R_{xy} = -\\frac{B}{ne} . As V_x = -\\frac{I_x}{ne}B , a stronger field makes Hall voltages easier to measure. 3. R_{xx} = \\frac{\\rho_{xx}L}{W} where \\rho_{xx} = \\frac{m_e}{ne^2\\tau} . Therefore, scattering time ( \\tau ) is known and R_{xx} depend upon the sample geometry.","title":"Exercise 1: Extracting quantities from basic Hall measurements"},{"location":"Solutions/solutions/#exercise-2-motion-of-an-electron-in-a-magnetic-and-an-electric-field","text":"1. m\\frac{d\\bf v}{dt} = -e(\\bf v \\times \\bf B) Magnetic field affects only the velocities along x and y, i.e., v_x(t) and v_y(t) as they are perpendicular to it. Therefore, the equations of motion for the electron are \\frac{dv_x}{dt} = -\\frac{e v_y B_z}{m} \\frac{dv_y}{dt} = \\frac{e v_x B_z}{m} We can compute v_x(t) and v_y(t) by solving the differential equations in 1. From v_x'' = -\\frac{e^2B_z^2}{m^2}v_x and the initial conditions, we find v_x(t) = v_0 \\cos(\\omega_c t) with \\omega_c=eB_z/m . From this we can derive v_y(t)=v_0\\sin(\\omega_c t) . We now calculate the particle position using x(t)=x(0) + \\int_0^t v_x(t')dt' (and similar for y(t) ). From this we can find a relation between the x - and y -coordinates of the particle (x(t) - x_0)^2 + (y(t) - y_0)^2 = \\frac{v_0^2}{\\omega_c^2}. This equation describes a circular motion around the point x_0=x(0), y_0=y(0)+v_0/\\omega , where the characteristic frequency \\omega_c is called the cyclotron frequency. Intuition: \\frac{mv^2}{r} = evB (centripetal force = Lorentz force due to magnetic field). Due to the applied electric field \\bf E in the x -direction, the equations of motion acquire an extra term: m v_x' = -e(E_x + v_yB_z). Differentiating w.r.t. time leads to the same 2nd-order D.E. for v_x as above. However, for v_y we get v_y'' = -\\omega_c^2(v_d+v_y), where we defined v_d=\\frac{E_x}{B_z} . The general solutions are v_y(t) = c_1\\sin(\\omega_c t)+ c_2\\cos(\\omega_c t) -v_d \\\\ v_x(t) = c_3\\sin(\\omega_c t)+ c_4\\cos(\\omega_c t). Using the initial conditions v_x(0)=v_0 and v_y(0)=0 and the 1st order D.E. above, we can show v_y(t) = v_0\\sin(\\omega_c t)+ v_d\\cos(\\omega_c t) -v_d \\\\ v_x(t) = v_d\\sin(\\omega_c t)+ v_0\\cos(\\omega_c t). By integrating the expressions for the velocity we find: (x(t)-x_0)^2 + (y(t) - y_0 + v_d t))^2 = \\frac{v_0^2}{\\omega_c^2}. This represents a cycloid : a circular motion around a point that moves in the y -direction with velocity v_d=\\frac{E_x}{B_z} .","title":"Exercise 2: Motion of an electron in a magnetic and an electric field"},{"location":"Solutions/solutions/#exercise-3-temperature-dependence-of-resistance-in-the-drude-model","text":"Find electron density from n_e = \\frac{Z n N_A}{W} where Z is valence of copper atom, n is density, N_A is Avogadro constant and W is atomic weight. Use \\rho = 1/\\sigma from the lecture notes to calculate scattering time. \\sigma = \\frac{n e^2 \\tau}{m} \\lambda = \\langle v \\rangle\\tau Scattering time \\tau \\propto \\frac{1}{\\sqrt{T}} ; \\rho \\propto \\sqrt{T} In general, \\rho \\propto T as the phonons in the system scales linearly with T (remember high temperature limit of Bose-Einstein factor becomes \\frac{kT}{\\hbar\\omega} leading to \\rho \\propto T ). Inability to explain this linear dependence is a failure of the Drude model.","title":"Exercise 3: Temperature dependence of resistance in the Drude model"},{"location":"Solutions/solutions/#exercise-4-the-hall-conductivity-matrix-and-the-hall-coefficient","text":"\\rho_{xx} is independent of B and \\rho_{xy} \\propto B 2. \\sigma_{xx} = \\frac{\\rho_{xx}}{\\rho_{xx}^2 + \\rho_{xy}^2} \\sigma_{xy} = \\frac{-\\rho_{yx}}{\\rho_{xx}^2 + \\rho_{xy}^2} This describes a Lorentzian .","title":"Exercise 4: The Hall conductivity matrix and the Hall coefficient"},{"location":"Solutions/solutions/#solutions-for-exercises-lecture-4-sommerfeld-model","text":"","title":"Solutions for exercises lecture 4: Sommerfeld model"},{"location":"Solutions/solutions/#warm-up-questions","text":"1. E = \\int \\limits_0^{\\infty} g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\varepsilon \\mathrm{d} \\varepsilon The electronic heat capacity C_e approaches 3N k_B . Thermal smearing is too significant and we can not accurately approximate the fraction of the excited electron with triangles anymore. Thus the Sommerfeld expansion breaks down. Electrons.","title":"Warm-up questions"},{"location":"Solutions/solutions/#exercise-1-potassium","text":"Alkali metals mostly have a spherical Fermi surface. Their energy depends only on the magnitude of the Fermi wavevector. Refer to the lecture notes. Electrons are fermions and obey the Pauli exclusion principle. As electrons cannot occupy the same state, they are forced to occupy higher energy states resulting in high Fermi energy and high Fermi temperature. 4. n = \\frac{N}{V} = \\frac{1}{3 \\pi^{2} \\hbar^{3}}\\left(2 m \\varepsilon_{F}\\right)^{3 / 2} 5. n = \\frac{\\rho N_A Z}{M}, where \\rho is the density, N_A is the Avogadro's constant, M is molar mass and Z is the valence of potassium atom. Comparing total and free electron density, only few electrons are available for conduction which is roughly 1 free electron per potassium atom.","title":"Exercise 1: potassium"},{"location":"Solutions/solutions/#exercise-3-a-hypothetical-material","text":"1. E = \\int_{0}^{\\infty}\\varepsilon g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\textrm{d} \\varepsilon = 2.10^{10}eV^{-\\frac{3}{2}} \\int_{0}^{\\infty}\\frac{\\varepsilon^{\\frac{3}{2}}}{e^\\frac{\\varepsilon-5.2}{k_BT}+1} \\textrm{d} \\varepsilon 2. E = \\frac{4}{5} (5.2)^{\\frac{5}{2}} 10^{10} eV 3. \\begin{align} E(T)-E(T=0) &= \\frac{\\pi^2}{6}(k_B T)^2\\frac{\\partial}{\\partial \\varepsilon}\\left(\\varepsilon g(\\varepsilon)\\right)\\bigg|_{\\varepsilon=\\varepsilon _F}\\\\ &\\approx 8.356 10^8 eV \\end{align} 5. C_v = 1.6713.10^6 eV/K 4, 6. mu = 5.2 kB = 8.617343e-5 T = 1000 #kelvin import numpy as np from scipy import integrate np . seterr ( over = 'ignore' ) # Fermi-Dirac distribution def f ( E , T ): return 1 / ( np . exp (( E - mu ) / ( kB * T )) + 1 ) # Density of states def g ( E ): return 2e10 * np . sqrt ( E ) #integration function def integral ( E , T ): return f ( E , T ) * g ( E ) * E ## Solve integral numerically using scipy's integrate dE = integrate . quad ( integral , 0 , 1e1 , args = ( T ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dT = 0.001 dEplus = integrate . quad ( integral , 0 , 1e1 , args = ( T + dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dEmin = integrate . quad ( integral , 0 , 1e1 , args = ( T - dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) CV = ( dEplus - dEmin ) / ( 2 * dT ); print ( f 'dE = { dE : .4e } eV' ) print ( f 'Cv = { CV : .4e } eV/K' ) Check the source code written in python for solving integral using midpoint rule.","title":"Exercise 3: a hypothetical material"},{"location":"Solutions/solutions/#exercise-3-graphene","text":"1. import numpy as np import matplotlib.pyplot as plt x = np . linspace ( - 1 , 1 , 100 ) fig , ax = plt . subplots ( figsize = ( 7 , 5 )) ax . plot ( x , x , 'b' ) ax . plot ( x , - x , 'b' ) ax . spines [ 'left' ] . set_position ( 'center' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0.0 )) # Eliminate upper and right axes ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . set_xticks ([]) ax . set_yticks ([]) ax . set_xlabel ( r '$\\mid \\vec k \\mid$' , fontsize = 14 ) ax . set_ylabel ( r '$\\varepsilon$' , fontsize = 18 , rotation = 'horizontal' ) ax . yaxis . set_label_coords ( 0.5 , 1 ) ax . xaxis . set_label_coords ( 1.0 , 0.49 ) 2.The DOS for the positive energies is given by g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{\\varepsilon}{c^2}, where 2_s is the spin degeneracy and 2_v is the valley degeneracy. If we account for the negative energies as well, we obtain g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{|\\varepsilon|}{c^2}. 3. g(\\varepsilon) vs \\varepsilon is a linear plot. Here, the region marked by -k_B T is a triangle whose area gives the number of electrons that can be excited: \\begin{align} n_{ex} &= \\frac{1}{2} g(-k_B T) k_B T\\\\ &= \\frac{L^2 k_B^2T^2}{\\pi c^2}. \\end{align} From this it follows that the energy difference is given by E(T) - E_0 = \\frac{L^2 k_B^3T^3}{\\pi c^2}. 4. C_v(T) = \\frac{\\partial E}{\\partial T} = \\frac{3L^2k_B^3T^2}{\\pi c^2}","title":"Exercise 3: graphene"}]}